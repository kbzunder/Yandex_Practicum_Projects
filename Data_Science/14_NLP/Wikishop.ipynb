{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikishop  \n",
    "## Анализ комментариев на токсичность\n",
    "### Используя модель логистической регрессии и LightGBM поможем выделить \"токсичные\" комментарии в корпусе текстов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Загрузка библиотек](#data_download)    \n",
    "[2. Загурзка данных. Предобработка](#data_preprocessing)  \n",
    "[3. Логистическая регрессия](#logistic)    \n",
    "[4. LightGBM](#lightGBM)  \n",
    "[5. Выводы](#Conclusion)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_download'></a>\n",
    "### 1. Загрузим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juliagrobman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "#import torch\n",
    "#import transformers \n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser','ner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en-core-web-sm==3.4.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl#egg=en_core_web_sm==3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (3.4.0)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from en-core-web-sm==3.4.0) (3.4.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (49.2.0.post20200714)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.47.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.18.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.24.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.25.9)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.8/site-packages (4.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.8/site-packages (3.4.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (8.1.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (49.2.0.post20200714)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.18.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.47.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_preprocessing'></a>\n",
    "### 2. Загрузка данных. Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_global = '/datasets/toxic_comments.csv'\n",
    "path_local = '/Users/juliagrobman/Downloads/toxic_comments (1).csv'\n",
    "\n",
    "if os.path.exists(path=path_global):\n",
    "    data = pd.read_csv(path_global)\n",
    "elif os.path.exists(path=path_local):\n",
    "    data = pd.read_csv(path_local)\n",
    "else: \n",
    "    print('ERROR IN PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наш датасет состоят из 160 тыс строк, столбец 'toxic' содержит целевой признак"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Уберем из текста знаки пунктуации, стоп-слова, пробелы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  preprocess_text(text, stopwords):\n",
    "    # cleaning punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # text to lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # removing stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "\n",
    "    # removing whitespaces\n",
    "    text = re.sub(r'\\s', ' ', text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean'] = data['text'].apply(lambda x: preprocess_text(x, stopwords=stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применим лемматизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemmatized'] = data['clean'].apply(lambda x: lemmatize_text(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "      <td>daww match background colour I m seemingly stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "      <td>hey man I m really try edit war guy constantly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>cant make real suggestions improvement wondere...</td>\n",
       "      <td>can not make real suggestion improvement wonde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page thats</td>\n",
       "      <td>sir hero chance remember page that s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulations well use tools well · talk</td>\n",
       "      <td>congratulation well use tool well · talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "      <td>vandalism matt shirvington article revert plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry word nonsense offensive anyway im intend...</td>\n",
       "      <td>sorry word nonsense offensive anyway I m inten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>fair use rationale imagewonjujpg thanks upload...</td>\n",
       "      <td>fair use rationale imagewonjujpg thank upload ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>bbq man lets discuss itmaybe phone</td>\n",
       "      <td>bbq man let discuss itmaybe phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>hey talk exclusive group wp talibanswho good d...</td>\n",
       "      <td>hey talk exclusive group wp talibanswho good d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>start throwing accusations warnings lets revie...</td>\n",
       "      <td>start throw accusation warning let review edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh girl started arguments stuck nose doesnt be...</td>\n",
       "      <td>oh girl start argument stick nose do not belon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>juelz santanas age 2002 juelz santana 18 years...</td>\n",
       "      <td>juelz santanas age 2002 juelz santana 18 year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>bye dont look come think comming back tosser</td>\n",
       "      <td>bye do not look come think comme back tosser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "      <td>redirect talkvoydan pop georgiev chernodrinski</td>\n",
       "      <td>redirect talkvoydan pop georgiev chernodrinski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>mitsurugi point made sense argue include hindi...</td>\n",
       "      <td>mitsurugi point make sense argue include hindi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "      <td>dont mean bother see youre writing something r...</td>\n",
       "      <td>do not mean bother see you re write something ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic  \\\n",
       "0   Explanation\\nWhy the edits made under my usern...      0   \n",
       "1   D'aww! He matches this background colour I'm s...      0   \n",
       "2   Hey man, I'm really not trying to edit war. It...      0   \n",
       "3   \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4   You, sir, are my hero. Any chance you remember...      0   \n",
       "5   \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7   Your vandalism to the Matt Shirvington article...      0   \n",
       "8   Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9   alignment on this subject and which are contra...      0   \n",
       "10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0   \n",
       "11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0   \n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1   \n",
       "13  Before you start throwing accusations and warn...      0   \n",
       "14  Oh, and the girl above started her arguments w...      0   \n",
       "15  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...      0   \n",
       "16  Bye! \\n\\nDon't look, come or think of comming ...      1   \n",
       "17   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski      0   \n",
       "18  The Mitsurugi point made no sense - why not ar...      0   \n",
       "19  Don't mean to bother you \\n\\nI see that you're...      0   \n",
       "\n",
       "                                                clean  \\\n",
       "0   explanation edits made username hardcore metal...   \n",
       "1   daww matches background colour im seemingly st...   \n",
       "2   hey man im really trying edit war guy constant...   \n",
       "3   cant make real suggestions improvement wondere...   \n",
       "4                 sir hero chance remember page thats   \n",
       "5          congratulations well use tools well · talk   \n",
       "6                         cocksucker piss around work   \n",
       "7   vandalism matt shirvington article reverted pl...   \n",
       "8   sorry word nonsense offensive anyway im intend...   \n",
       "9                alignment subject contrary dulithgow   \n",
       "10  fair use rationale imagewonjujpg thanks upload...   \n",
       "11                 bbq man lets discuss itmaybe phone   \n",
       "12  hey talk exclusive group wp talibanswho good d...   \n",
       "13  start throwing accusations warnings lets revie...   \n",
       "14  oh girl started arguments stuck nose doesnt be...   \n",
       "15  juelz santanas age 2002 juelz santana 18 years...   \n",
       "16       bye dont look come think comming back tosser   \n",
       "17     redirect talkvoydan pop georgiev chernodrinski   \n",
       "18  mitsurugi point made sense argue include hindi...   \n",
       "19  dont mean bother see youre writing something r...   \n",
       "\n",
       "                                           lemmatized  \n",
       "0   explanation edit make username hardcore metall...  \n",
       "1   daww match background colour I m seemingly stu...  \n",
       "2   hey man I m really try edit war guy constantly...  \n",
       "3   can not make real suggestion improvement wonde...  \n",
       "4                sir hero chance remember page that s  \n",
       "5            congratulation well use tool well · talk  \n",
       "6                         cocksucker piss around work  \n",
       "7   vandalism matt shirvington article revert plea...  \n",
       "8   sorry word nonsense offensive anyway I m inten...  \n",
       "9                alignment subject contrary dulithgow  \n",
       "10  fair use rationale imagewonjujpg thank upload ...  \n",
       "11                  bbq man let discuss itmaybe phone  \n",
       "12  hey talk exclusive group wp talibanswho good d...  \n",
       "13  start throw accusation warning let review edit...  \n",
       "14  oh girl start argument stick nose do not belon...  \n",
       "15  juelz santanas age 2002 juelz santana 18 year ...  \n",
       "16       bye do not look come think comme back tosser  \n",
       "17     redirect talkvoydan pop georgiev chernodrinski  \n",
       "18  mitsurugi point make sense argue include hindi...  \n",
       "19  do not mean bother see you re write something ...  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделим данные на обучающую, валидационную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['lemmatized']\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_full, features_valid, target_train_full, target_valid = train_test_split(features, target, test_size=0.2, shuffle=True)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_train_full, target_train_full, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применим if-idf для векторизации текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()\n",
    "features_train = count_tf_idf.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid = count_tf_idf.transform(features_valid)\n",
    "features_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logistic'></a>\n",
    "### 3. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим логистическую регрессию с гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 433, in _check_solver\n",
      "    raise ValueError(\"Logistic Regression supports only solvers in %s, got\"\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got lbfg.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7732712765957447"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'penalty' : ['l1','l2'],\n",
    "    'C': np.logspace(-3,3,7),\n",
    "    'solver':['lbfg', 'liblinear']\n",
    "}\n",
    "\n",
    "model = LogisticRegression(random_state=12345)\n",
    "grid = GridSearchCV(model, param_grid=params, scoring='f1')\n",
    "grid.fit(features_train, target_train)\n",
    "predictions = grid.predict(features_valid)\n",
    "score = f1_score(predictions, target_valid)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим на тестовой выборке:\n",
    "predictions = grid.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.77\n"
     ]
    }
   ],
   "source": [
    "score_test = f1_score(target_test, predictions)\n",
    "print('F1 score {:.2f}'.format(score_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Попробуем проверить нашу модель на \"токсичном\" и \"нетоксичном\" предложении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = 'look at yourself, you are a fat, black, sodding idiot, thinking just about money'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_0 = 'I will surely recommend this product to my family and friends, thanks!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = preprocess_text(test_sent, stop_words)\n",
    "test_sent = lemmatize_text(test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_0 = preprocess_text(test_sent_0, stop_words)\n",
    "test_sent_0 = lemmatize_text(test_sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'surely recommend product family friend thank'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = count_tf_idf.transform([test_sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_0 = count_tf_idf.transform([test_sent_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(test_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наша модель хорошо предсказывает токсичные комментарии, f1 выше трешхолда в 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lightGBM'></a>\n",
    "### 4.Попробуем другую модель: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.895864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[1]\tvalid_0's auc: 0.809626\n",
      "[2]\tvalid_0's auc: 0.876043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\tvalid_0's auc: 0.900458\n",
      "[4]\tvalid_0's auc: 0.909067\n",
      "[5]\tvalid_0's auc: 0.921281\n",
      "[6]\tvalid_0's auc: 0.924341\n",
      "[7]\tvalid_0's auc: 0.926004\n",
      "[8]\tvalid_0's auc: 0.926537\n",
      "[9]\tvalid_0's auc: 0.927568\n",
      "[10]\tvalid_0's auc: 0.929274\n",
      "[11]\tvalid_0's auc: 0.930684\n",
      "[12]\tvalid_0's auc: 0.931021\n",
      "[13]\tvalid_0's auc: 0.932074\n",
      "[14]\tvalid_0's auc: 0.932588\n",
      "[15]\tvalid_0's auc: 0.933744\n",
      "[16]\tvalid_0's auc: 0.933953\n",
      "[17]\tvalid_0's auc: 0.933855\n",
      "[18]\tvalid_0's auc: 0.934769\n",
      "[19]\tvalid_0's auc: 0.935645\n",
      "[20]\tvalid_0's auc: 0.93659\n",
      "[21]\tvalid_0's auc: 0.936995\n",
      "[22]\tvalid_0's auc: 0.936921\n",
      "[23]\tvalid_0's auc: 0.937333\n",
      "[24]\tvalid_0's auc: 0.937876\n",
      "[25]\tvalid_0's auc: 0.938012\n",
      "[26]\tvalid_0's auc: 0.9384\n",
      "[27]\tvalid_0's auc: 0.939101\n",
      "[28]\tvalid_0's auc: 0.939205\n",
      "[29]\tvalid_0's auc: 0.939199\n",
      "[30]\tvalid_0's auc: 0.939669\n",
      "[31]\tvalid_0's auc: 0.940241\n",
      "[32]\tvalid_0's auc: 0.94081\n",
      "[33]\tvalid_0's auc: 0.940773\n",
      "[34]\tvalid_0's auc: 0.941209\n",
      "[35]\tvalid_0's auc: 0.94118\n",
      "[36]\tvalid_0's auc: 0.941249\n",
      "[37]\tvalid_0's auc: 0.941365\n",
      "[38]\tvalid_0's auc: 0.941606\n",
      "[39]\tvalid_0's auc: 0.941914\n",
      "[40]\tvalid_0's auc: 0.94225\n",
      "[41]\tvalid_0's auc: 0.942144\n",
      "[42]\tvalid_0's auc: 0.942293\n",
      "[43]\tvalid_0's auc: 0.94243\n",
      "[44]\tvalid_0's auc: 0.942893\n",
      "[45]\tvalid_0's auc: 0.943577\n",
      "[46]\tvalid_0's auc: 0.943629\n",
      "[47]\tvalid_0's auc: 0.943429\n",
      "[48]\tvalid_0's auc: 0.943549\n",
      "[49]\tvalid_0's auc: 0.94354\n",
      "[50]\tvalid_0's auc: 0.94367\n",
      "[51]\tvalid_0's auc: 0.94396\n",
      "[52]\tvalid_0's auc: 0.944056\n",
      "[53]\tvalid_0's auc: 0.944055\n",
      "[54]\tvalid_0's auc: 0.9439\n",
      "[55]\tvalid_0's auc: 0.944004\n",
      "[56]\tvalid_0's auc: 0.944145\n",
      "[57]\tvalid_0's auc: 0.944278\n",
      "[58]\tvalid_0's auc: 0.944263\n",
      "[59]\tvalid_0's auc: 0.944323\n",
      "[60]\tvalid_0's auc: 0.944355\n",
      "[61]\tvalid_0's auc: 0.944402\n",
      "[62]\tvalid_0's auc: 0.944582\n",
      "[63]\tvalid_0's auc: 0.944998\n",
      "[64]\tvalid_0's auc: 0.945104\n",
      "[65]\tvalid_0's auc: 0.945078\n",
      "[66]\tvalid_0's auc: 0.945025\n",
      "[67]\tvalid_0's auc: 0.945163\n",
      "[68]\tvalid_0's auc: 0.945409\n",
      "[69]\tvalid_0's auc: 0.945461\n",
      "[70]\tvalid_0's auc: 0.945504\n",
      "[71]\tvalid_0's auc: 0.945619\n",
      "[72]\tvalid_0's auc: 0.945619\n",
      "[73]\tvalid_0's auc: 0.94581\n",
      "[74]\tvalid_0's auc: 0.945752\n",
      "[75]\tvalid_0's auc: 0.945678\n",
      "[76]\tvalid_0's auc: 0.945781\n",
      "[77]\tvalid_0's auc: 0.945679\n",
      "[78]\tvalid_0's auc: 0.945692\n",
      "[79]\tvalid_0's auc: 0.945906\n",
      "[80]\tvalid_0's auc: 0.945867\n",
      "[81]\tvalid_0's auc: 0.945857\n",
      "[82]\tvalid_0's auc: 0.946193\n",
      "[83]\tvalid_0's auc: 0.946187\n",
      "[84]\tvalid_0's auc: 0.946271\n",
      "[85]\tvalid_0's auc: 0.946265\n",
      "[86]\tvalid_0's auc: 0.946199\n",
      "[87]\tvalid_0's auc: 0.945814\n",
      "[88]\tvalid_0's auc: 0.945762\n",
      "[89]\tvalid_0's auc: 0.9458\n",
      "[90]\tvalid_0's auc: 0.945703\n",
      "[91]\tvalid_0's auc: 0.945694\n",
      "[92]\tvalid_0's auc: 0.945691\n",
      "[93]\tvalid_0's auc: 0.945612\n",
      "[94]\tvalid_0's auc: 0.945558\n",
      "[95]\tvalid_0's auc: 0.945642\n",
      "[96]\tvalid_0's auc: 0.945687\n",
      "[97]\tvalid_0's auc: 0.945623\n",
      "[98]\tvalid_0's auc: 0.945616\n",
      "[99]\tvalid_0's auc: 0.945614\n",
      "[100]\tvalid_0's auc: 0.945348\n",
      "[101]\tvalid_0's auc: 0.945463\n",
      "[102]\tvalid_0's auc: 0.945532\n",
      "[103]\tvalid_0's auc: 0.945526\n",
      "[104]\tvalid_0's auc: 0.945995\n",
      "[105]\tvalid_0's auc: 0.946019\n",
      "[106]\tvalid_0's auc: 0.945997\n",
      "[107]\tvalid_0's auc: 0.946073\n",
      "[108]\tvalid_0's auc: 0.946417\n",
      "[109]\tvalid_0's auc: 0.946338\n",
      "[110]\tvalid_0's auc: 0.946422\n",
      "[111]\tvalid_0's auc: 0.94647\n",
      "[112]\tvalid_0's auc: 0.946451\n",
      "[113]\tvalid_0's auc: 0.946429\n",
      "[114]\tvalid_0's auc: 0.946625\n",
      "[115]\tvalid_0's auc: 0.946645\n",
      "[116]\tvalid_0's auc: 0.946892\n",
      "[117]\tvalid_0's auc: 0.946889\n",
      "[118]\tvalid_0's auc: 0.947082\n",
      "[119]\tvalid_0's auc: 0.94704\n",
      "[120]\tvalid_0's auc: 0.947029\n",
      "[121]\tvalid_0's auc: 0.94706\n",
      "[122]\tvalid_0's auc: 0.947072\n",
      "[123]\tvalid_0's auc: 0.947382\n",
      "[124]\tvalid_0's auc: 0.947545\n",
      "[125]\tvalid_0's auc: 0.947612\n",
      "[126]\tvalid_0's auc: 0.947513\n",
      "[127]\tvalid_0's auc: 0.947652\n",
      "[128]\tvalid_0's auc: 0.947685\n",
      "[129]\tvalid_0's auc: 0.947932\n",
      "[130]\tvalid_0's auc: 0.947862\n",
      "[131]\tvalid_0's auc: 0.947897\n",
      "[132]\tvalid_0's auc: 0.948084\n",
      "[133]\tvalid_0's auc: 0.948439\n",
      "[134]\tvalid_0's auc: 0.948404\n",
      "[135]\tvalid_0's auc: 0.948196\n",
      "[136]\tvalid_0's auc: 0.948276\n",
      "[137]\tvalid_0's auc: 0.948257\n",
      "[138]\tvalid_0's auc: 0.948299\n",
      "[139]\tvalid_0's auc: 0.948505\n",
      "[140]\tvalid_0's auc: 0.948484\n",
      "[141]\tvalid_0's auc: 0.948499\n",
      "[142]\tvalid_0's auc: 0.948533\n",
      "[143]\tvalid_0's auc: 0.948609\n",
      "[144]\tvalid_0's auc: 0.948621\n",
      "[145]\tvalid_0's auc: 0.948734\n",
      "[146]\tvalid_0's auc: 0.948717\n",
      "[147]\tvalid_0's auc: 0.948736\n",
      "[148]\tvalid_0's auc: 0.948622\n",
      "[149]\tvalid_0's auc: 0.94873\n",
      "[150]\tvalid_0's auc: 0.948698\n",
      "[151]\tvalid_0's auc: 0.948701\n",
      "[152]\tvalid_0's auc: 0.948702\n",
      "[153]\tvalid_0's auc: 0.948865\n",
      "[154]\tvalid_0's auc: 0.948829\n",
      "[155]\tvalid_0's auc: 0.948932\n",
      "[156]\tvalid_0's auc: 0.948922\n",
      "[157]\tvalid_0's auc: 0.948838\n",
      "[158]\tvalid_0's auc: 0.948829\n",
      "[159]\tvalid_0's auc: 0.948905\n",
      "[160]\tvalid_0's auc: 0.948837\n",
      "[161]\tvalid_0's auc: 0.948923\n",
      "[162]\tvalid_0's auc: 0.948925\n",
      "[163]\tvalid_0's auc: 0.949063\n",
      "[164]\tvalid_0's auc: 0.949031\n",
      "[165]\tvalid_0's auc: 0.949089\n",
      "[166]\tvalid_0's auc: 0.948968\n",
      "[167]\tvalid_0's auc: 0.949332\n",
      "[168]\tvalid_0's auc: 0.949328\n",
      "[169]\tvalid_0's auc: 0.949458\n",
      "[170]\tvalid_0's auc: 0.949502\n",
      "[171]\tvalid_0's auc: 0.949443\n",
      "[172]\tvalid_0's auc: 0.949462\n",
      "[173]\tvalid_0's auc: 0.949547\n",
      "[174]\tvalid_0's auc: 0.949674\n",
      "[175]\tvalid_0's auc: 0.94976\n",
      "[176]\tvalid_0's auc: 0.949759\n",
      "[177]\tvalid_0's auc: 0.949759\n",
      "[178]\tvalid_0's auc: 0.949729\n",
      "[179]\tvalid_0's auc: 0.94982\n",
      "[180]\tvalid_0's auc: 0.94985\n",
      "[181]\tvalid_0's auc: 0.949964\n",
      "[182]\tvalid_0's auc: 0.95003\n",
      "[183]\tvalid_0's auc: 0.950379\n",
      "[184]\tvalid_0's auc: 0.950548\n",
      "[185]\tvalid_0's auc: 0.950477\n",
      "[186]\tvalid_0's auc: 0.950439\n",
      "[187]\tvalid_0's auc: 0.950709\n",
      "[188]\tvalid_0's auc: 0.950866\n",
      "[189]\tvalid_0's auc: 0.950854\n",
      "[190]\tvalid_0's auc: 0.950858\n",
      "[191]\tvalid_0's auc: 0.950792\n",
      "[192]\tvalid_0's auc: 0.950821\n",
      "[193]\tvalid_0's auc: 0.950906\n",
      "[194]\tvalid_0's auc: 0.950914\n",
      "[195]\tvalid_0's auc: 0.950924\n",
      "[196]\tvalid_0's auc: 0.95096\n",
      "[197]\tvalid_0's auc: 0.950999\n",
      "[198]\tvalid_0's auc: 0.950982\n",
      "[199]\tvalid_0's auc: 0.950982\n",
      "[200]\tvalid_0's auc: 0.950982\n",
      "[201]\tvalid_0's auc: 0.95096\n",
      "[202]\tvalid_0's auc: 0.950959\n",
      "[203]\tvalid_0's auc: 0.950769\n",
      "[204]\tvalid_0's auc: 0.950779\n",
      "[205]\tvalid_0's auc: 0.950806\n",
      "[206]\tvalid_0's auc: 0.950807\n",
      "[207]\tvalid_0's auc: 0.950768\n",
      "[208]\tvalid_0's auc: 0.95077\n",
      "[209]\tvalid_0's auc: 0.950713\n",
      "[210]\tvalid_0's auc: 0.950742\n",
      "[211]\tvalid_0's auc: 0.950738\n",
      "[212]\tvalid_0's auc: 0.951072\n",
      "[213]\tvalid_0's auc: 0.950981\n",
      "[214]\tvalid_0's auc: 0.950991\n",
      "[215]\tvalid_0's auc: 0.951066\n",
      "[216]\tvalid_0's auc: 0.951065\n",
      "[217]\tvalid_0's auc: 0.951199\n",
      "[218]\tvalid_0's auc: 0.951234\n",
      "[219]\tvalid_0's auc: 0.951217\n",
      "[220]\tvalid_0's auc: 0.951218\n",
      "[221]\tvalid_0's auc: 0.951225\n",
      "[222]\tvalid_0's auc: 0.951521\n",
      "[223]\tvalid_0's auc: 0.951727\n",
      "[224]\tvalid_0's auc: 0.951735\n",
      "[225]\tvalid_0's auc: 0.951725\n",
      "[226]\tvalid_0's auc: 0.95171\n",
      "[227]\tvalid_0's auc: 0.951692\n",
      "[228]\tvalid_0's auc: 0.951735\n",
      "[229]\tvalid_0's auc: 0.951728\n",
      "[230]\tvalid_0's auc: 0.951933\n",
      "[231]\tvalid_0's auc: 0.952162\n",
      "[232]\tvalid_0's auc: 0.952278\n",
      "[233]\tvalid_0's auc: 0.952274\n",
      "[234]\tvalid_0's auc: 0.952616\n",
      "[235]\tvalid_0's auc: 0.95262\n",
      "[236]\tvalid_0's auc: 0.952932\n",
      "[237]\tvalid_0's auc: 0.953075\n",
      "[238]\tvalid_0's auc: 0.953169\n",
      "[239]\tvalid_0's auc: 0.953222\n",
      "[240]\tvalid_0's auc: 0.953459\n",
      "[241]\tvalid_0's auc: 0.953459\n",
      "[242]\tvalid_0's auc: 0.953742\n",
      "[243]\tvalid_0's auc: 0.953728\n",
      "[244]\tvalid_0's auc: 0.953755\n",
      "[245]\tvalid_0's auc: 0.9539\n",
      "[246]\tvalid_0's auc: 0.953876\n",
      "[247]\tvalid_0's auc: 0.954078\n",
      "[248]\tvalid_0's auc: 0.954055\n",
      "[249]\tvalid_0's auc: 0.954068\n",
      "[250]\tvalid_0's auc: 0.954195\n",
      "[251]\tvalid_0's auc: 0.954172\n",
      "[252]\tvalid_0's auc: 0.954162\n",
      "[253]\tvalid_0's auc: 0.954188\n",
      "[254]\tvalid_0's auc: 0.954256\n",
      "[255]\tvalid_0's auc: 0.954248\n",
      "[256]\tvalid_0's auc: 0.954334\n",
      "[257]\tvalid_0's auc: 0.954439\n",
      "[258]\tvalid_0's auc: 0.954441\n",
      "[259]\tvalid_0's auc: 0.954441\n",
      "[260]\tvalid_0's auc: 0.954434\n",
      "[261]\tvalid_0's auc: 0.954423\n",
      "[262]\tvalid_0's auc: 0.954618\n",
      "[263]\tvalid_0's auc: 0.954689\n",
      "[264]\tvalid_0's auc: 0.95492\n",
      "[265]\tvalid_0's auc: 0.954893\n",
      "[266]\tvalid_0's auc: 0.954922\n",
      "[267]\tvalid_0's auc: 0.954895\n",
      "[268]\tvalid_0's auc: 0.954878\n",
      "[269]\tvalid_0's auc: 0.954892\n",
      "[270]\tvalid_0's auc: 0.954872\n",
      "[271]\tvalid_0's auc: 0.954902\n",
      "[272]\tvalid_0's auc: 0.954979\n",
      "[273]\tvalid_0's auc: 0.954994\n",
      "[274]\tvalid_0's auc: 0.954961\n",
      "[275]\tvalid_0's auc: 0.955276\n",
      "[276]\tvalid_0's auc: 0.955255\n",
      "[277]\tvalid_0's auc: 0.955189\n",
      "[278]\tvalid_0's auc: 0.955194\n",
      "[279]\tvalid_0's auc: 0.955339\n",
      "[280]\tvalid_0's auc: 0.955337\n",
      "[281]\tvalid_0's auc: 0.955328\n",
      "[282]\tvalid_0's auc: 0.955184\n",
      "[283]\tvalid_0's auc: 0.955174\n",
      "[284]\tvalid_0's auc: 0.955252\n",
      "[285]\tvalid_0's auc: 0.955406\n",
      "[286]\tvalid_0's auc: 0.955507\n",
      "[287]\tvalid_0's auc: 0.955524\n",
      "[288]\tvalid_0's auc: 0.955515\n",
      "[289]\tvalid_0's auc: 0.955463\n",
      "[290]\tvalid_0's auc: 0.955603\n",
      "[291]\tvalid_0's auc: 0.955577\n",
      "[292]\tvalid_0's auc: 0.955557\n",
      "[293]\tvalid_0's auc: 0.955549\n",
      "[294]\tvalid_0's auc: 0.955565\n",
      "[295]\tvalid_0's auc: 0.955544\n",
      "[296]\tvalid_0's auc: 0.955541\n",
      "[297]\tvalid_0's auc: 0.955518\n",
      "[298]\tvalid_0's auc: 0.955531\n",
      "[299]\tvalid_0's auc: 0.955584\n",
      "[300]\tvalid_0's auc: 0.955572\n",
      "[301]\tvalid_0's auc: 0.955569\n",
      "[302]\tvalid_0's auc: 0.955565\n",
      "[303]\tvalid_0's auc: 0.955572\n",
      "[304]\tvalid_0's auc: 0.955575\n",
      "[305]\tvalid_0's auc: 0.955557\n",
      "[306]\tvalid_0's auc: 0.955547\n",
      "[307]\tvalid_0's auc: 0.955559\n",
      "[308]\tvalid_0's auc: 0.955702\n",
      "[309]\tvalid_0's auc: 0.955667\n",
      "[310]\tvalid_0's auc: 0.955764\n",
      "[311]\tvalid_0's auc: 0.955757\n",
      "[312]\tvalid_0's auc: 0.955917\n",
      "[313]\tvalid_0's auc: 0.956021\n",
      "[314]\tvalid_0's auc: 0.955991\n",
      "[315]\tvalid_0's auc: 0.955979\n",
      "[316]\tvalid_0's auc: 0.956009\n",
      "[317]\tvalid_0's auc: 0.956021\n",
      "[318]\tvalid_0's auc: 0.956054\n",
      "[319]\tvalid_0's auc: 0.95604\n",
      "[320]\tvalid_0's auc: 0.956041\n",
      "[321]\tvalid_0's auc: 0.956054\n",
      "[322]\tvalid_0's auc: 0.956216\n",
      "[323]\tvalid_0's auc: 0.956352\n",
      "[324]\tvalid_0's auc: 0.956378\n",
      "[325]\tvalid_0's auc: 0.956469\n",
      "[326]\tvalid_0's auc: 0.956468\n",
      "[327]\tvalid_0's auc: 0.95662\n",
      "[328]\tvalid_0's auc: 0.956618\n",
      "[329]\tvalid_0's auc: 0.9567\n",
      "[330]\tvalid_0's auc: 0.956715\n",
      "[331]\tvalid_0's auc: 0.956732\n",
      "[332]\tvalid_0's auc: 0.95674\n",
      "[333]\tvalid_0's auc: 0.95672\n",
      "[334]\tvalid_0's auc: 0.956718\n",
      "[335]\tvalid_0's auc: 0.956712\n",
      "[336]\tvalid_0's auc: 0.956715\n",
      "[337]\tvalid_0's auc: 0.956902\n",
      "[338]\tvalid_0's auc: 0.956937\n",
      "[339]\tvalid_0's auc: 0.956928\n",
      "[340]\tvalid_0's auc: 0.956947\n",
      "[341]\tvalid_0's auc: 0.957047\n",
      "[342]\tvalid_0's auc: 0.957034\n",
      "[343]\tvalid_0's auc: 0.957202\n",
      "[344]\tvalid_0's auc: 0.957192\n",
      "[345]\tvalid_0's auc: 0.957205\n",
      "[346]\tvalid_0's auc: 0.957313\n",
      "[347]\tvalid_0's auc: 0.957312\n",
      "[348]\tvalid_0's auc: 0.957357\n",
      "[349]\tvalid_0's auc: 0.957429\n",
      "[350]\tvalid_0's auc: 0.957424\n",
      "[351]\tvalid_0's auc: 0.957622\n",
      "[352]\tvalid_0's auc: 0.957689\n",
      "[353]\tvalid_0's auc: 0.957763\n",
      "[354]\tvalid_0's auc: 0.957739\n",
      "[355]\tvalid_0's auc: 0.957719\n",
      "[356]\tvalid_0's auc: 0.957666\n",
      "[357]\tvalid_0's auc: 0.957671\n",
      "[358]\tvalid_0's auc: 0.957687\n",
      "[359]\tvalid_0's auc: 0.957673\n",
      "[360]\tvalid_0's auc: 0.957743\n",
      "[361]\tvalid_0's auc: 0.957735\n",
      "[362]\tvalid_0's auc: 0.957777\n",
      "[363]\tvalid_0's auc: 0.957771\n",
      "[364]\tvalid_0's auc: 0.95776\n",
      "[365]\tvalid_0's auc: 0.957752\n",
      "[366]\tvalid_0's auc: 0.957738\n",
      "[367]\tvalid_0's auc: 0.957712\n",
      "[368]\tvalid_0's auc: 0.957806\n",
      "[369]\tvalid_0's auc: 0.9578\n",
      "[370]\tvalid_0's auc: 0.957814\n",
      "[371]\tvalid_0's auc: 0.957801\n",
      "[372]\tvalid_0's auc: 0.957787\n",
      "[373]\tvalid_0's auc: 0.957812\n",
      "[374]\tvalid_0's auc: 0.957902\n",
      "[375]\tvalid_0's auc: 0.9579\n",
      "[376]\tvalid_0's auc: 0.957895\n",
      "[377]\tvalid_0's auc: 0.958076\n",
      "[378]\tvalid_0's auc: 0.958068\n",
      "[379]\tvalid_0's auc: 0.958042\n",
      "[380]\tvalid_0's auc: 0.95807\n",
      "[381]\tvalid_0's auc: 0.958064\n",
      "[382]\tvalid_0's auc: 0.958044\n",
      "[383]\tvalid_0's auc: 0.958114\n",
      "[384]\tvalid_0's auc: 0.958164\n",
      "[385]\tvalid_0's auc: 0.958141\n",
      "[386]\tvalid_0's auc: 0.958253\n",
      "[387]\tvalid_0's auc: 0.958388\n",
      "[388]\tvalid_0's auc: 0.958433\n",
      "[389]\tvalid_0's auc: 0.958566\n",
      "[390]\tvalid_0's auc: 0.958616\n",
      "[391]\tvalid_0's auc: 0.958611\n",
      "[392]\tvalid_0's auc: 0.958541\n",
      "[393]\tvalid_0's auc: 0.958605\n",
      "[394]\tvalid_0's auc: 0.958697\n",
      "[395]\tvalid_0's auc: 0.958684\n",
      "[396]\tvalid_0's auc: 0.958679\n",
      "[397]\tvalid_0's auc: 0.958794\n",
      "[398]\tvalid_0's auc: 0.958811\n",
      "[399]\tvalid_0's auc: 0.958819\n",
      "[400]\tvalid_0's auc: 0.958889\n",
      "[401]\tvalid_0's auc: 0.958892\n",
      "[402]\tvalid_0's auc: 0.959\n",
      "[403]\tvalid_0's auc: 0.959005\n",
      "[404]\tvalid_0's auc: 0.95907\n",
      "[405]\tvalid_0's auc: 0.959156\n",
      "[406]\tvalid_0's auc: 0.959125\n",
      "[407]\tvalid_0's auc: 0.959243\n",
      "[408]\tvalid_0's auc: 0.959251\n",
      "[409]\tvalid_0's auc: 0.959403\n",
      "[410]\tvalid_0's auc: 0.959457\n",
      "[411]\tvalid_0's auc: 0.959541\n",
      "[412]\tvalid_0's auc: 0.959539\n",
      "[413]\tvalid_0's auc: 0.959533\n",
      "[414]\tvalid_0's auc: 0.959587\n",
      "[415]\tvalid_0's auc: 0.959636\n",
      "[416]\tvalid_0's auc: 0.959621\n",
      "[417]\tvalid_0's auc: 0.959608\n",
      "[418]\tvalid_0's auc: 0.959606\n",
      "[419]\tvalid_0's auc: 0.959588\n",
      "[420]\tvalid_0's auc: 0.959587\n",
      "[421]\tvalid_0's auc: 0.959637\n",
      "[422]\tvalid_0's auc: 0.959732\n",
      "[423]\tvalid_0's auc: 0.959753\n",
      "[424]\tvalid_0's auc: 0.95976\n",
      "[425]\tvalid_0's auc: 0.959764\n",
      "[426]\tvalid_0's auc: 0.95973\n",
      "[427]\tvalid_0's auc: 0.959785\n",
      "[428]\tvalid_0's auc: 0.959762\n",
      "[429]\tvalid_0's auc: 0.959779\n",
      "[430]\tvalid_0's auc: 0.959789\n",
      "[431]\tvalid_0's auc: 0.959827\n",
      "[432]\tvalid_0's auc: 0.95985\n",
      "[433]\tvalid_0's auc: 0.959846\n",
      "[434]\tvalid_0's auc: 0.959842\n",
      "[435]\tvalid_0's auc: 0.959832\n",
      "[436]\tvalid_0's auc: 0.959895\n",
      "[437]\tvalid_0's auc: 0.959931\n",
      "[438]\tvalid_0's auc: 0.959921\n",
      "[439]\tvalid_0's auc: 0.959919\n",
      "[440]\tvalid_0's auc: 0.960002\n",
      "[441]\tvalid_0's auc: 0.96017\n",
      "[442]\tvalid_0's auc: 0.960225\n",
      "[443]\tvalid_0's auc: 0.960223\n",
      "[444]\tvalid_0's auc: 0.960284\n",
      "[445]\tvalid_0's auc: 0.960336\n",
      "[446]\tvalid_0's auc: 0.960329\n",
      "[447]\tvalid_0's auc: 0.960258\n",
      "[448]\tvalid_0's auc: 0.96027\n",
      "[449]\tvalid_0's auc: 0.960374\n",
      "[450]\tvalid_0's auc: 0.960375\n",
      "[451]\tvalid_0's auc: 0.960265\n",
      "[452]\tvalid_0's auc: 0.960276\n",
      "[453]\tvalid_0's auc: 0.960262\n",
      "[454]\tvalid_0's auc: 0.960268\n",
      "[455]\tvalid_0's auc: 0.960282\n",
      "[456]\tvalid_0's auc: 0.960278\n",
      "[457]\tvalid_0's auc: 0.960289\n",
      "[458]\tvalid_0's auc: 0.960311\n",
      "[459]\tvalid_0's auc: 0.960321\n",
      "[460]\tvalid_0's auc: 0.960334\n",
      "[461]\tvalid_0's auc: 0.960401\n",
      "[462]\tvalid_0's auc: 0.960386\n",
      "[463]\tvalid_0's auc: 0.960414\n",
      "[464]\tvalid_0's auc: 0.960463\n",
      "[465]\tvalid_0's auc: 0.960449\n",
      "[466]\tvalid_0's auc: 0.960441\n",
      "[467]\tvalid_0's auc: 0.960512\n",
      "[468]\tvalid_0's auc: 0.960513\n",
      "[469]\tvalid_0's auc: 0.96057\n",
      "[470]\tvalid_0's auc: 0.960557\n",
      "[471]\tvalid_0's auc: 0.960663\n",
      "[472]\tvalid_0's auc: 0.960653\n",
      "[473]\tvalid_0's auc: 0.960736\n",
      "[474]\tvalid_0's auc: 0.960805\n",
      "[475]\tvalid_0's auc: 0.960816\n",
      "[476]\tvalid_0's auc: 0.960826\n",
      "[477]\tvalid_0's auc: 0.960919\n",
      "[478]\tvalid_0's auc: 0.960908\n",
      "[479]\tvalid_0's auc: 0.960901\n",
      "[480]\tvalid_0's auc: 0.96095\n",
      "[481]\tvalid_0's auc: 0.960989\n",
      "[482]\tvalid_0's auc: 0.960996\n",
      "[483]\tvalid_0's auc: 0.960989\n",
      "[484]\tvalid_0's auc: 0.960994\n",
      "[485]\tvalid_0's auc: 0.96099\n",
      "[486]\tvalid_0's auc: 0.961057\n",
      "[487]\tvalid_0's auc: 0.961092\n",
      "[488]\tvalid_0's auc: 0.961169\n",
      "[489]\tvalid_0's auc: 0.961204\n",
      "[490]\tvalid_0's auc: 0.9612\n",
      "[491]\tvalid_0's auc: 0.961198\n",
      "[492]\tvalid_0's auc: 0.961193\n",
      "[493]\tvalid_0's auc: 0.961184\n",
      "[494]\tvalid_0's auc: 0.961207\n",
      "[495]\tvalid_0's auc: 0.961187\n",
      "[496]\tvalid_0's auc: 0.961269\n",
      "[497]\tvalid_0's auc: 0.961302\n",
      "[498]\tvalid_0's auc: 0.961311\n",
      "[499]\tvalid_0's auc: 0.961307\n",
      "[500]\tvalid_0's auc: 0.961306\n",
      "[501]\tvalid_0's auc: 0.961312\n",
      "[502]\tvalid_0's auc: 0.961318\n",
      "[503]\tvalid_0's auc: 0.961299\n",
      "[504]\tvalid_0's auc: 0.961298\n",
      "[505]\tvalid_0's auc: 0.9613\n",
      "[506]\tvalid_0's auc: 0.961248\n",
      "[507]\tvalid_0's auc: 0.96121\n",
      "[508]\tvalid_0's auc: 0.961165\n",
      "[509]\tvalid_0's auc: 0.961168\n",
      "[510]\tvalid_0's auc: 0.961123\n",
      "[511]\tvalid_0's auc: 0.961119\n",
      "[512]\tvalid_0's auc: 0.961128\n",
      "[513]\tvalid_0's auc: 0.961147\n",
      "[514]\tvalid_0's auc: 0.961099\n",
      "[515]\tvalid_0's auc: 0.961085\n",
      "[516]\tvalid_0's auc: 0.961084\n",
      "[517]\tvalid_0's auc: 0.961086\n",
      "[518]\tvalid_0's auc: 0.961086\n",
      "[519]\tvalid_0's auc: 0.961083\n",
      "[520]\tvalid_0's auc: 0.961063\n",
      "[521]\tvalid_0's auc: 0.961083\n",
      "[522]\tvalid_0's auc: 0.961083\n",
      "[523]\tvalid_0's auc: 0.961088\n",
      "[524]\tvalid_0's auc: 0.961081\n",
      "[525]\tvalid_0's auc: 0.961083\n",
      "[526]\tvalid_0's auc: 0.961196\n",
      "[527]\tvalid_0's auc: 0.961195\n",
      "[528]\tvalid_0's auc: 0.961245\n",
      "[529]\tvalid_0's auc: 0.961344\n",
      "[530]\tvalid_0's auc: 0.961355\n",
      "[531]\tvalid_0's auc: 0.961348\n",
      "[532]\tvalid_0's auc: 0.961322\n",
      "[533]\tvalid_0's auc: 0.961317\n",
      "[534]\tvalid_0's auc: 0.961302\n"
     ]
    }
   ],
   "source": [
    "## Попробуем LightGBM\n",
    "\n",
    "train_data  = lgb.Dataset(features_train, label=target_train)\n",
    "test_data = lgb.Dataset(features_test, label=target_test)\n",
    "\n",
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric' : 'auc',\n",
    "    'boosting': 'dart',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "classifier = lgb.train(\n",
    "    parameters,\n",
    "    train_data,\n",
    "    valid_sets=test_data,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=100\n",
    "    \n",
    ")\n",
    "predict = classifier.predict(features_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [1  if el > 0.4 else 0 for el in list(predict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_light = f1_score(target_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score по LightGBM 0.78\n"
     ]
    }
   ],
   "source": [
    "print('F1 score по LightGBM {:.2f}'.format(score_light))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = classifier.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_f1_score\n",
    "pred_test_light =  [1  if el > 0.4 else 0 for el in list(pred_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7985777034093287"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# попробуем LigthGBM на тестовой выборке\n",
    "score_light_test = f1_score(target_test, pred_test_light)\n",
    "score_light_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score на тестовой выборке по LightGBM 0.80\n"
     ]
    }
   ],
   "source": [
    "print('F1 score на тестовой выборке по LightGBM {:.2f}'.format(score_light_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получилось на тестовой выборке немного улучшить показатели логистической регрессии, F1 мера составляет чуть менее 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Conclusion'></a>\n",
    "### 5. Выводы\n",
    "* Зазрузили данные с необработанными комментариями\n",
    "* Провели предобработку текстов: \n",
    "    - убрали знаки пунктуации, стоп-слова, привели к нижнему регистру\n",
    "    - провели лемматизацию\n",
    "    - с помощью if-idf провели векторизацию\n",
    "* Обучили модели Логистической регрессии и LightGBM с различными гиперпараметрами\n",
    "* Добились f1-score на тестовой выборке 0.80  \n",
    "* Проверили модели на токсчичном и нетоксичном предложениях, убедились, что модель адекватно предсказывает \"токсчичность\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f5dd8f20b058ead9365f7e252fda945bb74a615f91a5f6b0a68f63e4f4eb6f7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
