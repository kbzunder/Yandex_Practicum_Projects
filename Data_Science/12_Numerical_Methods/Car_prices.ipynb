{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Проект определения стоимости автомобиля.  \n","Сервис по продаже автомобилей запускает сервис для привлечения новых клиентов. Модель должна расчитвать рыночную стоимость автомобиля в зависимости от технических характеристик и комплектации. \n"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: optuna in /opt/conda/lib/python3.9/site-packages (2.10.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from optuna) (1.21.1)\n","Requirement already satisfied: alembic in /opt/conda/lib/python3.9/site-packages (from optuna) (1.6.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from optuna) (21.3)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from optuna) (6.0)\n","Requirement already satisfied: cliff in /opt/conda/lib/python3.9/site-packages (from optuna) (3.10.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from optuna) (4.61.2)\n","Requirement already satisfied: sqlalchemy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from optuna) (1.4.20)\n","Requirement already satisfied: colorlog in /opt/conda/lib/python3.9/site-packages (from optuna) (6.6.0)\n","Requirement already satisfied: cmaes>=0.8.2 in /opt/conda/lib/python3.9/site-packages (from optuna) (0.8.2)\n","Requirement already satisfied: scipy!=1.4.0 in /opt/conda/lib/python3.9/site-packages (from optuna) (1.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->optuna) (2.4.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n","Requirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.9/site-packages (from alembic->optuna) (1.0.4)\n","Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from alembic->optuna) (2.8.1)\n","Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic->optuna) (1.1.4)\n","Requirement already satisfied: stevedore>=2.0.1 in /opt/conda/lib/python3.9/site-packages (from cliff->optuna) (3.5.0)\n","Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from cliff->optuna) (5.9.0)\n","Requirement already satisfied: autopage>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from cliff->optuna) (0.5.1)\n","Requirement already satisfied: PrettyTable>=0.7.2 in /opt/conda/lib/python3.9/site-packages (from cliff->optuna) (3.3.0)\n","Requirement already satisfied: cmd2>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from cliff->optuna) (2.4.1)\n","Requirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Requirement already satisfied: pyperclip>=1.6 in /opt/conda/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n","Requirement already satisfied: attrs>=16.3.0 in /opt/conda/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.9/site-packages (from Mako->alembic->optuna) (2.0.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil->alembic->optuna) (1.16.0)\n"]}],"source":["! pip install optuna"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":false},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import datetime\n","import time\n","\n","import matplotlib as plt\n","%matplotlib inline\n","import seaborn as sns\n","import plotly.express as px \n","import plotly.graph_objects as go\n","\n","# from pandas_profiling import ProfileReport\n","\n","from scipy import stats as st\n","import math as mth\n","\n","from sklearn.linear_model import LinearRegression, LassoCV, Ridge\n","from sklearn import set_config\n","from sklearn.utils import shuffle\n","from numpy.random import RandomState\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import mean_squared_error\n","\n","from catboost import Pool, CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","import lightgbm as lgb\n","import optuna\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","pd.set_option('display.float_format', '{:.2f}'.format)"]},{"cell_type":"markdown","metadata":{},"source":["[1. Загрузка данных](#data_download)  \n","[2. Знакомство в с данными. Предобработка](#data_preprocessing)  \n","[3. Выбор моделей обучения](#model_celection)  \n","[4. Линейные регрессии](#regressions)  \n","[5. Градиентный бустинг](#gradient_boosting)  \n","[5.1 LightGBM](#light_gbm)  \n","[5.2 CatBoost](#my_model)  \n","[6. Меняем гиперпараметры](#hyperparameters)  \n","[7. Выводы](#Conclusion)  \n"]},{"cell_type":"markdown","metadata":{},"source":["<a id='data_download'></a>\n","### 1. Загрузка данных\n"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":false},"outputs":[],"source":["# загрузим данные\n","try: \n","    data = pd.read_csv('/Users/ulia/Downloads/autos.csv')\n","except FileNotFoundError:\n","    data = pd.read_csv('/datasets/autos.csv')\n","\n","\n","    "]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DateCrawled</th>\n","      <th>Price</th>\n","      <th>VehicleType</th>\n","      <th>RegistrationYear</th>\n","      <th>Gearbox</th>\n","      <th>Power</th>\n","      <th>Model</th>\n","      <th>Kilometer</th>\n","      <th>RegistrationMonth</th>\n","      <th>FuelType</th>\n","      <th>Brand</th>\n","      <th>NotRepaired</th>\n","      <th>DateCreated</th>\n","      <th>NumberOfPictures</th>\n","      <th>PostalCode</th>\n","      <th>LastSeen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2016-03-24 11:52:17</td>\n","      <td>480</td>\n","      <td>NaN</td>\n","      <td>1993</td>\n","      <td>manual</td>\n","      <td>0</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>0</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>NaN</td>\n","      <td>2016-03-24 00:00:00</td>\n","      <td>0</td>\n","      <td>70435</td>\n","      <td>2016-04-07 03:16:57</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2016-03-24 10:58:45</td>\n","      <td>18300</td>\n","      <td>coupe</td>\n","      <td>2011</td>\n","      <td>manual</td>\n","      <td>190</td>\n","      <td>NaN</td>\n","      <td>125000</td>\n","      <td>5</td>\n","      <td>gasoline</td>\n","      <td>audi</td>\n","      <td>yes</td>\n","      <td>2016-03-24 00:00:00</td>\n","      <td>0</td>\n","      <td>66954</td>\n","      <td>2016-04-07 01:46:50</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2016-03-14 12:52:21</td>\n","      <td>9800</td>\n","      <td>suv</td>\n","      <td>2004</td>\n","      <td>auto</td>\n","      <td>163</td>\n","      <td>grand</td>\n","      <td>125000</td>\n","      <td>8</td>\n","      <td>gasoline</td>\n","      <td>jeep</td>\n","      <td>NaN</td>\n","      <td>2016-03-14 00:00:00</td>\n","      <td>0</td>\n","      <td>90480</td>\n","      <td>2016-04-05 12:47:46</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2016-03-17 16:54:04</td>\n","      <td>1500</td>\n","      <td>small</td>\n","      <td>2001</td>\n","      <td>manual</td>\n","      <td>75</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>6</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>no</td>\n","      <td>2016-03-17 00:00:00</td>\n","      <td>0</td>\n","      <td>91074</td>\n","      <td>2016-03-17 17:40:17</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2016-03-31 17:25:20</td>\n","      <td>3600</td>\n","      <td>small</td>\n","      <td>2008</td>\n","      <td>manual</td>\n","      <td>69</td>\n","      <td>fabia</td>\n","      <td>90000</td>\n","      <td>7</td>\n","      <td>gasoline</td>\n","      <td>skoda</td>\n","      <td>no</td>\n","      <td>2016-03-31 00:00:00</td>\n","      <td>0</td>\n","      <td>60437</td>\n","      <td>2016-04-06 10:17:21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n","0  2016-03-24 11:52:17    480         NaN              1993  manual      0   \n","1  2016-03-24 10:58:45  18300       coupe              2011  manual    190   \n","2  2016-03-14 12:52:21   9800         suv              2004    auto    163   \n","3  2016-03-17 16:54:04   1500       small              2001  manual     75   \n","4  2016-03-31 17:25:20   3600       small              2008  manual     69   \n","\n","   Model  Kilometer  RegistrationMonth  FuelType       Brand NotRepaired  \\\n","0   golf     150000                  0    petrol  volkswagen         NaN   \n","1    NaN     125000                  5  gasoline        audi         yes   \n","2  grand     125000                  8  gasoline        jeep         NaN   \n","3   golf     150000                  6    petrol  volkswagen          no   \n","4  fabia      90000                  7  gasoline       skoda          no   \n","\n","           DateCreated  NumberOfPictures  PostalCode             LastSeen  \n","0  2016-03-24 00:00:00                 0       70435  2016-04-07 03:16:57  \n","1  2016-03-24 00:00:00                 0       66954  2016-04-07 01:46:50  \n","2  2016-03-14 00:00:00                 0       90480  2016-04-05 12:47:46  \n","3  2016-03-17 00:00:00                 0       91074  2016-03-17 17:40:17  \n","4  2016-03-31 00:00:00                 0       60437  2016-04-06 10:17:21  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{},"source":["<a id='#data_preprocessing'></a>\n","### 2. Знакомство в с данными. Предобработка"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 354369 entries, 0 to 354368\n","Data columns (total 16 columns):\n"," #   Column             Non-Null Count   Dtype \n","---  ------             --------------   ----- \n"," 0   DateCrawled        354369 non-null  object\n"," 1   Price              354369 non-null  int64 \n"," 2   VehicleType        316879 non-null  object\n"," 3   RegistrationYear   354369 non-null  int64 \n"," 4   Gearbox            334536 non-null  object\n"," 5   Power              354369 non-null  int64 \n"," 6   Model              334664 non-null  object\n"," 7   Kilometer          354369 non-null  int64 \n"," 8   RegistrationMonth  354369 non-null  int64 \n"," 9   FuelType           321474 non-null  object\n"," 10  Brand              354369 non-null  object\n"," 11  NotRepaired        283215 non-null  object\n"," 12  DateCreated        354369 non-null  object\n"," 13  NumberOfPictures   354369 non-null  int64 \n"," 14  PostalCode         354369 non-null  int64 \n"," 15  LastSeen           354369 non-null  object\n","dtypes: int64(7), object(9)\n","memory usage: 43.3+ MB\n"]}],"source":["# получим общиее представление о датасете:\n","data.info()"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["DateCrawled              0\n","Price                    0\n","RegistrationYear         0\n","Power                    0\n","Kilometer                0\n","RegistrationMonth        0\n","Brand                    0\n","DateCreated              0\n","NumberOfPictures         0\n","PostalCode               0\n","LastSeen                 0\n","Model                19705\n","Gearbox              19833\n","FuelType             32895\n","VehicleType          37490\n","NotRepaired          71154\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data.isnull().sum().sort_values()"]},{"cell_type":"code","execution_count":10,"metadata":{"scrolled":true,"trusted":false},"outputs":[],"source":["# ProfileReport(data)"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":false},"outputs":[],"source":["# Видим, что в данных есть пропуски в столбцах VehicleType, Gearbox, Model, FuelType, NotRepaired\n","# необходимо проверить на дубликаты, в том числе скрытые"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Посмотрим минимальные и максимальные даты в столбцах DateCrawled, RegistrationYear"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["(2016, 2016)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# DataCrawled\n","(pd.to_datetime(data.DateCrawled).dt.year.min(),pd.to_datetime(data.DateCrawled).dt.year.max())"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["(1000, 9999)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# RegistrationYear\n","(data.RegistrationYear.min(), data.RegistrationYear.max())"]},{"cell_type":"markdown","metadata":{},"source":["Для оценки предполагаемой сотимости автомобиля считаю столбцы DateCrawled, DateCreated, LastSeen, PostalCode нерелевантными, думаю для упрощения модели их можно удалить \n","Удалим также столбец NumberOfPictures - в нем одни нули \n"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":false},"outputs":[],"source":["data = data.drop(['DateCrawled', 'DateCreated', 'LastSeen', 'PostalCode','NumberOfPictures'], axis=1)"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","      <th>VehicleType</th>\n","      <th>RegistrationYear</th>\n","      <th>Gearbox</th>\n","      <th>Power</th>\n","      <th>Model</th>\n","      <th>Kilometer</th>\n","      <th>RegistrationMonth</th>\n","      <th>FuelType</th>\n","      <th>Brand</th>\n","      <th>NotRepaired</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>480</td>\n","      <td>NaN</td>\n","      <td>1993</td>\n","      <td>manual</td>\n","      <td>0</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>0</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18300</td>\n","      <td>coupe</td>\n","      <td>2011</td>\n","      <td>manual</td>\n","      <td>190</td>\n","      <td>NaN</td>\n","      <td>125000</td>\n","      <td>5</td>\n","      <td>gasoline</td>\n","      <td>audi</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9800</td>\n","      <td>suv</td>\n","      <td>2004</td>\n","      <td>auto</td>\n","      <td>163</td>\n","      <td>grand</td>\n","      <td>125000</td>\n","      <td>8</td>\n","      <td>gasoline</td>\n","      <td>jeep</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1500</td>\n","      <td>small</td>\n","      <td>2001</td>\n","      <td>manual</td>\n","      <td>75</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>6</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3600</td>\n","      <td>small</td>\n","      <td>2008</td>\n","      <td>manual</td>\n","      <td>69</td>\n","      <td>fabia</td>\n","      <td>90000</td>\n","      <td>7</td>\n","      <td>gasoline</td>\n","      <td>skoda</td>\n","      <td>no</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Price VehicleType  RegistrationYear Gearbox  Power  Model  Kilometer  \\\n","0    480         NaN              1993  manual      0   golf     150000   \n","1  18300       coupe              2011  manual    190    NaN     125000   \n","2   9800         suv              2004    auto    163  grand     125000   \n","3   1500       small              2001  manual     75   golf     150000   \n","4   3600       small              2008  manual     69  fabia      90000   \n","\n","   RegistrationMonth  FuelType       Brand NotRepaired  \n","0                  0    petrol  volkswagen         NaN  \n","1                  5  gasoline        audi         yes  \n","2                  8  gasoline        jeep         NaN  \n","3                  6    petrol  volkswagen          no  \n","4                  7  gasoline       skoda          no  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["27543"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# проверим на дубликаты\n","data.duplicated().sum()"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":false},"outputs":[],"source":["data = data.drop_duplicates()"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","      <th>RegistrationYear</th>\n","      <th>Power</th>\n","      <th>Kilometer</th>\n","      <th>RegistrationMonth</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>326826.00</td>\n","      <td>326826.00</td>\n","      <td>326826.00</td>\n","      <td>326826.00</td>\n","      <td>326826.00</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>4403.75</td>\n","      <td>2004.23</td>\n","      <td>110.24</td>\n","      <td>128144.07</td>\n","      <td>5.70</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>4518.21</td>\n","      <td>91.12</td>\n","      <td>195.89</td>\n","      <td>37947.66</td>\n","      <td>3.72</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.00</td>\n","      <td>1000.00</td>\n","      <td>0.00</td>\n","      <td>5000.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1000.00</td>\n","      <td>1999.00</td>\n","      <td>69.00</td>\n","      <td>125000.00</td>\n","      <td>3.00</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2700.00</td>\n","      <td>2003.00</td>\n","      <td>105.00</td>\n","      <td>150000.00</td>\n","      <td>6.00</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6350.00</td>\n","      <td>2008.00</td>\n","      <td>141.00</td>\n","      <td>150000.00</td>\n","      <td>9.00</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>20000.00</td>\n","      <td>9999.00</td>\n","      <td>20000.00</td>\n","      <td>150000.00</td>\n","      <td>12.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Price  RegistrationYear     Power  Kilometer  RegistrationMonth\n","count 326826.00         326826.00 326826.00  326826.00          326826.00\n","mean    4403.75           2004.23    110.24  128144.07               5.70\n","std     4518.21             91.12    195.89   37947.66               3.72\n","min        0.00           1000.00      0.00    5000.00               0.00\n","25%     1000.00           1999.00     69.00  125000.00               3.00\n","50%     2700.00           2003.00    105.00  150000.00               6.00\n","75%     6350.00           2008.00    141.00  150000.00               9.00\n","max    20000.00           9999.00  20000.00  150000.00              12.00"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["data.describe()"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["Text(0.5, 1.0, 'Распределение данных по годам')"]},"execution_count":13,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["sns.distplot(data.query('RegistrationYear > 1980 and RegistrationYear < 2030')\\\n","    .RegistrationYear).set_title('Распределение данных по годам')"]},{"cell_type":"markdown","metadata":{},"source":["Видим явно ошибочные значения в столбце RegistrationYear, оставим строки, где значения этого признака в промежутке от 1990 до 2016 (данные просканированы в 2016 году)"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":false},"outputs":[],"source":["data = data.query('RegistrationYear >=1990 and RegistrationYear <=2016')"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["0    0.10\n","1    0.07\n","2    0.06\n","3    0.10\n","4    0.08\n","5    0.08\n","6    0.09\n","7    0.08\n","8    0.06\n","9    0.07\n","10   0.07\n","11   0.07\n","12   0.07\n","Name: RegistrationMonth, dtype: float64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["data.RegistrationMonth.value_counts(normalize=True).sort_index()"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["<AxesSubplot:xlabel='RegistrationMonth', ylabel='Density'>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA9ZklEQVR4nO3dd3hcZ5X48e9R712WbTU3ufe4JHF6TwhxsgGSQIBdSshClmVZdhd298ezjV1YttFDgFBTCAQnITjVJHEc9265y7Isq1nN6l1zfn/MjDOW7miKNJbsnM/z6NHMbXrV7rlvO6+oKsYYY8xQUeNdAGOMMROTBQhjjDGOLEAYY4xxZAHCGGOMIwsQxhhjHMWMdwHGUk5Ojk6bNm28i2GMMReNXbt2NapqrtO+SypATJs2jZ07d453MYwx5qIhIqf87bMmJmOMMY4sQBhjjHFkAcIYY4wjCxDGGGMcWYAwxhjjyAKEMcYYRxYgjDHGOLIAYYwxxpEFCGOMMY4iOpNaRG4DvgVEAz9W1a/7OW4lsBW4T1V/G8q5ZuJ5clvlsG0fXl00DiUxxoxGxGoQIhINfA+4HZgPPCAi8/0c9w3glVDPNcYYEzmRrEGsAspUtRxARJ4G1gKHhhz3F8CzwMowzp2QnJ6gwZ6ijTEXl0j2QeQDp33eV3m2nSMi+cA9wKOhnmuMMSayIhkgxGGbDnn/f8DfqepgGOe6DxR5SER2isjOhoaG0EtpjDHGUSSbmKqAQp/3BUDNkGNWAE+LCEAOcIeIDAR5LgCq+hjwGMCKFSscg4gxxpjQRTJA7ABKRGQ6UA3cD3zY9wBVne59LSI/A15U1edEJCbQucYYYyIrYgFCVQdE5BHco5OigcdV9aCIPOzZP7TfIeC5kSqrMcaY4SI6D0JV1wPrh2xzDAyq+qeBzjXGGHPh2ExqY4wxjixAGGOMcWQBwhhjjCMLEMYYYxxZgDDGGOPIAoQxxhhHFiCMMcY4sgBhjDHGUUQnyhlj3GwRJXMxshqEMcYYRxYgjDHGOLIAYYwxxpEFCGOMMY4sQBhjjHFkAcIYY4wjCxDGGGMcWYAwxhjjKKIBQkRuE5GjIlImIl922L9WRPaLyF4R2SkiV/nsqxCRA959kSynMcaY4SI2k1pEooHvATcDVcAOEXlBVQ/5HLYBeEFVVUQWA88Ac332X6+qjZEqozHGGP8iWYNYBZSparmq9gFPA2t9D1DVDlVVz9tkQDHGGDMhRDIXUz5w2ud9FbB66EEicg/wH8Ak4H0+uxR4VUQU+KGqPub0RUTkIeAhgKIiy21zqXLKZQSWz8iYSIpkDUIctg2rIajqOlWdC9wN/KvPrjWquhy4HficiFzj9EVU9TFVXaGqK3Jzc8eg2MYYYyCyNYgqoNDnfQFQ4+9gVd0oIjNFJEdVG1W1xrO9XkTW4W6y2hjB8pr3GKuVGDOySNYgdgAlIjJdROKA+4EXfA8QkVkiIp7Xy4E4oElEkkUk1bM9GbgFKI1gWY0xxgwRsRqEqg6IyCPAK0A08LiqHhSRhz37HwXuBT4mIv1AN3CfZ0RTHrDOEztigCdV9eVIldUYY8xwEV0wSFXXA+uHbHvU5/U3gG84nFcOLIlk2YwxxozMZlIbY4xxZAHCGGOMIwsQxhhjHFmAMMYY48gChDHGGEcWIIwxxjiyAGGMMcaRBQhjjDGOLEAYY4xxFNGZ1MaYyHFKNmiJBs1YshqEMcYYRxYgjDHGOLIAYYwxxpEFCGOMMY6sk9oYc1GyTvrIsxqEMcYYRxENECJym4gcFZEyEfmyw/61IrJfRPaKyE4RuSrYc40xxkRWxAKEiEQD3wNuB+YDD4jI/CGHbQCWqOpS4BPAj0M41xhjTARFsgaxCihT1XJV7QOeBtb6HqCqHaqqnrfJgAZ7rjHGmMiKZIDIB077vK/ybDuPiNwjIkeAP+CuRQR9ruf8hzzNUzsbGhrGpODGGGMiGyDEYZsO26C6TlXnAncD/xrKuZ7zH1PVFaq6Ijc3N9yyGmOMGSKSAaIKKPR5XwDU+DtYVTcCM0UkJ9RzjTHGjL1IBogdQImITBeROOB+4AXfA0RkloiI5/VyIA5oCuZcY4wxkRWxiXKqOiAijwCvANHA46p6UEQe9ux/FLgX+JiI9APdwH2eTmvHcyNVVmOMMcNFdCa1qq4H1g/Z9qjP628A3wj2XGOMMReOpdowxpgIckoJAhdHWhBLtWGMMcaR1SCMMcbDEgCezwKEMSbi7MZ7cbImJmOMMY4sQBhjjHFkAcIYY4wj64O4iFg7rjHmQrIahDHGGEcWIIwxxjiyJiZjzDkX86xfM/asBmGMMcaRBQhjjDGOLEAYY4xxZAHCGGOMIwsQxhhjHFmAMMYY4yiiAUJEbhORoyJSJiJfdtj/ERHZ7/nYLCJLfPZViMgBEdkrIjsjWU5jjDHDRWwehIhEA98DbgaqgB0i8oKqHvI57CRwraqeFZHbgceA1T77r1fVxkiV0Vj6DmOMf5GsQawCylS1XFX7gKeBtb4HqOpmVT3rebsVKIhgeYwxxoQgkgEiHzjt877Ks82fTwIv+bxX4FUR2SUiD/k7SUQeEpGdIrKzoaFhVAU2xhjzrkim2hCHbep4oMj1uAPEVT6b16hqjYhMAl4TkSOqunHYBVUfw900xYoVKxyvb4wxJnRB1SBE5FkReZ+IhFLjqAIKfd4XADUO114M/BhYq6pN3u2qWuP5XA+sw91kZYwx5gIJ9ob/A+DDwHER+bqIzA3inB1AiYhMF5E44H7gBd8DRKQI+B3wUVU95rM9WURSva+BW4DSIMtqjDFmDATVxKSqrwOvi0g68ADuJp/TwI+AX6lqv8M5AyLyCPAKEA08rqoHReRhz/5Hga8C2cD3RQRgQFVXAHnAOs+2GOBJVX15dN+qMcaYUATdByEi2cCDwEeBPcATuPsMPg5c53SOqq4H1g/Z9qjP608Bn3I4rxxYMnS7McaYCyeoACEivwPmAr8E3q+qtZ5dv7ZJbMYYc2kKtgbxY09t4BwRiVfVXk+TkDHGmEtMsJ3U/+awbctYFsQYY8zEMmINQkQm457cligiy3h3bkMakBThshljjBlHgZqYbgX+FPcchv/x2d4O/H2EymSMMWYCGDFAqOrPgZ+LyL2q+uwFKpMxxpgJIFAT04Oq+itgmoh8ceh+Vf0fh9OMMcZcAgI1MSV7PqdEuiDGGGMmlkBNTD/0fP7nC1McY4wxE0Wwyfr+U0TSRCRWRDaISKOIPBjpwhljjBk/wc6DuEVV24A7cWdpnQ38TcRKZYwxZtwFGyBiPZ/vAJ5S1eYIlccYY8wEEWyqjd+LyBGgG/isiOQCPZErljHGmPEWVA1CVb8MXAGs8KT27mTI+tLGGGMuLaEsOToP93wI33N+McblMcYYM0EEm+77l8BMYC8w6NmsWIAwxphLVrA1iBXAfFXVUC4uIrcB38K9otyPVfXrQ/Z/BPg7z9sO4M9VdV8w5xpjjImsYEcxlQKTQ7mwiEQD3wNuB+YDD4jI/CGHnQSuVdXFwL8Cj4VwrjHGmAgKtgaRAxwSke1Ar3ejqt41wjmrgDLP8qGIyNO4O7YP+Zy/2ef4rbizxgZ1rjHGmMgKNkD8UxjXzgdO+7yvAlaPcPwngZdCPVdEHgIeAigqKgqjmMYYY5wEFSBU9S0RKQZKVPV1EUnC3TcwEnHY5tiHISLX4w4QV4V6rqo+hqdpasWKFSH1kRhjjPEv2FxMnwZ+C/zQsykfeC7AaVVAoc/7AqDG4dqLgR8Da1W1KZRzjTHGRE6wndSfA9YAbQCqehyYFOCcHUCJiEwXkTjgfuAF3wNEpAj4HfBRVT0WyrnGGGMiK9g+iF5V7RNxt/x4JsuN2JyjqgMi8gjwCu7mqMdV9aCIPOzZ/yjwVSAb+L7n2gOqusLfuaF/e8YYY8IVbIB4S0T+HkgUkZuBzwK/D3SSqq4H1g/Z9qjP608Bnwr2XGOMMRdOsE1MXwYagAPAZ3DfuP8xUoUyxhgz/oIdxeQSkeeA51S1IbJFMsYYMxGMWIMQt38SkUbgCHBURBpE5KsXpnjGGGPGS6Ampi/gHr20UlWzVTUL94S1NSLyV5EunDHGmPETKEB8DHhAVU96N3jSXzzo2WeMMeYSFShAxKpq49CNnn6IWIfjjTHGXCICBYi+MPcZY4y5yAUaxbRERNoctguQEIHyGGOMmSBGDBCqGighnzHGmEtUsBPljDHGvMdYgDDGGOPIAoQxxhhHFiCMMcY4sgBhjDHGkQUIY4wxjixAGGOMcRTRACEit4nIUREpE5EvO+yfKyJbRKRXRL40ZF+FiBwQkb0isjOS5TTGGDNcsCvKhUxEooHvATcDVcAOEXlBVQ/5HNYMfB64289lrnfKBWWMMSbyIlmDWAWUqWq5qvYBTwNrfQ9Q1XpV3QH0R7AcxhhjwhDJAJEPnPZ5X+XZFiwFXhWRXSLy0JiWzBhjTEARa2LCndBvKA3h/DWqWiMik4DXROSIqm4c9kXcweMhgKKiovBKaowxZphI1iCqgEKf9wVATbAnq2qN53M9sA53k5XTcY+p6gpVXZGbmzuK4hpjjPEVyQCxAygRkekiEgfcD7wQzIkikiwiqd7XwC1AacRKaowxZpiINTGp6oCIPAK8AkQDj6vqQRF52LP/URGZDOwE0gCXiHwBmA/kAOtExFvGJ1X15UiV1RhjzHCR7INAVdcD64dse9TndR3upqeh2oAlkSybMcaYkdlMamOMMY4sQBhjjHFkAcJETN+Aa7yLYIwZBQsQEdDdN4hqKFM+Lj17Ks/yz78/yPoDtQwMWqAw5mJkAWKMPbmtkq+tP8Srh86Md1HGTVt3P7/fX0NKfAybyhr57e6q8S6SMSYMFiDG0C+3VPD36w6QGBfDW8caKKvvGO8ijYsX99cwMKh8+poZrJmZTWl1K82dfeNdLGNMiCxAjBFV5afvVLC8KIO/vnk2uSnxPLu7Ctd7rKmpvaefQ7VtXD4jm5yUeJYXZ+JS+MP+oCfRG2MmCAsQY+TomXbKGzv5k+UFJMRGc8PcSbR291N1tnu8i3ZBvVPWhEth7pRUAKakJzI5LYF1e6rHuWTGmFBZgBgj6w/UESVw64LJAJTkpRAlcKSubZxLdmG9ebSe+JgoirOSz21bWpjB7soWKpu6xrFk46N3YJDS6lZqWroZdL23apPm4mcBYoysP1DLqulZ5KbGA5AUF0NRVjJH69rHuWQXjqry5tEGSialEB31bjLf+VPSANhU9t5b++mfXjjInd/ZxHffKOPVg3XjXRxjQmIBYgxUNHZSVt/B7QunnLd93pRUalt7aOl6b3TQHqlrp66th9l5qedtz06JIzs5jp2nmsepZOOjorGTZ3ZWsXbpVOZNSWNLeRNtPbY2lrl4WIAYA3tOnwVg9Yys87bPmey+UR49896oRWwtbwKgZEiAEBEuK85k16mz41GscfPtDceJjRb+4X3zuGPhZFyqbDzWMN7FMiZoFiDGwL7TrSTFRVMy6fwbY25KPKkJMe+ZtvfS6jZyU+NJT4wdtm/FtExONXVR394zqq/R3TfI4do2dp06O+YjxAYGXWM2wbG+vYfn9lbz0cuLmZSaQHZKPMsKM9l+spne/sEx+RrGRJoFiDGw93QLC/PTz2t3B/eTc0FmEqfPvjcCxMGaVhZOTXPcd1mxu3a1qyL8WkTfgIvv/PE4v9x6imd3V41pjaS2tZuvv3yEn26u4OwYzNnYeKwRl8Ldy95dZXdpUQYDLqW8sXPU1zfmQrAAMUp9Ay4O1baxtDDDcX9hZiKNHX10913aT409/YMcr+9gUX664/6F+WnExUSxcxQ39W0nm2jp7uf+lYVMy07m5dK6MZmA19jRy+ObTiIinGzs5J7vvzPq39ebR+vJTY0/10EPUJydRFx0FMfeI02O5uJnAWKUjta10zfgYklBhuP+gswkAKou8VrE4do2Bl3KAj8BIj4mmiUF6WE/9fcNuNh4rIFZuSksLsjgrqVT6R0Y5FuvHxtNsQF440g9Ay7lM1fP4COri6ho6uL3o5jYN+hS3j7eyDUluXgWvQIgJiqKGbnJHDvT/p7P1WUuDhYgRmlvVQsASwqdb4wFmYkIcPoSnzBXWt0K4LcGAbCkIINDtW30h5G8b3flWTr7Brlx3iQAJqclsDA/nRf3145qfkFP/yClNa0sKcggJzWeOXmpzJqUwpPbKsO+5r6qFlq7+7luzvA10mfnpXK2q58mSz1iLgIRDRAicpuIHBWRMhH5ssP+uSKyRUR6ReRLoZw7Uew73UJOShz5GYmO+xNio8lJjb/kaxCl1W1kJccxJT3B7zGLCtLpG3Bx/EzoOaoO17aRkxJPcfa7E/DmT0mjqbOPnRXhD58trW6lf1BZXpwJuPuNHlhVxN7TLRyqCW+S41tHG4gSuGpWzrB93iHAo21mOtvZxxPbTvGdPx6ntduGzprIiFiAEJFo4HvA7bjXmX5AROYPOawZ+DzwX2GcOyEcrWtn3pS085oShirMTOJ0c9cl3axwoLqVBVNH/jl4axcHqltCunZH7wDljZ3MnXz+KLE5eanExUTxysHwM+furjxLTkochZnvBvh7l+cTFxPFMztPh3XN7SebmT81jczkuGH7spLjyEiKpWIUI9tauvq48zubOFLbTlNHHz9+u/w9Pb+iq2+AHhsZFhGRrEGsAspUtVxV+4CngbW+B6hqvaruAIb+dQc8dyIYdCnH69uHTQwbqiAzkc6+QWpaRzfEc6LqHRjk2Jn2EZuXAKZlJ5MSH8MBT3NUsDYdb2DQpefyO3nFx0Zz9awcXjlYF1bwbe/pp6Kpi6WFGecFtoykONbMzOatMOYsDAy62FfVwvKiTL/HFGW5HxjC9dT201S3dPOJq6bziTXTaO3u582j9WFf72LW3tPPtzcc59/XH+a3u05f8oNBLrRIBoh8wPcRrMqzbUzPFZGHRGSniOxsaLiwk5BON3fR0+9iToAAMdXT/FQa4o3xYnG0rp0Bl7IwQICIihIW5qdxoDq0ppsNh+tJiD0/v5PXrQsmU93SzZEwUpqcaHAPN3UK8FeX5HKysTPkG/nRM+109Q2OGCAKM5No7e6ntjX0fqn+QRc/31zBmlnZTM9Jpig7mQVT09h7uuU9t4LfoEt5ansl3f2DLPHk+/rp5pPjXaxLSiQDhFNbQ7CPeUGfq6qPqeoKVV2Rmzu8UzCSvO3IJXkpIx43JT2BKLl0A0Sp54YfqAbhPeZwCB3VqsobRxuYnZc6bJ4JwJoSdzv/Ns8s7lCcaOggITbqXAD3dc1s93VDzR+1u7IFIGANAmCv59hQvFRaR11bD59YM/3ctpXTsujpd1Fac2n+ffmz69RZKpq6uGdZAfcuL2BOXiqPbSyn/T3c3DbWIhkgqoBCn/cFQLBjB0dz7gXzboAYuQYRGx3FpNSESzZAHKhuJS0hhoJM5456X4sKMugbcAXdSXu8voPGjl5KJjkH4fyMRPIzEtkeYke1qnKivoMZOSlEOfSbzMxNYUp6Am8fD61WuueUp08jy//PYkpGAjFRwp7TLSFdG+A3O09TlJXE9XMmnds2PSeZ7OQ4doyis/5itOtUM5PTElhS4H4wuXHeJFq6+vnZOxVj9jX6BlxjnoW3tbuffVUtF8VSvJEMEDuAEhGZLiJxwP3ACxfg3Avm2JkO8jMSSYmPCXjs1IwEDlS3XZId1QdrWlmYnz5iB7XXuY7qquCCpTe/0/Qc/7W01dOz2H6yOaSf7ammLlq6+5nlJ/CICFfNymHT8caQbhC7K8+yrChzxJ9FTJS71rKnMrQ5IR29A2wtb+K2hZOJ8qlNiQjLi92pTBrae0O65oUy6FJ2nTrLzzafpKZl9EO+TzR0cPpsN8uK3u0/KshM4uqSHH698/So/8+aO/v4+eYK/vXFQ3z6FzvH7Gbe2NHLo2+d4Nc7TnP399+hvGFirzoZsQChqgPAI8ArwGHgGVU9KCIPi8jDACIyWUSqgC8C/ygiVSKS5u/cSJU1XMfOtJ9LyBfI1IxEGjt6OdMW3j9wfXsPNS3dEy7A9A+6OFIbuIPaqzgridSE4Duqt5xoIj8jkSyHEUFeq6Zn0djRF1IKi3dOuJuOZub6DzxXleTQ1jPAwSCbbpo6eqlo6hqxecmrMDOR/VWtIc0J2XS8gf5B5Ya5k4bt8/ajhFrjuVB+5UmPUlbfwU82jT5IPLurCgGWDMlg8L5FU6g6283h2vCHEasqv9tdRUVTJ/OnpvHHI/X82x8Oj6q84K6N/GTTSfoHXdyxaAqnm7v5f8+Xjvq6kRTReRCqul5VZ6vqTFX9mmfbo6r6qOd1naoWqGqaqmZ4Xrf5O3ci6R90Ud7QGbD/wSt/FB3VNS3d3P3dd/juG2X87+vHqZtAo6GOnWmnb9Dldwb1UFFRwsKp6UEFCJdL2XaymctnZI943Mrp7jxP208G38SytbyZtIQYclL8B57V07NDuu5eT5PR8qKMgMcWZiXRO+AOrsHacLietIQYLiseHoCmpCeQHBc9Jtlimzp6x7Qd/52yRo6eaefGeZP4q5tmExcTxVPbK3GF2XSjqjy/t4aSvBTSEs5PDHnT/DxE4NVD4a+9cbjWvTrkLfPzeGBVEX+2Zho/21wRco1vKO8EygdWFXHVrBw+e91M3ilrmtBNzzaTOkynmjrpGww8gslrSnoiUULIQzw7egd48CfbaO8Z4LYFk+nuG+C5vdUTpiZxMIQOaq/FBekcqW0POOrmeH0HzZ19XD4kjfpQM3KSyUmJY0eQN3JVZcfJZoqzk0dsCpqcnkBxdlLQAWJ35VliooTFftKu+PJ2VHtTxQficilvHK3n2jmTiI0e/m8bJcKsSSm8fbwx7BsvuIPhf792jP946Qg/2VQ+6vZ3VeWbrxwlPTGWa0tyyU6J57aFk2nq7OPNY+ENzS1v7KS6pZt5U4YnhsxJiWdFcWbYc2NUlZcP1pGbEs8qzwPCX98yh+S4aJ4Yxex6VWXLiSampCcwI8c9Gu+B1UWkxMfww43lYV830ixAhOmYZzZwoDkQXnExUczMTQm6ucLr6e2VlDd08oMHL+Oa2bncumAylc1d7A+yDT/SDlS3khIfQ7HnhheMhfnp9A0G7qj29j8EqkGICKumZ7EtyBt51dlu6tp6mJYzfNjsUKumZbGjojmom+7uUy3Mm5JGYlx0wGPTE2PJS4tnT5AjmQ5Ut9LY0ceNDs1LXiV5qTR19nGoNrwZ4DsqmnlhXzWzJqVw7excTjR0svnE6FYB3Hyiib2nW7hhziRiPIFt4dR00hJieHxTRVjX3HTcXaZZfpoHb10wmcO1bWHNNals7qKxo5drZ+eeGzWXEh/D2mX5vLi/htau8GpWJ5s6qWvr4YoZ2eceStISYvnw6iL+sL9m1GnwI8UCRJiO1rUjgt9OTicL84NrWvEaGHTx03cqWDU9i6s8wzmXF2cyNSOBVw/VjXo9hEGXsv1kMz96u5yntleGlSOptMY9gzrKYQiqP4sLvDOqR/5ZbDnRREFmIoVBBJ9V07KobukOKqWJt0YwLTuI607P4mxXP2UBOhPfnSCXEfCa4A5qywozg2628A639f4dOPGO9NoYRj+EqvIP6w6QkRTHAyuLuGV+HvMmp/L64TOjypj7UmktSXHRLPX5uURHCZfPyGZTWWNYKUfePt5IYVYi2SnxjvtvnJcHENZEx31VrcRECQuGpK3/8KoievpdPLu7KuRrAuw+dZaE2KhhfSZrl07FpfDm0YnZd2QBIkzH69spzkoiITbw06LXwvx0zrT1Bv208PLBOqpbuvnUVe+OeY8S4apZuZzt6qeiaXTrCvzo7XKe21tNe08/pdWt/HxLRUiTrQYGXRyubQs4QW6ooqwk0gJ0VLv7H5oC1h68vP0QwQz13FHh7n/IS/OfN8rL2w8RqHZyboKcQ/+AP8uKMqho6qKpI/DAhXfKGpk7OZUcPzdFgNSEWObkpbLlROhzQraWN3PsTAfXz8klMS4aEeGupfm4FLaEWYtQVV4/VM81JbnDmsVWTMsiSuD3+0IbvT4w6GJreRNXzfI/52ladhL5GYm8E+IcloFBFweqWpg7JY34If/XC/PTWZSfzvMhlhfcD2JH6tqZOzlt2M9h/pQ0Jqcl8MaRiTkT3gJEmI7WBU6xMZR3MZ2DQc4k/uWWUxRnJ517IvKaPyWNuOgo9oUxjt7rdHMX//f6MeZNSeOLN8/hA5cVUN7QeW50TzBONHTS0+9iYb7zIkH+iAiLCtLZ78mE6+RYfTtnu/qDDhBzJ6eRmhATVH/B9opmzw0qcK2nMCuRyWkJ55q7/AlmgtxQyzzH7g3we+zpH2TnqbOOyf+GumJmNjsqmkOeVf2LLRVkJMWe13+SnhjLvClp7AlzlvaB6lbq2nq4eX7esH0p8TGsnJbFKwdD60zeV9VCR+8AV49Qk/IOUd58oimkPpR3TjTR2TfI0gLnB57bFk5m3+kWzrSF1hx0qrmTrr5Bxz4TEeH6uZN4+3jjhJwJbwEiDL0Dg1Q0dQU9xNVrQX46EmRH9Zm2HrZXNHPPsvxhM4jjYqKYPzWNA9Wt9A6El3vm39cfJkqE9y+eArhvVnPyUnmnrJHO3oGgrnEgiBTf/lxWnMWhmja/Sea2nvD2P4zcQe0VHSWsnBa4H6KhvZfyhk5WTgvuuiLCFTOz2XqiacR+iN2nzpKTEh/UZEGvRfnpxEQJuwM0M+2sOEvfgOvcrPGRXDEzm55+V8Cg46u2tZtXD53hvpWFw5/0izPp6htkw+HQO31fP3SGKIHr/fSb3LpgMsfOdHAyhOHJbx9vRASunDnyg8Oakhxau/tDGiH0cmkt8TFRfh/8vIHutUOh/SwO17QRHSXM9tMcfcPcSXT0DkzIiY4WIMJQ3tDJoEsDzqAeKiU+huk5yUH90f5hfy2qcOfiqY77lxZm0NPvCqvtsqmjl1cPneGjVxSTkfTuMM8b5k6iq2+QX209FdR1Sqvda3GPNInNnytnZuNS2F7u/E+xpbyJwqzEcwsuBWPV9CzKGzppHKHJxtvpGugG42vNrByaOvv85nvyjlBZPSMrqMmCXolx0SyYmsaOkyMHiE1ljcRGC6uCCGqXT89GhJA6l//gWVPj/pVFw/bNmpRCWkIMvw4js+2rh86wYlqW3zksty6cDBBSLWLT8UYW5aef93frxPv7DTZVisulbDhcT0le6rnO9KFKJqVQnJ0UUoBQVQ7XtTMzN3lYs5XXmlnZxMVETchmJgsQYfB2rAU7xNXXwqnpQQWIF/fXMHdyqt9O8Jm5KSTGRodcRQf4wwH3DeGeZefnPyzMSmLWpBR+sulkUDNHD9a0Mn9KmmOOpECWFWUQHxPFZof28kHv/Ifpwd/EwT2jGnC8ptfmsibSEmJC6jdZMyvbc13nm015o3uEypqZgZ/wh7p8ZjZ7Tp8dMQvpxmMNLCvKJDmIGfvpSbEsnJo+4s9gqPUHapk/JY3pDqO6okRYVpTJ28cbaekKvrP6dHMXR+raucWheckrPyORRfnpQf8Nt/f0s+d0S1BNbTkp8cybknZuxFMgpTWt1Lf3Mm+EVgER4eZ5eWw50URHkLXsMs9QbafmJa+kuBiWF2UEPQrvQrIAEYZjZ9qJiRLHf6hAFhekU9PaQ/0I7ZjVLd3srmzh/Uucaw/gblKZMzmVN482hDxW/bk91cydnMrcycP/aFdPz6K+vTfgSJj+QRcHa0LvoPaKj4lmxbRMtji07e+saKalq5+rZ4eWfHFxQQbpibF+J4upKpvKGrliZnZIQW1KeiIzcpP9dnpu9mz3BpJQXDEjm/5B9bsUa11rD4dq287LvRTIlTOz2VvZElTq67rWHnZXtnDHosl+j1kwNY1Bl/L64eCfcF/3NEk59T/4unVBHnsqW4Ka/Lm1vJlBl444ksvX1SU57Do1cvA9V15Pc1igh76b5+fRN+jirSBr7t4afqDrrpqWxcGa1qADz4ViASIMR+s6mJ6TTFxM6D++VZ6nXKcbo9cfPOsh3+npH/Bn7uRUmjv7QprhWdnUxe7KFtYudc68PmdyKlnJcfxm58jD+UqrW+nqGwy6Ld/JFTOyOVzbNmwY5UuldcTHRI045t9JdJS7c3LjsQbHiYSVzV1Ut3SzJogn0KHWzMxh20nnzt93ytzpQIpCmAvitXJaFjFRwpZy5+DzhmedB6f0Gv5cPjObvkFXUOt/v1xaC8BtC/3/reVnJDIlPSGk2uprh854mmRGfoi6dcFkz/GBr73peAMJsVGOM8mdrJmVQ9+gK6i2/dcP13NZcSZJAWpplxVnkpkUG1R5Ad48Vs+k1PiATWIrp2fhUndf1kRiASIMwSwS5M8CzyShzWX+A8SL+2tZlJ8e8J9rdl4qMVES0pPd83urAbhrqXPtJCYqiruX5vP64TOcHWH8+1ZP38HqIDuRnVzhaZLxzR/kcikvldZy3ZzcoJpUhrp2di717b2O/QXveH7m4QSIq0py6OobZNvJ839vgy5lS3kTV87MDqn/wSs5PobFBel+h6b+8Ug9+RmJzA4ypQu8G3SC6YdYX1rH7LyUEefziAi3zM9j47EGuvoCP+G2dvWz7WRzwNoDuPs4ZuQkBzXz+e2yRlZNzyY+Jrih5SunZRIXHRWwH6KmpZtDtW3DRgs6iYmO4oa5efzxSH3AeUOdvQPsOHk2qHvFsqJMooRRLZ8bCRYgQtTdN0hlc1fYASI6yj0qxt9w0lNNneyvag1YewD3eterZ2QFPcJEVXlubzWrpmf5XUMb4IMrCugf1HPBxMm2k03MmpQy4rj8QJYWZlCYlcgTW99NYbC78ixn2nq5Y1Hg79/J1Z51HJyamTYcPsNUn1QHobh2di6pCTGs23P+z2R35Vlau/uDbvZwcvmMbPZXDW9e6B0Y5J2yRq6bkxtS8EmJj2FJYUbAfoj69h52VDRz+wi1B69bF0ymd8AVVK6nN47WM+jSoAKEiHDLgslsLW8asY/jdHMX5Q2dXBPCzzkpLoblxRkB+yE2eDqHb5oXXC3t5vl5tPUMBEztsvlEE32DrqDuFSnxMSyYmh5y2vpIswARorL6DlQJ6YluqDWzcqg6202lw7rEL+53V/nfF0SAALhxbh7H6zs4FcSkuYM1bZxo6ORuP81LXvOmpLEwP43f7HJuZhoYdLHjZHPQQ1D9iY4SPn7FNLZXNJ/ruP/p5griYqJCalLxNSXd/bS9YciIkMaOXt481sD7l04N60k/ITaaOxdP4eXSuvOGAT+1rZKU+BhuCuLp058b5k5iwKW8XHp+s8XGY4109Q1yY5A3Ll9XzszmQHXriEn3Xj14BlWCCsarpmeRkRQ7rIxOXjt8htzUeJYEkZMK3P0QA55RRP780fP7DOYp39fVJbkcqm0bcTLi64fOUJydNGJmX1/XzM4hPiaKVwOMZnrjaD1JcdFBzdgHd81vT+XEWhnQAkSIjnpGMM0OcQ6Erys9TStDaxGqyro91Swrygh6eKf3xhRMM9Nze6qJjZYROyS9PrC8gIM1bRyqGT6pr7Smjc6+waAnsY3kQysLSY6L5tsbjvO73VX8YX8tj1w/i9QhWTpDsXZpPttPNp+XxuGFvTUMupR7lxeEfd0/WV5AV9/gubb4s519vHiglnuW5YfVHOZ1WXEm03OSeWbIUNJfbj1FXlo8V5eEvlLiFTOyGXTpiO3vL5XWMiM3OaiHnZjoKG6al8eGI/Uj3sB6BwZ562gDN82bFHT6lSUFGUxOG7mP449H6pmekxzywBBvc6K/tBudvQNsOdHEjXPzgn5wSIqL4apZObx26IzfpJmDLuXVg2e43icHVSCrpmfSO+AKOaFnJFmACNHxM+3ERUeFlJxuqJm5yUxNT+ClIU9jm8oaKavv4COri4O+VlF2kvuJOUAz06BLeWFfDdfNmRSwwwzcN9m46Ch+s2v4+PdNnj4Db4f7aKQlxPKna6bx6qEzfPGZfSyYmsafXzdzVNd8YFUR8TFR/NRnZbHf7aliUX562E2D4J40VpSVxA/ePEF7Tz9P7aikb8DFg5cH//tyIiJ84LICtp9sPlcTLG/oYOOxBj6yutgxe2sgy4sziYuJYuMx5+aV5s4+tpY3c/vCyUHfGG9dMJn2noERZ5VvLW+mo3cgqOYlr6go4ZYFeWw83uA44qirb4At5U1h1SoX56czJT2B9QdqHfe/fbyRvkEXN80P7do3z8+jusX/uhN7Ks/S2NF7bq5HMC4rdv8/TaR+CAsQITp6pp2Zk1KCfipwIiJ8eHURG481UFb/7h/Yz96pICcljvcvCa39/cZ5eWw/2Uxrt//mhK3lTdS39wZsXvLKTI7j5vl5/G539XnNFC6X8ptdVayensWk1MC5jILxpVvmsO6zV/KZa2fw3Q8vD+uG6CsrOY67l+azbk8V9W09rNtTRWl1G/cuD+5790dE+No9CznZ2Mn7v7OJb75ylKtm5YQ8o97JvcsLiBLOBbWfbDpJbLRw/6rCkU/0IyE2muvn5J6b8zLUi/vdNapQ+nquLskhKW7kuTevHzpDUlz0uVpysG5dMJmefpfjk/47ZU30DbjCChBRUcIdi6aw8Vij4//Hi/trSE+MDXk03o3z3OtO+Js093JpHXHRUVw/J/jaX25qPDNykifUjOqIBggRuU1EjopImYh82WG/iMi3Pfv3i8hyn30VInJARPaKyM5IljMUx890jKr/wcv7lPu454ZwtK6dPx6t58Ori4MepeF10zx3G/ZI2Suf21NNSnxMSO3Zn7l2Bq3d/fx8c8W5bZtPNHGqqYsPrx4+6zZc4pmM9ZXb54U1t8TJJ6+ejssFt33rbf72t/u5fEYWD4xBma8uyeXf/2QRlc1dfGR1EY997LIxKK177YkPrSjkZ5sr+MAPNvPEtko+tKJwVEF47dJ8Gtp7hz3xqypPbqtkYX4aC6YGP48lITaaa2fn8srBM44TKQddyquH6rimJDekJJbgro2mJ8byqkPwWbenioyk0G/iXu9bPIW+QRevD7mZN3b08srBOv5keX7IDyW5qfEsK8zgtcPDy+tdU2LNrOyQm0pXTstiR8XZUa3pMZYiFiBEJBr4HnA7MB94QETmDznsdqDE8/EQ8IMh+69X1aWquiJS5QxFe08/1S3do2qm8MpOieeeZfk8u6uKX2yp4BM/20FWUhwfDaO5YmlhJnlp8bzgZ9RRT/8gL5fWcdvCySH94y4uyODGuZP40dsnz+VMemp7JZlJsefGr09Us/NSef6RNRRnJ1EyKZUfPrgi5MDrz4dWFHLwn2/j3+5eRFJc+H0PQ33tnkU8sKqQnafO8umrp/MvaxeO6no3zJ1ESnzMsNFoe063cKSunQ+vCv1v7e5l+TR29J7rNPa18VgDZ9p6uXtZ6DW12Ogobp6fxysH684bXl3b2s0rB915osKZdwSwrDCD/IxEXhiSifXZXVX0DyofCfPB4eb5kymtbqN6yPKpOyrOUnW2O6jRYUOtmJZJa3c/x+snxlrVkaxBrALKVLVcVfuAp4G1Q45ZC/xC3bYCGSIS3vjGCyDURYIC+fyNJczOS+Wrzx+krbufn39iFbmpoQ8bjY4S7llWwBtHGxxTib926AztvQNBNy/5+sJNs2nt7uczv9jFdzYc56XSWj5wWUHIT4jjYd6UNNZ9dg1/+PxVpCeF3+ntJJhFgUIVHSX8+z2L2PzlG/iH980PK4WJr4TYaG5ZkMdLpXXnDaF9clslSXHRfufCjOTGuZPIS4vnye3DV1d7ekclOSlxYY26Avj01TPo6h/ksbffXWHtia2VuFR5MIR+uaFEhA+uKOCtYw3sOuVuvhkYdPHU9kpWTcti1qTw/p/vXDyF6Cjhp5tOnrf9sY0nyEqOGzETgj+rQkhbfyFEMkDkA749nFWebcEeo8CrIrJLRB7y90VE5CER2SkiOxsaIrvohnc1uPlT/edVCcXUjESe/9wafvSxFfz6M1eEnbYC3HMXBl3Kut3nPy2qKj/edJJp2UlcEUKCOq9FBen89weXsLvyLP/92jFuXTCZv7p5dtjlHA/hDGsdLyLC1BHmqITqo5cX09E7wDdfPgLAtvImnt1dxYdWFJISxsirmOgo7ltRyFvHGs5bsa2hvZcNh+u5d3lB2H1Icyan8v7FU/nZOxXUt/dQ2dTFE9tOcePcvKAWjRrJp6+eQV5aPP/y+0O4XO5lUCuauviEz1oroSrMSuLupfn8cuupc6lzyurbef1wPR+9vDish4iirCQmpca/JwKE03/l0Ia1kY5Zo6rLcTdDfU5ErnH6Iqr6mKquUNUVubmhDwcMxYGqVrKT45iaPjads+DuRLt5ft6og87M3BSWF2XwzM7T57Vf7jx1ln2nW/jk1TPCfiK997ICnn9kDf973xK+/5HlY9qsYiJrWVEmH79iGj/fcopvbzjOF5/ZR3FWEn9z65ywr3nfqiIE+PaG4+e2ff/NMgZcygdXhNep7vWFm0oYcLm441tv84FHN6PAl24d/QNJcnwMf3fbXPZVtXLdf73JDzeW89HLi7kthFFGTj5/4ywGXMrXXzpCS1cfX33+IAmxUXzsivBqPCLCyulZQa+vHmmRDBBVgO9fSwEwdDkmv8eoqvdzPbAOd5PVuDpQ3crC/PQJ+0T68SuncaKhkyc81X9V5ftvlJGZFMsHRjH+H9wL8tyzrGDCfu/Gv7+5dQ5z8lL5n9eO0dLVx//et3RU8zbyMxL58+tm8ptdVazbU8Vrh87w03cq+PgVxSEtwetkRm4Kz/75lczwpJB/+qHLHZNKhuPupfl87Z6FlExK4c7FU/h/dw7tEg1dcXYyn7p6Or/bU82qr21g28lm/uWuhX6XQw3GyuJMalp7glo+N9Ii+Si4AygRkelANXA/8OEhx7wAPCIiTwOrgVZVrRWRZCBKVds9r28B/iWCZQ2ou2+Q4/Udo5oxG2l3LZnKb3dV8fX1h7msKJNXDtbxxtEGvnL73Ii0mZuLQ3J8DOv/8mo6egaIi4kak7+FL9w0m80nmvirX+8D3NlKv3LHvFFfF9yDI555+AoGXTrqfhhfUVHCR1YXhzTPKBhfuX0eq6dn8ZNNJ3nomplcG2IW4qG8y+furDgb0nookRCxAKGqAyLyCPAKEA08rqoHReRhz/5HgfXAHUAZ0AX8mef0PGCd52k1BnhSVV+OVFmDcai2jUGXssjPcoQTgYi7k/PW/9vIHd9+G4APrSjgoWtmjHPJzHiLjpIx7aiPjY7iJx9fye/31eBS93yKsR64MJbBIdJumJvHDXPH5uFx7uQ0UuNj2F7RHNaIsLEU0cZkVV2POwj4bnvU57UCn3M4rxxYEsmyhap0FMtrXkiFWUm88oVrPGvcDvLg5cXWLGQiIis5jo9fOW28i3HJiY4SlhdnToh+COttDNKB6lZyUuKYMoYd1JFSmJU0phPZjDEX1qrpWXzzlaOc7ewj08+SrReCpdoI0p7KsyyawB3UxphLx+ogFha7ECxABKG+vYcTDZ2sHoPspcYYE8jSwgxSE2KCXto0UixABGGbZ/W0sUhvbYwxgcRER3F1SQ5v+Vk+90KxABGELeVNpMTHsHCMZlAbY0wg15TkUtfWM655mSxABGFreRMrp2WOKsW3McaE4hrPfIrxbGayO14AZ9p6KG/oDCuPkTHGhGtqhnf53ODWnI8ECxABeBdpv2JG+IvSG2NMOG5fOIVtJ5s50zY8S/OFYAEigD8cqCU/I5GF+db/YIy5sO5aOhVV+P2+oWnsLgwLECNo6epj0/FG7lw8xeY/GGMuuJm5KSzKT7cAMRG9crCOAZdy5+LQF/4wxpixcNeSqeyrauVEw4UfzWQBYgS/31dLUVaSNS8ZY8bN2mVTiYuJ4idDVq67ECxA+FFa3cqmskY+eJmtgWCMGT+TUhP4wGUF/HZn1bmV6y4UCxB+fPePZaTGx/Axy1ZpjBlnn7lmBgMuFz/yWa/7QrAA4eBQTRsvH6zjz9ZMIz1xbBe7N8aYUBVnJ3P3snx+trmCQzVtF+zrWoAYoqtvgC/8eg9ZyXH82ZrwFzQ3xpix9I/vm096YhxffGYvvQODF+RrWoDwMTDo4iu/O8Dx+g7+776l45qH3RhjfGUlx/GNexdxpK6dP//Vbnr6Ix8kIhogROQ2ETkqImUi8mWH/SIi3/bs3y8iy4M9d6zVtHTz8Z9u5/m9Nfz1zbPP5UExxpiJ4sZ5efzb3Qt542g9D/xoKwdrWiP69SK2opyIRAPfA24GqoAdIvKCqh7yOex2oMTzsRr4AbA6yHPHREfvAF99vpQX9tYQJcJ/fmAxH1pRONZfxhhjxsSDlxeTkRTL/3uulDu/s4krZ2Zz+8Ip3LeykNgxTigayRrEKqBMVctVtQ94Glg75Ji1wC/UbSuQISJTgjx3TCTFRnOioZMHLy9mw19fa8HBGDPh3bl4Km9+6Xr+4oYSalt6ePStE8REjf1wfInUYhQi8gHgNlX9lOf9R4HVqvqIzzEvAl9X1U2e9xuAvwOmBTrX5xoPAQ953s4BjkbkGwpNDtA43oUI0cVWZitvZFl5I2+ilLlYVR3b1CPWxAQ4hbOh0cjfMcGc696o+hjwWGhFiywR2amqK8a7HKG42Mps5Y0sK2/kXQxljmSAqAJ822sKgKEZp/wdExfEucYYYyIokn0QO4ASEZkuInHA/cALQ455AfiYZzTT5UCrqtYGea4xxpgIilgNQlUHROQR4BUgGnhcVQ+KyMOe/Y8C64E7gDKgC/izkc6NVFkjYEI1eQXpYiuzlTeyrLyRN+HLHLFOamOMMRc3m0ltjDHGkQUIY4wxjixAjLELnSJkNESkUETeEJHDInJQRP5yvMsUDBGJFpE9nnk0E56IZIjIb0XkiOdnfcV4l2kkIvJXnr+HUhF5SkQSxrtMvkTkcRGpF5FSn21ZIvKaiBz3fM4czzL68lPeb3r+HvaLyDoRyRjHIvplAWIM+aQIuR2YDzwgIvPHt1QjGgD+WlXnAZcDn5vg5fX6S+DweBciBN8CXlbVucASJnDZRSQf+DywQlUX4h4kcv/4lmqYnwG3Ddn2ZWCDqpYAGzzvJ4qfMby8rwELVXUxcAz4yoUuVDAsQIytC5YiZCyoaq2q7va8bsd948of31KNTEQKgPcBPx7vsgRDRNKAa4CfAKhqn6q2jGuhAosBEkUkBkhigs1BUtWNQPOQzWuBn3te/xy4+0KWaSRO5VXVV1V1wPN2K+65XhOOBYixlQ+c9nlfxQS/4XqJyDRgGbBtnIsSyP8Bfwu4xrkcwZoBNAA/9TSL/VhEkse7UP6oajXwX0AlUIt7btKr41uqoOR55lDh+TxpnMsTik8AL413IZxYgBhbQacImUhEJAV4FviCql645apCJCJ3AvWqumu8yxKCGGA58ANVXQZ0MrGaP87jabtfC0wHpgLJIvLg+Jbq0iUi/4C7qfeJ8S6LEwsQYyuY9CITiojE4g4OT6jq78a7PAGsAe4SkQrczXc3iMivxrdIAVUBVarqrZn9FnfAmKhuAk6qaoOq9gO/A64c5zIF44wnEzSez/XjXJ6AROTjwJ3AR3SCTkizADG2LqoUISIiuNvGD6vq/4x3eQJR1a+oaoGqTsP9s/2jqk7op1tVrQNOi8gcz6YbgTFf12QMVQKXi0iS5+/jRiZwp7qPF4CPe15/HHh+HMsSkIjchjtz9V2q2jXe5fHHAsQY8nQ6eVOEHAaemeApQtYAH8X9JL7X83HHeBfqEvQXwBMish9YCvz7+BbHP09N57fAbuAA7nvEhEoJISJPAVuAOSJSJSKfBL4O3Cwix3EvNPb18SyjLz/l/S6QCrzm+b97dFwL6Yel2jDGGOPIahDGGGMcWYAwxhjjyAKEMcYYRxYgjDHGOLIAYYwxxpEFCHPREZFBz9DAUhH5fbiZMEVkqoj8doT9GSLy2TCv/fdD3m8O5zqec98UkUrPvATvtudEpGMU1/yCiCT5vA/7WubSZQHCXIy6VXWpJ9toM/C5cC6iqjWq+oERDskAHAOEJ3PvSM4LEKo62tnILbjnreAJiFNGeb0v4E7EZ4xfFiDMxW4LnoSIIjJTRF4WkV0i8raIzPXZvlVEdojIv3iflkVkmjdHv4gsEJHtnprJfhEpwT3ZaqZn2zdF5DrP+hlP4p5E5n2S3+VZP+Ehz7av486GuldEnvBs835N8VyrVEQOiMh9nu3XeWoK3nUjnvCtMeBOLeJNu/0nuFNgEM41ReTzuPMsvSEib/hc52siss/zs8obw9+RuVipqn3Yx0X1AXR4PkcDvwFu87zfAJR4Xq/GnYoD4EXgAc/rh33OnwaUel5/B3dOHIA4INF3v2f7dbiT7U332Zbl+ZwIlALZvmV0KPO9uNcCiAbycKe2mOK5divu/F1RuAPfVZ5z3vR8P/s9573qKdtorlkB5PiUT4H3e17/J/CP4/17to/x/7AahLkYJYrIXqAJyMKdriAFd1K533j2/ZB3m2GuwB1IAJ70c80twN+LyN8Bxara7ee47ap60uf950VkH+6c/oVASYCyXwU8paqDqnoGeAtY6XPtKlV1AXtxBwGvQWATcB+QqKoVY3BNX324AynArhGOM+8hFiDMxahbVZcCxbif9j+H+2+5Rd19E96PecFeUFWfBO4CuoFXROQGP4d2el+IyHW4s59eoapLgD1AoOU5nVLCe/X6vB7EnSrc19O4azrPjOE1vfpVVYM4zryHWIAwFy1VbcW9POaXcN/YT4rIB+Fcu/wSz6FbcTfDgJ/lM0VkBlCuqt/GnRl0MdCOO6GaP+nAWVXt8vR3XO6zr1/cqdSH2gjcJ+51tXNxrza3PfB3C8DbwH8AT43BNQN9b8ZYgDAXN1XdA+zDfeP/CPBJT5PPQd5d7vULwBdFZDvuZqdWh0vdB5R6mqfmAr9Q1SbgHU/n7zcdznkZiPFkaf1X3IHI6zFgv7eT2sc63H0J+4A/An+r7pTgwXyvqqr/paqNY3DNx4CXfDupjRnKsrmaS55nvH+3qqqI3I+7w3rCrhVuzERh7YzmveAy4LueYaMtuNcANsYEYDUIY4wxjqwPwhhjjCMLEMYYYxxZgDDGGOPIAoQxxhhHFiCMMcY4+v8jf7c/GDvJGgAAAABJRU5ErkJggg==","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["sns.distplot(data['RegistrationMonth'])\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Очень странно, что месяцев регистрации 13, а не 12, это моджет говорить о разном кодировании дат или об ошибке, когда нулевой месяц указывает на отсутсвие данных. В данном случае нужно было бы задать вопрос поставщику данных. Я предположу, что 0 - это отсутствие данных, остальные месяца (с 1 по 12) распределю на 4 сезона:"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":false},"outputs":[],"source":["def seasons(row):\n","    if row['RegistrationMonth'] in [12,1,2]:\n","        return 'winter'\n","    elif row['RegistrationMonth'] in [3,4,5]:\n","        return 'spring'\n","    elif row['RegistrationMonth'] in [6,7,8]:\n","        return 'summer'\n","    elif row['RegistrationMonth'] in [9,10,11]:\n","        return 'autumn'\n","    else:\n","        return 'no data'       "]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":false},"outputs":[],"source":["data['RegistrationMonth'] = data.apply(seasons, axis=1)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":false},"outputs":[],"source":["data = data.rename(columns={'RegistrationMonth':'RegSeason'})"]},{"cell_type":"code","execution_count":20,"metadata":{"scrolled":true,"trusted":false},"outputs":[{"data":{"text/plain":["Index(['Price', 'VehicleType', 'RegistrationYear', 'Gearbox', 'Power', 'Model',\n","       'Kilometer', 'RegSeason', 'FuelType', 'Brand', 'NotRepaired'],\n","      dtype='object')"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["data.columns"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["Price              0.00\n","RegistrationYear   0.00\n","Power              0.00\n","Kilometer          0.00\n","RegSeason          0.00\n","Brand              0.00\n","Gearbox            0.05\n","Model              0.05\n","VehicleType        0.07\n","FuelType           0.08\n","NotRepaired        0.19\n","dtype: float64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Пропуски по столбцам в процентном отношении\n","data.isna().mean().sort_values()"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":false},"outputs":[],"source":["# petrol и  gasoline обознчим 'petrol', lpg и cng - 'gas'\n","data['FuelType'] = data['FuelType'].replace('gasoline','petrol').replace('lpg','gas').replace('cng','gas')"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["petrol      273951\n","gas           5212\n","hybrid         218\n","other          129\n","electric        86\n","Name: FuelType, dtype: int64"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["data['FuelType'].value_counts()"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","      <th>VehicleType</th>\n","      <th>RegistrationYear</th>\n","      <th>Gearbox</th>\n","      <th>Power</th>\n","      <th>Model</th>\n","      <th>Kilometer</th>\n","      <th>RegSeason</th>\n","      <th>FuelType</th>\n","      <th>Brand</th>\n","      <th>NotRepaired</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>480</td>\n","      <td>NaN</td>\n","      <td>1993</td>\n","      <td>manual</td>\n","      <td>0</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>no data</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18300</td>\n","      <td>coupe</td>\n","      <td>2011</td>\n","      <td>manual</td>\n","      <td>190</td>\n","      <td>NaN</td>\n","      <td>125000</td>\n","      <td>spring</td>\n","      <td>petrol</td>\n","      <td>audi</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9800</td>\n","      <td>suv</td>\n","      <td>2004</td>\n","      <td>auto</td>\n","      <td>163</td>\n","      <td>grand</td>\n","      <td>125000</td>\n","      <td>summer</td>\n","      <td>petrol</td>\n","      <td>jeep</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1500</td>\n","      <td>small</td>\n","      <td>2001</td>\n","      <td>manual</td>\n","      <td>75</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>summer</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3600</td>\n","      <td>small</td>\n","      <td>2008</td>\n","      <td>manual</td>\n","      <td>69</td>\n","      <td>fabia</td>\n","      <td>90000</td>\n","      <td>summer</td>\n","      <td>petrol</td>\n","      <td>skoda</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>354364</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>2005</td>\n","      <td>manual</td>\n","      <td>0</td>\n","      <td>colt</td>\n","      <td>150000</td>\n","      <td>summer</td>\n","      <td>petrol</td>\n","      <td>mitsubishi</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>354365</th>\n","      <td>2200</td>\n","      <td>NaN</td>\n","      <td>2005</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>20000</td>\n","      <td>winter</td>\n","      <td>NaN</td>\n","      <td>sonstige_autos</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>354366</th>\n","      <td>1199</td>\n","      <td>convertible</td>\n","      <td>2000</td>\n","      <td>auto</td>\n","      <td>101</td>\n","      <td>fortwo</td>\n","      <td>125000</td>\n","      <td>spring</td>\n","      <td>petrol</td>\n","      <td>smart</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>354367</th>\n","      <td>9200</td>\n","      <td>bus</td>\n","      <td>1996</td>\n","      <td>manual</td>\n","      <td>102</td>\n","      <td>transporter</td>\n","      <td>150000</td>\n","      <td>spring</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>354368</th>\n","      <td>3400</td>\n","      <td>wagon</td>\n","      <td>2002</td>\n","      <td>manual</td>\n","      <td>100</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>summer</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>299481 rows × 11 columns</p>\n","</div>"],"text/plain":["        Price  VehicleType  RegistrationYear Gearbox  Power        Model  \\\n","0         480          NaN              1993  manual      0         golf   \n","1       18300        coupe              2011  manual    190          NaN   \n","2        9800          suv              2004    auto    163        grand   \n","3        1500        small              2001  manual     75         golf   \n","4        3600        small              2008  manual     69        fabia   \n","...       ...          ...               ...     ...    ...          ...   \n","354364      0          NaN              2005  manual      0         colt   \n","354365   2200          NaN              2005     NaN      0          NaN   \n","354366   1199  convertible              2000    auto    101       fortwo   \n","354367   9200          bus              1996  manual    102  transporter   \n","354368   3400        wagon              2002  manual    100         golf   \n","\n","        Kilometer RegSeason FuelType           Brand NotRepaired  \n","0          150000   no data   petrol      volkswagen         NaN  \n","1          125000    spring   petrol            audi         yes  \n","2          125000    summer   petrol            jeep         NaN  \n","3          150000    summer   petrol      volkswagen          no  \n","4           90000    summer   petrol           skoda          no  \n","...           ...       ...      ...             ...         ...  \n","354364     150000    summer   petrol      mitsubishi         yes  \n","354365      20000    winter      NaN  sonstige_autos         NaN  \n","354366     125000    spring   petrol           smart          no  \n","354367     150000    spring   petrol      volkswagen          no  \n","354368     150000    summer   petrol      volkswagen         NaN  \n","\n","[299481 rows x 11 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# После переобозначения проверим на дубликаты и удалим при необходимости\n","data.duplicated().sum()\n","data.drop_duplicates()"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["Price                   0\n","RegistrationYear        0\n","Power                   0\n","Kilometer               0\n","RegSeason               0\n","Brand                   0\n","Gearbox             14383\n","Model               15027\n","VehicleType         20448\n","FuelType            24153\n","NotRepaired         57487\n","dtype: int64"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["data.isna().sum().sort_values()"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":false},"outputs":[],"source":["# пропущенные значения в столбце NotRepaired заполним строкой 'no data'\n","data['NotRepaired'] = data['NotRepaired'].fillna('no data')"]},{"cell_type":"markdown","metadata":{},"source":["Заполним пропуски в столбцах VehicleType  и FuelType так: сгруппируем данные по модели, заполним пропуски наиболее часто встречающимися значениями (mode)"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":false},"outputs":[],"source":["mode_vtypes = dict(data.groupby('Model')['VehicleType'].apply(lambda x: st.mode(x)[0][0]))"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":false},"outputs":[],"source":["mode_fueltypes = dict(data.groupby('Model')['FuelType'].apply(lambda x: st.mode(x)[0][0]))"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":false},"outputs":[],"source":["for key, value in mode_vtypes.items():\n","    data.loc[(data['VehicleType'].isna())&(data['Model']==key),'VehicleType'] = value \n","    "]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":false},"outputs":[],"source":["for key, value in mode_fueltypes.items():\n","    data.loc[(data['FuelType'].isna())&(data['Model']==key),'FuelType'] = value \n","    "]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["Price              0.00\n","RegistrationYear   0.00\n","Power              0.00\n","Kilometer          0.00\n","RegSeason          0.00\n","Brand              0.00\n","NotRepaired        0.00\n","VehicleType        0.01\n","FuelType           0.02\n","Gearbox            0.05\n","Model              0.05\n","dtype: float64"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["data.isna().mean().sort_values()"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>Model</th>\n","    </tr>\n","    <tr>\n","      <th>Brand</th>\n","      <th>VehicleType</th>\n","      <th>RegistrationYear</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">alfa_romeo</th>\n","      <th rowspan=\"5\" valign=\"top\">convertible</th>\n","      <th>1990</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1991</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1992</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1993</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1995</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <th>...</th>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">volvo</th>\n","      <th rowspan=\"5\" valign=\"top\">wagon</th>\n","      <th>2011</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2012</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2013</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2014</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2016</th>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4979 rows × 1 columns</p>\n","</div>"],"text/plain":["                                         Model\n","Brand      VehicleType RegistrationYear       \n","alfa_romeo convertible 1990                  1\n","                       1991                  1\n","                       1992                  1\n","                       1993                  1\n","                       1995                  1\n","...                                        ...\n","volvo      wagon       2011                  4\n","                       2012                  4\n","                       2013                  2\n","                       2014                  1\n","                       2016                  4\n","\n","[4979 rows x 1 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["data.groupby(['Brand','VehicleType','RegistrationYear']).agg({'Model':'nunique'})"]},{"cell_type":"markdown","metadata":{},"source":["Видим, что заполнить модели по данным производителя, типа машины и года выпуска не получится, нет однозначного соответствия, так как модель очень сильно влияент на цену, лучше пропуски удалить, чем пытаться их заполнить. И поскольку пропуски в каждом столбце не превышают 5%, считаю правильным все оставшиеся с в данных пропуски удалить"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":false},"outputs":[],"source":["data = data.dropna()"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 277023 entries, 0 to 354368\n","Data columns (total 11 columns):\n"," #   Column            Non-Null Count   Dtype \n","---  ------            --------------   ----- \n"," 0   Price             277023 non-null  int64 \n"," 1   VehicleType       277023 non-null  object\n"," 2   RegistrationYear  277023 non-null  int64 \n"," 3   Gearbox           277023 non-null  object\n"," 4   Power             277023 non-null  int64 \n"," 5   Model             277023 non-null  object\n"," 6   Kilometer         277023 non-null  int64 \n"," 7   RegSeason         277023 non-null  object\n"," 8   FuelType          277023 non-null  object\n"," 9   Brand             277023 non-null  object\n"," 10  NotRepaired       277023 non-null  object\n","dtypes: int64(4), object(7)\n","memory usage: 25.4+ MB\n"]}],"source":["data.info()"]},{"cell_type":"markdown","metadata":{},"source":["Рассмотрим столбец Power"]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["count   277023.00\n","mean       116.01\n","std        186.85\n","min          0.00\n","25%         75.00\n","50%        107.00\n","75%        144.00\n","max      20000.00\n","Name: Power, dtype: float64"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["data.Power.describe()"]},{"cell_type":"markdown","metadata":{},"source":["Мощность серийных машин не превышает 1850 лс \n","[ссылка](https://atlanticexpress.com.ua/samye-moshhnye-serijnye-avto-v-mire-ot-1750-l-s/)  \n","\n","Удалим выбросы:"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":false},"outputs":[],"source":["data = data.query('Power<=1850')"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["count   276918.00\n","mean       113.24\n","std         66.62\n","min          0.00\n","25%         75.00\n","50%        107.00\n","75%        144.00\n","max       1800.00\n","Name: Power, dtype: float64"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["data.Power.describe()"]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":false},"outputs":[],"source":["# Нули в столбце Power скорее всего означают пропуски. "]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["54.0"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# У 90 процентов данных мощность выше 54 лс, заменим значения меньшие 54 на медианные по модели\n","data.Power.quantile(0.1)"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":false},"outputs":[],"source":["median_power = dict(data.groupby('Model')['Power'].apply(lambda x: x.median()))"]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":false},"outputs":[],"source":["for key, value in median_power.items():\n","    data.loc[(data['Power']<54)&(data['Model']==key),'Power'] = value "]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["count   276918.00\n","mean       121.24\n","std         59.37\n","min          0.00\n","25%         80.00\n","50%        112.00\n","75%        150.00\n","max       1800.00\n","Name: Power, dtype: float64"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["data.Power.describe()"]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["array(['samara'], dtype=object)"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["data[data['Power']==0]['Model'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["Мощность Lada Samara составляет в основном 70-80 лс [источник Википедия](https://ru.wikipedia.org/wiki/Lada_Samara#:~:text=Lada%20Samara%20%E2%80%94%20%D1%81%D0%B5%D0%BC%D0%B5%D0%B9%D1%81%D1%82%D0%B2%D0%BE%20%D1%81%D0%BE%D0%B2%D0%B5%D1%82%D1%81%D0%BA%D0%B8%D1%85%20%D0%B8,%D1%81%D0%BE%D0%B1%D0%BE%D0%B9%20%D0%B2%D1%82%D0%BE%D1%80%D0%BE%D0%B5%20%D0%BF%D0%BE%D0%BA%D0%BE%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%B0%D0%B2%D1%82%D0%BE%D0%BC%D0%BE%D0%B1%D0%B8%D0%BB%D0%B5%D0%B9%20%D0%92%D0%90%D0%97.)  \n","Заполним занчения равные 0, значением 80 лс"]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":false},"outputs":[],"source":["data.loc[data['Power']==0, 'Power'] = 80"]},{"cell_type":"code","execution_count":44,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["count   276918.00\n","mean       121.24\n","std         59.37\n","min         26.00\n","25%         80.00\n","50%        112.00\n","75%        150.00\n","max       1800.00\n","Name: Power, dtype: float64"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["data.Power.describe()"]},{"cell_type":"markdown","metadata":{},"source":["Завершена предобработка данных:  \n","1) Удалены столбцы, не влияющие на цены  \n","2) Удалены дубликаты  \n","3) Обработаны и заполнены пропуски  \n","#### Данные готовы для обучения"]},{"cell_type":"markdown","metadata":{},"source":["<a id='model_celection'></a>\n","### 3. Выбор моделей обучения. Подготовка данных"]},{"cell_type":"markdown","metadata":{},"source":["Применим модели Линейной Регресси, CatBoost, LightGBM  \n","Линейная регрессия не умеет работать с категориальными переменными. Нужно будет их закодировать."]},{"cell_type":"code","execution_count":45,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","      <th>VehicleType</th>\n","      <th>RegistrationYear</th>\n","      <th>Gearbox</th>\n","      <th>Power</th>\n","      <th>Model</th>\n","      <th>Kilometer</th>\n","      <th>RegSeason</th>\n","      <th>FuelType</th>\n","      <th>Brand</th>\n","      <th>NotRepaired</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>480</td>\n","      <td>sedan</td>\n","      <td>1993</td>\n","      <td>manual</td>\n","      <td>101.00</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>no data</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>no data</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9800</td>\n","      <td>suv</td>\n","      <td>2004</td>\n","      <td>auto</td>\n","      <td>163.00</td>\n","      <td>grand</td>\n","      <td>125000</td>\n","      <td>summer</td>\n","      <td>petrol</td>\n","      <td>jeep</td>\n","      <td>no data</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1500</td>\n","      <td>small</td>\n","      <td>2001</td>\n","      <td>manual</td>\n","      <td>75.00</td>\n","      <td>golf</td>\n","      <td>150000</td>\n","      <td>summer</td>\n","      <td>petrol</td>\n","      <td>volkswagen</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3600</td>\n","      <td>small</td>\n","      <td>2008</td>\n","      <td>manual</td>\n","      <td>69.00</td>\n","      <td>fabia</td>\n","      <td>90000</td>\n","      <td>summer</td>\n","      <td>petrol</td>\n","      <td>skoda</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>650</td>\n","      <td>sedan</td>\n","      <td>1995</td>\n","      <td>manual</td>\n","      <td>102.00</td>\n","      <td>3er</td>\n","      <td>150000</td>\n","      <td>autumn</td>\n","      <td>petrol</td>\n","      <td>bmw</td>\n","      <td>yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Price VehicleType  RegistrationYear Gearbox  Power  Model  Kilometer  \\\n","0    480       sedan              1993  manual 101.00   golf     150000   \n","2   9800         suv              2004    auto 163.00  grand     125000   \n","3   1500       small              2001  manual  75.00   golf     150000   \n","4   3600       small              2008  manual  69.00  fabia      90000   \n","5    650       sedan              1995  manual 102.00    3er     150000   \n","\n","  RegSeason FuelType       Brand NotRepaired  \n","0   no data   petrol  volkswagen     no data  \n","2    summer   petrol        jeep     no data  \n","3    summer   petrol  volkswagen          no  \n","4    summer   petrol       skoda          no  \n","5    autumn   petrol         bmw         yes  "]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":46,"metadata":{"trusted":false},"outputs":[],"source":["# категориальные переменные\n","cat_columns = ['VehicleType','Gearbox','Model','RegSeason','FuelType','RegistrationYear','Brand','NotRepaired']"]},{"cell_type":"code","execution_count":47,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["array([1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n","       2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011,\n","       2012, 2013, 2014, 2015, 2016])"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["data.RegistrationYear.sort_values().unique()"]},{"cell_type":"markdown","metadata":{},"source":["Годы идут без пропусков, можно считать год регистрации категориальным признаком"]},{"cell_type":"code","execution_count":48,"metadata":{"trusted":false},"outputs":[],"source":["# кодируем\n","data_encorded = pd.get_dummies(data, columns = cat_columns, drop_first=True)"]},{"cell_type":"code","execution_count":49,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","      <th>Power</th>\n","      <th>Kilometer</th>\n","      <th>VehicleType_convertible</th>\n","      <th>VehicleType_coupe</th>\n","      <th>VehicleType_other</th>\n","      <th>VehicleType_sedan</th>\n","      <th>VehicleType_small</th>\n","      <th>VehicleType_suv</th>\n","      <th>VehicleType_wagon</th>\n","      <th>...</th>\n","      <th>Brand_skoda</th>\n","      <th>Brand_smart</th>\n","      <th>Brand_subaru</th>\n","      <th>Brand_suzuki</th>\n","      <th>Brand_toyota</th>\n","      <th>Brand_trabant</th>\n","      <th>Brand_volkswagen</th>\n","      <th>Brand_volvo</th>\n","      <th>NotRepaired_no data</th>\n","      <th>NotRepaired_yes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>480</td>\n","      <td>101.00</td>\n","      <td>150000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9800</td>\n","      <td>163.00</td>\n","      <td>125000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1500</td>\n","      <td>75.00</td>\n","      <td>150000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3600</td>\n","      <td>69.00</td>\n","      <td>90000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>650</td>\n","      <td>102.00</td>\n","      <td>150000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 331 columns</p>\n","</div>"],"text/plain":["   Price  Power  Kilometer  VehicleType_convertible  VehicleType_coupe  \\\n","0    480 101.00     150000                        0                  0   \n","2   9800 163.00     125000                        0                  0   \n","3   1500  75.00     150000                        0                  0   \n","4   3600  69.00      90000                        0                  0   \n","5    650 102.00     150000                        0                  0   \n","\n","   VehicleType_other  VehicleType_sedan  VehicleType_small  VehicleType_suv  \\\n","0                  0                  1                  0                0   \n","2                  0                  0                  0                1   \n","3                  0                  0                  1                0   \n","4                  0                  0                  1                0   \n","5                  0                  1                  0                0   \n","\n","   VehicleType_wagon  ...  Brand_skoda  Brand_smart  Brand_subaru  \\\n","0                  0  ...            0            0             0   \n","2                  0  ...            0            0             0   \n","3                  0  ...            0            0             0   \n","4                  0  ...            1            0             0   \n","5                  0  ...            0            0             0   \n","\n","   Brand_suzuki  Brand_toyota  Brand_trabant  Brand_volkswagen  Brand_volvo  \\\n","0             0             0              0                 1            0   \n","2             0             0              0                 0            0   \n","3             0             0              0                 1            0   \n","4             0             0              0                 0            0   \n","5             0             0              0                 0            0   \n","\n","   NotRepaired_no data  NotRepaired_yes  \n","0                    1                0  \n","2                    1                0  \n","3                    0                0  \n","4                    0                0  \n","5                    0                1  \n","\n","[5 rows x 331 columns]"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["data_encorded.head()"]},{"cell_type":"markdown","metadata":{},"source":["Разделим выборки на тренировочную, валидационную и тестовую"]},{"cell_type":"code","execution_count":50,"metadata":{"trusted":false},"outputs":[],"source":["features = data_encorded.drop('Price', axis=1)\n","target = data_encorded['Price']"]},{"cell_type":"code","execution_count":51,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["[276918, 221534, 55384]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["features_train_full, features_test, target_train_full, target_test = train_test_split(features,\\\n","    target, test_size=0.2, random_state = 123123)\n","[data.shape[0], features_train_full.shape[0],features_test.shape[0]]"]},{"cell_type":"code","execution_count":52,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["[221534, 166150, 55384]"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["features_train, features_valid, target_train, target_valid = train_test_split(features_train_full,\\\n","     target_train_full,test_size=0.25, random_state=123123)\n","[features_train_full.shape[0], features_train.shape[0],features_valid.shape[0]]"]},{"cell_type":"code","execution_count":53,"metadata":{"trusted":false},"outputs":[],"source":["#  стандартизируем численные признаки:\n","scaler = StandardScaler()\n","numeric = ['Kilometer','Power']\n","features_train[numeric] = scaler.fit_transform(features_train[numeric])\n","features_valid[numeric] = scaler.transform(features_valid[numeric])\n","features_test[numeric] = scaler.transform(features_test[numeric])"]},{"cell_type":"code","execution_count":54,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["6.29614520072937\n"]}],"source":["# Линейная регрессия\n","start = time.time()\n","model = LinearRegression()\n","model.fit(features_train, target_train)\n","end = time.time()\n","Linear_time = end - start\n","print(Linear_time)"]},{"cell_type":"code","execution_count":55,"metadata":{"trusted":false},"outputs":[],"source":["prediction = model.predict(features_valid)"]},{"cell_type":"code","execution_count":56,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE по линейной регрессии 2160.00\n","RMSE 2160.004565553684\n"]}],"source":["RMSE_reg = np.sqrt(((prediction - target_valid)**2).mean())\n","RMSE_N_reg = mean_squared_error(prediction, target_valid, squared=False)\n","print('RMSE по линейной регрессии {:.2f}'.format(RMSE_reg))\n","print('RMSE' , RMSE_N_reg)"]},{"cell_type":"markdown","metadata":{},"source":["Попробуем Lasso и Ridge"]},{"cell_type":"code","execution_count":57,"metadata":{"trusted":false},"outputs":[],"source":["start = time.time()\n","model = LassoCV(random_state=123)\n","model.fit(features_train, target_train)\n","prediction_lasso = model.predict(features_valid)\n","end = time.time()\n","Lasso_time = end - start"]},{"cell_type":"code","execution_count":58,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE по Lasso  2228.29\n"]}],"source":["RMSE_lasso = mean_squared_error(prediction_lasso, target_valid, squared=False)\n","print('RMSE по Lasso  {:.2f}'.format(RMSE_lasso))"]},{"cell_type":"code","execution_count":59,"metadata":{"trusted":false},"outputs":[],"source":["start = time.time()\n","model = Ridge(random_state=123)\n","model.fit(features_train, target_train)\n","prediction_ridge = model.predict(features_valid)\n","end = time.time()\n","Ridge_time = end - start"]},{"cell_type":"code","execution_count":60,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE по Ridge  2160.45\n"]}],"source":["RMSE_ridge = mean_squared_error(prediction_ridge,target_valid, squared=False)\n","print('RMSE по Ridge  {:.2f}'.format(RMSE_ridge))"]},{"cell_type":"markdown","metadata":{},"source":["Все модели линейной регрессии показали очень хорошие результаты, лучше трешхолда в 2500 "]},{"cell_type":"markdown","metadata":{},"source":["<a id='gradient_boosting'></a>\n","### 5. Градиентный бустинг"]},{"cell_type":"markdown","metadata":{},"source":["<a id='light_gbm'></a>\n","### 5.1 LightGBM"]},{"cell_type":"code","execution_count":61,"metadata":{"trusted":false},"outputs":[],"source":["data[cat_columns] = data[cat_columns].astype('category')\n"]},{"cell_type":"code","execution_count":62,"metadata":{"trusted":false},"outputs":[],"source":["features_light = data.drop('Price', axis=1)\n","target_light = data['Price']"]},{"cell_type":"code","execution_count":63,"metadata":{"trusted":false},"outputs":[],"source":["features_light_train, features_light_test, target_light_train, target_light_test = train_test_split(features_light, target_light,test_size=0.25, random_state=123)"]},{"cell_type":"code","execution_count":64,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["[276918, 221534, 55384]"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["features_light_train_full, features_light_test, target_light_train_full, target_light_test = train_test_split(features_light,\\\n","    target_light, test_size=0.2, random_state = 123123)\n","[data.shape[0], features_train_full.shape[0],features_test.shape[0]]"]},{"cell_type":"code","execution_count":65,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["[221534, 166150, 55384]"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["features_light_train, features_light_valid, target_light_train, target_light_valid = train_test_split(features_light_train_full,\\\n","     target_light_train_full,test_size=0.25, random_state=123123)\n","[features_train_full.shape[0], features_train.shape[0],features_valid.shape[0]]"]},{"cell_type":"code","execution_count":66,"metadata":{"scrolled":true,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["[1]\tvalid_0's rmse: 4258.43\tvalid_0's l2: 1.81342e+07\n","[2]\tvalid_0's rmse: 3958.13\tvalid_0's l2: 1.56668e+07\n","[3]\tvalid_0's rmse: 3688.75\tvalid_0's l2: 1.36069e+07\n","[4]\tvalid_0's rmse: 3450.04\tvalid_0's l2: 1.19028e+07\n","[5]\tvalid_0's rmse: 3242.4\tvalid_0's l2: 1.05132e+07\n","[6]\tvalid_0's rmse: 3058.3\tvalid_0's l2: 9.35319e+06\n","[7]\tvalid_0's rmse: 2896.15\tvalid_0's l2: 8.38771e+06\n","[8]\tvalid_0's rmse: 2753.93\tvalid_0's l2: 7.58412e+06\n","[9]\tvalid_0's rmse: 2627.35\tvalid_0's l2: 6.90295e+06\n","[10]\tvalid_0's rmse: 2515.56\tvalid_0's l2: 6.32806e+06\n","[11]\tvalid_0's rmse: 2417.83\tvalid_0's l2: 5.84591e+06\n","[12]\tvalid_0's rmse: 2330.89\tvalid_0's l2: 5.43306e+06\n","[13]\tvalid_0's rmse: 2255.37\tvalid_0's l2: 5.08669e+06\n","[14]\tvalid_0's rmse: 2188.03\tvalid_0's l2: 4.78749e+06\n","[15]\tvalid_0's rmse: 2129.73\tvalid_0's l2: 4.53576e+06\n","[16]\tvalid_0's rmse: 2076.82\tvalid_0's l2: 4.31318e+06\n","[17]\tvalid_0's rmse: 2032.06\tvalid_0's l2: 4.12928e+06\n","[18]\tvalid_0's rmse: 1993.06\tvalid_0's l2: 3.97227e+06\n","[19]\tvalid_0's rmse: 1958.08\tvalid_0's l2: 3.83408e+06\n","[20]\tvalid_0's rmse: 1927.58\tvalid_0's l2: 3.71556e+06\n","[21]\tvalid_0's rmse: 1897.64\tvalid_0's l2: 3.60103e+06\n","[22]\tvalid_0's rmse: 1872.08\tvalid_0's l2: 3.50469e+06\n","[23]\tvalid_0's rmse: 1848.42\tvalid_0's l2: 3.41667e+06\n","[24]\tvalid_0's rmse: 1828.77\tvalid_0's l2: 3.34441e+06\n","[25]\tvalid_0's rmse: 1811.1\tvalid_0's l2: 3.28007e+06\n","[26]\tvalid_0's rmse: 1796.06\tvalid_0's l2: 3.22581e+06\n","[27]\tvalid_0's rmse: 1782.3\tvalid_0's l2: 3.17659e+06\n","[28]\tvalid_0's rmse: 1769.8\tvalid_0's l2: 3.13219e+06\n","[29]\tvalid_0's rmse: 1759.66\tvalid_0's l2: 3.09639e+06\n","[30]\tvalid_0's rmse: 1749.65\tvalid_0's l2: 3.06127e+06\n","[31]\tvalid_0's rmse: 1740.69\tvalid_0's l2: 3.03e+06\n","[32]\tvalid_0's rmse: 1733.14\tvalid_0's l2: 3.00379e+06\n","[33]\tvalid_0's rmse: 1725.94\tvalid_0's l2: 2.97887e+06\n","[34]\tvalid_0's rmse: 1719.77\tvalid_0's l2: 2.9576e+06\n","[35]\tvalid_0's rmse: 1713.14\tvalid_0's l2: 2.93486e+06\n","[36]\tvalid_0's rmse: 1707.32\tvalid_0's l2: 2.91493e+06\n","[37]\tvalid_0's rmse: 1702.9\tvalid_0's l2: 2.89986e+06\n","[38]\tvalid_0's rmse: 1698.43\tvalid_0's l2: 2.88467e+06\n","[39]\tvalid_0's rmse: 1694.04\tvalid_0's l2: 2.86978e+06\n","[40]\tvalid_0's rmse: 1689.66\tvalid_0's l2: 2.85497e+06\n","[41]\tvalid_0's rmse: 1686.4\tvalid_0's l2: 2.84396e+06\n","[42]\tvalid_0's rmse: 1683.63\tvalid_0's l2: 2.83462e+06\n","[43]\tvalid_0's rmse: 1680.94\tvalid_0's l2: 2.82556e+06\n","[44]\tvalid_0's rmse: 1678.06\tvalid_0's l2: 2.8159e+06\n","[45]\tvalid_0's rmse: 1674.95\tvalid_0's l2: 2.80545e+06\n","[46]\tvalid_0's rmse: 1672.66\tvalid_0's l2: 2.79778e+06\n","[47]\tvalid_0's rmse: 1670.35\tvalid_0's l2: 2.79007e+06\n","[48]\tvalid_0's rmse: 1668.13\tvalid_0's l2: 2.78267e+06\n","[49]\tvalid_0's rmse: 1665.35\tvalid_0's l2: 2.77339e+06\n","[50]\tvalid_0's rmse: 1663.71\tvalid_0's l2: 2.76794e+06\n","[51]\tvalid_0's rmse: 1661.47\tvalid_0's l2: 2.76048e+06\n","[52]\tvalid_0's rmse: 1658.85\tvalid_0's l2: 2.75179e+06\n","[53]\tvalid_0's rmse: 1657.79\tvalid_0's l2: 2.74828e+06\n","[54]\tvalid_0's rmse: 1656.17\tvalid_0's l2: 2.74291e+06\n","[55]\tvalid_0's rmse: 1655.23\tvalid_0's l2: 2.73979e+06\n","[56]\tvalid_0's rmse: 1653.64\tvalid_0's l2: 2.73451e+06\n","[57]\tvalid_0's rmse: 1652.37\tvalid_0's l2: 2.73032e+06\n","[58]\tvalid_0's rmse: 1651.7\tvalid_0's l2: 2.72812e+06\n","[59]\tvalid_0's rmse: 1650.74\tvalid_0's l2: 2.72493e+06\n","[60]\tvalid_0's rmse: 1649.64\tvalid_0's l2: 2.72131e+06\n","[61]\tvalid_0's rmse: 1648.4\tvalid_0's l2: 2.71724e+06\n","[62]\tvalid_0's rmse: 1647.48\tvalid_0's l2: 2.71418e+06\n","[63]\tvalid_0's rmse: 1646.46\tvalid_0's l2: 2.71085e+06\n","[64]\tvalid_0's rmse: 1645.69\tvalid_0's l2: 2.70828e+06\n","[65]\tvalid_0's rmse: 1644.5\tvalid_0's l2: 2.70438e+06\n","[66]\tvalid_0's rmse: 1643.89\tvalid_0's l2: 2.70236e+06\n","[67]\tvalid_0's rmse: 1643.09\tvalid_0's l2: 2.69974e+06\n","[68]\tvalid_0's rmse: 1642.55\tvalid_0's l2: 2.69796e+06\n","[69]\tvalid_0's rmse: 1641.75\tvalid_0's l2: 2.69533e+06\n","[70]\tvalid_0's rmse: 1641.19\tvalid_0's l2: 2.69352e+06\n","[71]\tvalid_0's rmse: 1640.69\tvalid_0's l2: 2.69188e+06\n","[72]\tvalid_0's rmse: 1639.42\tvalid_0's l2: 2.68768e+06\n","[73]\tvalid_0's rmse: 1638.75\tvalid_0's l2: 2.68549e+06\n","[74]\tvalid_0's rmse: 1637.86\tvalid_0's l2: 2.6826e+06\n","[75]\tvalid_0's rmse: 1637.22\tvalid_0's l2: 2.68048e+06\n","[76]\tvalid_0's rmse: 1636.5\tvalid_0's l2: 2.67814e+06\n","[77]\tvalid_0's rmse: 1635.81\tvalid_0's l2: 2.67589e+06\n","[78]\tvalid_0's rmse: 1635.04\tvalid_0's l2: 2.67335e+06\n","[79]\tvalid_0's rmse: 1634.57\tvalid_0's l2: 2.6718e+06\n","[80]\tvalid_0's rmse: 1633.99\tvalid_0's l2: 2.66992e+06\n","[81]\tvalid_0's rmse: 1632.93\tvalid_0's l2: 2.66645e+06\n","[82]\tvalid_0's rmse: 1632.52\tvalid_0's l2: 2.66512e+06\n","[83]\tvalid_0's rmse: 1631.94\tvalid_0's l2: 2.66324e+06\n","[84]\tvalid_0's rmse: 1631.54\tvalid_0's l2: 2.66192e+06\n","[85]\tvalid_0's rmse: 1631.1\tvalid_0's l2: 2.6605e+06\n","[86]\tvalid_0's rmse: 1630.52\tvalid_0's l2: 2.65861e+06\n","[87]\tvalid_0's rmse: 1629.82\tvalid_0's l2: 2.65633e+06\n","[88]\tvalid_0's rmse: 1629.22\tvalid_0's l2: 2.65436e+06\n","[89]\tvalid_0's rmse: 1628.84\tvalid_0's l2: 2.65312e+06\n","[90]\tvalid_0's rmse: 1628.3\tvalid_0's l2: 2.65138e+06\n","[91]\tvalid_0's rmse: 1627.76\tvalid_0's l2: 2.6496e+06\n","[92]\tvalid_0's rmse: 1627.46\tvalid_0's l2: 2.64861e+06\n","[93]\tvalid_0's rmse: 1627.29\tvalid_0's l2: 2.64806e+06\n","[94]\tvalid_0's rmse: 1626.74\tvalid_0's l2: 2.64627e+06\n","[95]\tvalid_0's rmse: 1626.27\tvalid_0's l2: 2.64476e+06\n","[96]\tvalid_0's rmse: 1625.84\tvalid_0's l2: 2.64335e+06\n","[97]\tvalid_0's rmse: 1625.08\tvalid_0's l2: 2.64089e+06\n","[98]\tvalid_0's rmse: 1624.73\tvalid_0's l2: 2.63976e+06\n","[99]\tvalid_0's rmse: 1624.41\tvalid_0's l2: 2.63871e+06\n","[100]\tvalid_0's rmse: 1624.07\tvalid_0's l2: 2.63761e+06\n","2.2528271675109863\n","CPU times: user 3.54 s, sys: 228 ms, total: 3.77 s\n","Wall time: 2.25 s\n"]}],"source":["%%time\n","start_light = time.time()\n","light = lgb.LGBMRegressor()\n","light.fit(features_light_train, target_light_train, eval_set=[(features_light_valid, target_light_valid)],\\\n","     eval_metric='rmse', categorical_feature=cat_columns)\n","end_light = time.time()\n","Light_time = end_light - start_light\n","print(Light_time)\n"]},{"cell_type":"code","execution_count":67,"metadata":{"trusted":false},"outputs":[],"source":["predictions_light = light.predict(features_light_valid, num_iteraction=light.best_iteration_)\n","RMSE_light = mean_squared_error(predictions_light, target_light_valid,squared=False)"]},{"cell_type":"code","execution_count":68,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE по LightGBM 1624.07\n"]}],"source":["print('RMSE по LightGBM {:.2f}'.format(RMSE_light))\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id='my_model'></a>\n","### 5.2 CatBoost"]},{"cell_type":"code","execution_count":69,"metadata":{"trusted":false},"outputs":[],"source":["model_cat = CatBoostRegressor(cat_features=cat_columns)"]},{"cell_type":"code","execution_count":70,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning rate set to 0.113636\n","0:\tlearn: 4229.1668294\ttest: 4242.3184621\tbest: 4242.3184621 (0)\ttotal: 170ms\tremaining: 2m 49s\n","200:\tlearn: 1655.1211457\ttest: 1687.4167260\tbest: 1687.4167260 (200)\ttotal: 25.6s\tremaining: 1m 41s\n","400:\tlearn: 1599.9892994\ttest: 1651.9537277\tbest: 1651.9537277 (400)\ttotal: 51.2s\tremaining: 1m 16s\n","600:\tlearn: 1567.6392891\ttest: 1633.8739149\tbest: 1633.8739149 (600)\ttotal: 1m 17s\tremaining: 51.6s\n","800:\tlearn: 1544.1806973\ttest: 1623.5272147\tbest: 1623.5272147 (800)\ttotal: 1m 43s\tremaining: 25.8s\n","999:\tlearn: 1527.1856920\ttest: 1618.1490654\tbest: 1618.1490654 (999)\ttotal: 2m 6s\tremaining: 0us\n","\n","bestTest = 1618.149065\n","bestIteration = 999\n","\n","CPU times: user 4min 12s, sys: 5.79 s, total: 4min 18s\n","Wall time: 2min 7s\n"]}],"source":["%%time\n","start_cat = time.time()\n","model_cat.fit(features_light_train, target_light_train, eval_set=(features_light_valid, target_light_valid), verbose=200)\n","end_cat = time.time()\n","Cat_time = end_cat-start_cat"]},{"cell_type":"code","execution_count":71,"metadata":{"trusted":false},"outputs":[],"source":["predictions_cat = model_cat.predict(features_light_valid)"]},{"cell_type":"code","execution_count":72,"metadata":{"trusted":false},"outputs":[],"source":["RMSE_cat = mean_squared_error(predictions_cat, target_light_valid, squared=False)"]},{"cell_type":"code","execution_count":73,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE по CatBoost 1618.15\n"]}],"source":["print('RMSE по CatBoost {:.2f}'.format(RMSE_cat))"]},{"cell_type":"code","execution_count":74,"metadata":{"trusted":false},"outputs":[],"source":["scores = [RMSE_reg, RMSE_light, RMSE_cat, RMSE_lasso, RMSE_ridge]\n","times = [Linear_time, Light_time, Cat_time, Lasso_time, Ridge_time]\n","models = ['LinearRegression', 'LightGBM','CatBoostRegressor', 'Lasso','Ridge']\n","table = pd.DataFrame({'model':models,'score_rmse':scores,'time_sec':times})"]},{"cell_type":"code","execution_count":75,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_rmse</th>\n","      <th>time_sec</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CatBoostRegressor</td>\n","      <td>1618.15</td>\n","      <td>127.69</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LightGBM</td>\n","      <td>1624.07</td>\n","      <td>2.25</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LinearRegression</td>\n","      <td>2160.00</td>\n","      <td>6.30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ridge</td>\n","      <td>2160.45</td>\n","      <td>1.19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Lasso</td>\n","      <td>2228.29</td>\n","      <td>34.85</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               model  score_rmse  time_sec\n","0  CatBoostRegressor     1618.15    127.69\n","1           LightGBM     1624.07      2.25\n","2   LinearRegression     2160.00      6.30\n","3              Ridge     2160.45      1.19\n","4              Lasso     2228.29     34.85"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["table.sort_values(by='score_rmse').reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["Применив методы \"из коробки\", без настойки гиперпараметров, мы получили результаты удовлетворяющие нашим условиям (RMSE меньше 2500) для всех моделей.  \n","При этом лучшие результаты показала модель Catboost, а быстрее всех отработала модель Ridge Regression"]},{"cell_type":"markdown","metadata":{},"source":["<a id='hyperparameters'></a>\n","### 6 Меняем гиперпараметры"]},{"cell_type":"code","execution_count":76,"metadata":{"trusted":false},"outputs":[],"source":["#Ridge regression\n","start = time.time()\n","model_reg = Ridge(random_state=123)\n","params = {'alpha': np.arange(0,3,0.05), 'fit_intercept':[True,False]}\n","grid_reg = GridSearchCV(model_reg,params, scoring='neg_root_mean_squared_error')\n","grid_reg.fit(features_train,target_train)\n","predict_reg = grid_reg.predict(features_valid)\n","end = time.time()\n","Ridge_param_time = end - start\n","RMSE_reg_params = mean_squared_error(predict_reg, target_valid, squared=False)\n"]},{"cell_type":"code","execution_count":77,"metadata":{"trusted":false},"outputs":[{"data":{"text/plain":["{'alpha': 0.05, 'fit_intercept': True}"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["grid_reg.best_params_"]},{"cell_type":"code","execution_count":78,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE по Ridge 2160.00\n"]}],"source":["print('RMSE по Ridge {:.2f}'.format(RMSE_reg_params))\n"]},{"cell_type":"markdown","metadata":{},"source":["Значение RMSE практически не изменилось"]},{"cell_type":"code","execution_count":79,"metadata":{"scrolled":true,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007617 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006208 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004355 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004147 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005048 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004420 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003977 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013574 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005254 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005846 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004287 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004376 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006575 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004600 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004259 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005784 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005074 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003999 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006653 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004280 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003938 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006090 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005963 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005121 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004233 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004143 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003910 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004137 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004304 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004002 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004188 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004904 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008609 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005801 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005033 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019535 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006709 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005639 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005224 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007023 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005517 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004462 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006144 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003870 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007048 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013695 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015217 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005873 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004877 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004402 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005411 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005483 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007393 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005541 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009458 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004751 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006432 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008628 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006348 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004283 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004234 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005975 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005205 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004613 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022951 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004121 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005804 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010514 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004304 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004254 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008739 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006646 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007998 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004109 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004000 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005889 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006149 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004011 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005781 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005485 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006188 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013792 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067772 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004427 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007792 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005359 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004214 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017995 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006289 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004694 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015159 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004658 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008340 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006176 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008338 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003912 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009882 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003827 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006191 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006074 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 604\n","[LightGBM] [Info] Number of data points in the train set: 166150, number of used features: 10\n","[LightGBM] [Info] Start training from score 4625.751267\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Number of finished trials: 100\n","Best trial:\n","  Value: 1576.4379289895555\n","  Params: \n","    n_estimators: 100\n","    num_leaves: 200\n","    max_depth: 12\n"]}],"source":["#LightGBM\n","# попробуем применить optuna\n","start = time.time() \n","from optuna.integration import LightGBMPruningCallback\n","def objective(trial):\n","    param_grid = { \n","        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [100]),\n","        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 200, step=20),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12)\n","        }\n","    dtrain = lgb.Dataset(features_light_train, label=target_light_train)\n","    gbm = lgb.train(param_grid, dtrain)\n","    preds = gbm.predict(features_light_valid)\n","    pred_labels = np.rint(preds)\n","    rmse =  mean_squared_error(preds, target_light_valid, squared=False)\n","    return rmse\n","\n","\n","if __name__ == \"__main__\":\n","    study = optuna.create_study(direction= 'minimize')\n","    study.optimize(objective, n_trials=100)\n","\n","    print(\"Number of finished trials: {}\".format(len(study.trials)))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: {}\".format(trial.value))\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))\n","    \n","\n","end = time.time()\n","Light_param_time = end - start"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning rate set to 0.113636\n","0:\tlearn: 4269.4695416\ttest: 4282.9457541\tbest: 4282.9457541 (0)\ttotal: 72.4ms\tremaining: 1m 12s\n","200:\tlearn: 1794.6032449\ttest: 1800.4061040\tbest: 1800.4061040 (200)\ttotal: 10.8s\tremaining: 43.1s\n","400:\tlearn: 1733.7756574\ttest: 1742.0911104\tbest: 1742.0911104 (400)\ttotal: 17.7s\tremaining: 26.4s\n","600:\tlearn: 1706.7716600\ttest: 1718.3867134\tbest: 1718.3867134 (600)\ttotal: 24.6s\tremaining: 16.3s\n","800:\tlearn: 1690.0932132\ttest: 1705.9405417\tbest: 1705.9405417 (800)\ttotal: 31.7s\tremaining: 7.88s\n","999:\tlearn: 1677.1140903\ttest: 1697.1032969\tbest: 1697.1032969 (999)\ttotal: 40.1s\tremaining: 0us\n","\n","bestTest = 1697.103297\n","bestIteration = 999\n","\n","Learning rate set to 0.113636\n","0:\tlearn: 4185.5418243\ttest: 4199.7584060\tbest: 4199.7584060 (0)\ttotal: 236ms\tremaining: 3m 55s\n","200:\tlearn: 1392.5919641\ttest: 1604.1296660\tbest: 1604.0965567 (199)\ttotal: 1m 7s\tremaining: 4m 28s\n","400:\tlearn: 1257.3076258\ttest: 1588.2733941\tbest: 1588.2733941 (400)\ttotal: 2m 11s\tremaining: 3m 17s\n","600:\tlearn: 1169.0357902\ttest: 1584.9349176\tbest: 1584.7235248 (585)\ttotal: 3m 19s\tremaining: 2m 12s\n","800:\tlearn: 1105.0117741\ttest: 1584.6934851\tbest: 1584.3356072 (645)\ttotal: 4m 29s\tremaining: 1m 7s\n","999:\tlearn: 1047.2344870\ttest: 1585.9279626\tbest: 1584.3356072 (645)\ttotal: 5m 38s\tremaining: 0us\n","\n","bestTest = 1584.335607\n","bestIteration = 645\n","\n","Shrink model to first 646 iterations.\n","Learning rate set to 0.113636\n","0:\tlearn: 4269.4695416\ttest: 4282.9457541\tbest: 4282.9457541 (0)\ttotal: 57.9ms\tremaining: 57.8s\n","200:\tlearn: 1794.6032449\ttest: 1800.4061040\tbest: 1800.4061040 (200)\ttotal: 7.96s\tremaining: 31.7s\n","400:\tlearn: 1733.7756574\ttest: 1742.0911104\tbest: 1742.0911104 (400)\ttotal: 15.2s\tremaining: 22.8s\n","600:\tlearn: 1706.7716600\ttest: 1718.3867134\tbest: 1718.3867134 (600)\ttotal: 23.6s\tremaining: 15.6s\n","800:\tlearn: 1690.0932132\ttest: 1705.9405417\tbest: 1705.9405417 (800)\ttotal: 31.2s\tremaining: 7.75s\n","999:\tlearn: 1677.1140903\ttest: 1697.1032969\tbest: 1697.1032969 (999)\ttotal: 39.5s\tremaining: 0us\n","\n","bestTest = 1697.103297\n","bestIteration = 999\n","\n","Learning rate set to 0.113636\n","0:\tlearn: 4195.4844679\ttest: 4209.1869456\tbest: 4209.1869456 (0)\ttotal: 232ms\tremaining: 3m 52s\n","200:\tlearn: 1494.8453024\ttest: 1621.9463652\tbest: 1621.9463652 (200)\ttotal: 41s\tremaining: 2m 43s\n","400:\tlearn: 1405.2623432\ttest: 1600.3650827\tbest: 1600.3650827 (400)\ttotal: 1m 17s\tremaining: 1m 55s\n","600:\tlearn: 1346.1640240\ttest: 1591.1540100\tbest: 1591.1315048 (590)\ttotal: 2m\tremaining: 1m 20s\n","800:\tlearn: 1295.9466577\ttest: 1585.9994834\tbest: 1585.9062960 (795)\ttotal: 2m 45s\tremaining: 41.2s\n","999:\tlearn: 1254.9312284\ttest: 1583.7796341\tbest: 1583.6303654 (992)\ttotal: 3m 26s\tremaining: 0us\n","\n","bestTest = 1583.630365\n","bestIteration = 992\n","\n","Shrink model to first 993 iterations.\n","Learning rate set to 0.113636\n","0:\tlearn: 4243.1701160\ttest: 4256.2766670\tbest: 4256.2766670 (0)\ttotal: 84.8ms\tremaining: 1m 24s\n","200:\tlearn: 1690.3269551\ttest: 1709.4900325\tbest: 1709.4900325 (200)\ttotal: 14.4s\tremaining: 57.4s\n","400:\tlearn: 1637.3211970\ttest: 1667.7051399\tbest: 1667.7051399 (400)\ttotal: 30s\tremaining: 44.8s\n","600:\tlearn: 1609.2073520\ttest: 1650.9161475\tbest: 1650.8672300 (599)\ttotal: 47.6s\tremaining: 31.6s\n","800:\tlearn: 1588.1702207\ttest: 1639.3424898\tbest: 1639.3424898 (800)\ttotal: 1m 2s\tremaining: 15.6s\n","999:\tlearn: 1572.4236531\ttest: 1631.9667506\tbest: 1631.9563669 (997)\ttotal: 1m 18s\tremaining: 0us\n","\n","bestTest = 1631.956367\n","bestIteration = 997\n","\n","Shrink model to first 998 iterations.\n","Learning rate set to 0.113636\n","0:\tlearn: 4185.5418243\ttest: 4199.7584060\tbest: 4199.7584060 (0)\ttotal: 233ms\tremaining: 3m 52s\n","200:\tlearn: 1392.5919641\ttest: 1604.1296660\tbest: 1604.0965567 (199)\ttotal: 1m 3s\tremaining: 4m 13s\n","400:\tlearn: 1257.3076258\ttest: 1588.2733941\tbest: 1588.2733941 (400)\ttotal: 2m 5s\tremaining: 3m 7s\n","600:\tlearn: 1169.0357902\ttest: 1584.9349176\tbest: 1584.7235248 (585)\ttotal: 3m 8s\tremaining: 2m 5s\n","800:\tlearn: 1105.0117741\ttest: 1584.6934851\tbest: 1584.3356072 (645)\ttotal: 4m 10s\tremaining: 1m 2s\n","999:\tlearn: 1047.2344870\ttest: 1585.9279626\tbest: 1584.3356072 (645)\ttotal: 5m 12s\tremaining: 0us\n","\n","bestTest = 1584.335607\n","bestIteration = 645\n","\n","Shrink model to first 646 iterations.\n","Learning rate set to 0.113636\n","0:\tlearn: 4229.1668294\ttest: 4242.3184621\tbest: 4242.3184621 (0)\ttotal: 77.7ms\tremaining: 1m 17s\n","200:\tlearn: 1655.1211457\ttest: 1687.4167260\tbest: 1687.4167260 (200)\ttotal: 17.3s\tremaining: 1m 8s\n","400:\tlearn: 1599.9892994\ttest: 1651.9537277\tbest: 1651.9537277 (400)\ttotal: 35.6s\tremaining: 53.2s\n","600:\tlearn: 1567.6392891\ttest: 1633.8739149\tbest: 1633.8739149 (600)\ttotal: 54.3s\tremaining: 36s\n","800:\tlearn: 1544.1806973\ttest: 1623.5272147\tbest: 1623.5272147 (800)\ttotal: 1m 12s\tremaining: 18s\n","999:\tlearn: 1527.1856920\ttest: 1618.1490654\tbest: 1618.1490654 (999)\ttotal: 1m 30s\tremaining: 0us\n","\n","bestTest = 1618.149065\n","bestIteration = 999\n","\n","Learning rate set to 0.113636\n","0:\tlearn: 4212.6308357\ttest: 4226.8457560\tbest: 4226.8457560 (0)\ttotal: 238ms\tremaining: 3m 58s\n","200:\tlearn: 1582.2664260\ttest: 1648.2959045\tbest: 1648.2959045 (200)\ttotal: 24.9s\tremaining: 1m 38s\n","400:\tlearn: 1517.8919904\ttest: 1620.4225985\tbest: 1620.4225985 (400)\ttotal: 52.9s\tremaining: 1m 19s\n","600:\tlearn: 1474.5024126\ttest: 1606.1979729\tbest: 1606.1979729 (600)\ttotal: 1m 23s\tremaining: 55.3s\n","800:\tlearn: 1440.6212093\ttest: 1597.8563376\tbest: 1597.8563376 (800)\ttotal: 1m 50s\tremaining: 27.5s\n","999:\tlearn: 1412.7092975\ttest: 1593.9498962\tbest: 1593.8779528 (994)\ttotal: 2m 17s\tremaining: 0us\n","\n","bestTest = 1593.877953\n","bestIteration = 994\n","\n","Shrink model to first 995 iterations.\n","Learning rate set to 0.113636\n","0:\tlearn: 4185.5418243\ttest: 4199.7584060\tbest: 4199.7584060 (0)\ttotal: 317ms\tremaining: 5m 16s\n","200:\tlearn: 1392.5919641\ttest: 1604.1296660\tbest: 1604.0965567 (199)\ttotal: 59.4s\tremaining: 3m 55s\n","400:\tlearn: 1257.3076258\ttest: 1588.2733941\tbest: 1588.2733941 (400)\ttotal: 2m 2s\tremaining: 3m 2s\n","600:\tlearn: 1169.0357902\ttest: 1584.9349176\tbest: 1584.7235248 (585)\ttotal: 2m 55s\tremaining: 1m 56s\n","800:\tlearn: 1105.0117741\ttest: 1584.6934851\tbest: 1584.3356072 (645)\ttotal: 3m 47s\tremaining: 56.6s\n","999:\tlearn: 1047.2344870\ttest: 1585.9279626\tbest: 1584.3356072 (645)\ttotal: 4m 39s\tremaining: 0us\n","\n","bestTest = 1584.335607\n","bestIteration = 645\n","\n","Shrink model to first 646 iterations.\n","Learning rate set to 0.113636\n","0:\tlearn: 4212.6308357\ttest: 4226.8457560\tbest: 4226.8457560 (0)\ttotal: 110ms\tremaining: 1m 50s\n","200:\tlearn: 1582.2664260\ttest: 1648.2959045\tbest: 1648.2959045 (200)\ttotal: 20.7s\tremaining: 1m 22s\n","400:\tlearn: 1517.8919904\ttest: 1620.4225985\tbest: 1620.4225985 (400)\ttotal: 42.3s\tremaining: 1m 3s\n","600:\tlearn: 1474.5024126\ttest: 1606.1979729\tbest: 1606.1979729 (600)\ttotal: 1m 4s\tremaining: 42.8s\n","800:\tlearn: 1440.6212093\ttest: 1597.8563376\tbest: 1597.8563376 (800)\ttotal: 1m 30s\tremaining: 22.5s\n","999:\tlearn: 1412.7092975\ttest: 1593.9498962\tbest: 1593.8779528 (994)\ttotal: 1m 53s\tremaining: 0us\n","\n","bestTest = 1593.877953\n","bestIteration = 994\n","\n","Shrink model to first 995 iterations.\n","Number of finished trials: 10\n","Best trial:\n","  Value: 1583.6303654449607\n","  Params: \n","    max_depth: 10\n","    min_child_samples: 16\n"]}],"source":["#CatBoost\n","# попробуем применить optuna\n","start = time.time()\n","def objective(trial):\n","    param_grid = { \n","        \"depth\": trial.suggest_int(\"max_depth\", 3, 12),\n","        'min_child_samples': trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n","        }\n","    model_cat = CatBoostRegressor(cat_features=cat_columns, **param_grid)\n","    model_cat.fit(features_light_train, target_light_train, eval_set=(features_light_valid, target_light_valid), verbose=200)\n","    predictions = model_cat.predict(features_light_valid)\n","    rmse =  mean_squared_error(predictions,target_light_valid, squared=False)\n","    return rmse\n","\n","\n","if __name__ == \"__main__\":\n","    study = optuna.create_study(direction= 'minimize')\n","    study.optimize(objective, n_trials=10)\n","\n","    print(\"Number of finished trials: {}\".format(len(study.trials)))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: {}\".format(trial.value))\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))\n","\n","end  = time.time()\n","Cat_param_time = end - start"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["# Проверим лучшие модели  на тестовых данных:\n","# Ridge \n","start_train_ridge = time.time()\n","model_ridge = Ridge(alpha=0.05, fit_intercept=True)\n","model_ridge.fit(features_train, target_train)\n","end_train_ridge = time.time()\n","Time_ridge_train = end_train_ridge - start_train_ridge\n"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE Ridge на тестовой выборке составляет 2125.77\n"]}],"source":["start_predict_ridge = time.time()\n","prediction_ridge_test = model_ridge.predict(features_test)\n","end_predict_ridge = time.time()\n","Time_ridge_pred = end_predict_ridge - start_predict_ridge\n","rmse_ridge_test = mean_squared_error(prediction_ridge_test, target_test, squared=False)\n","print('RMSE Ridge на тестовой выборке составляет {:.2f}'.format(rmse_ridge_test))"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["#LightGBM\n","dtrain = lgb.Dataset(features_light_train, label=target_light_train)\n","start_train_light = time.time()\n","model_light_test = lgb.LGBMRegressor(n_estimators=100, num_leaves=200, max_depth=12)\n","model_light_test.fit(features_light_train, target_light_train)\n","end_train_light = time.time()\n","Time_light_train = end_train_light - start_train_light"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE LightGBM на тестовой выборке составляет 1584.67\n"]}],"source":["start_predict_light = time.time()\n","prediction_light_test = model_light_test.predict(features_light_test)\n","end_predict_light = time.time()\n","Time_light_pred = end_predict_light - start_predict_light\n","rmse_light_test = mean_squared_error(prediction_light_test, target_light_test, squared=False)\n","print('RMSE LightGBM на тестовой выборке составляет {:.2f}'.format(rmse_light_test))"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning rate set to 0.091837\n","0:\tlearn: 4269.6676080\ttotal: 290ms\tremaining: 4m 49s\n","1:\tlearn: 3985.5270322\ttotal: 493ms\tremaining: 4m 6s\n","2:\tlearn: 3732.7016584\ttotal: 850ms\tremaining: 4m 42s\n","3:\tlearn: 3502.4438622\ttotal: 1.22s\tremaining: 5m 3s\n","4:\tlearn: 3302.6562538\ttotal: 1.55s\tremaining: 5m 7s\n","5:\tlearn: 3125.2377079\ttotal: 1.79s\tremaining: 4m 57s\n","6:\tlearn: 2961.8988328\ttotal: 2.12s\tremaining: 5m\n","7:\tlearn: 2817.4021704\ttotal: 2.36s\tremaining: 4m 53s\n","8:\tlearn: 2691.9455448\ttotal: 2.78s\tremaining: 5m 6s\n","9:\tlearn: 2578.8506992\ttotal: 3.02s\tremaining: 4m 58s\n","10:\tlearn: 2479.4922498\ttotal: 3.3s\tremaining: 4m 56s\n","11:\tlearn: 2391.8037499\ttotal: 3.64s\tremaining: 4m 59s\n","12:\tlearn: 2312.8504487\ttotal: 3.96s\tremaining: 5m\n","13:\tlearn: 2241.8606355\ttotal: 4.31s\tremaining: 5m 3s\n","14:\tlearn: 2181.4616071\ttotal: 4.57s\tremaining: 4m 59s\n","15:\tlearn: 2126.4781945\ttotal: 4.79s\tremaining: 4m 54s\n","16:\tlearn: 2079.3821358\ttotal: 5.1s\tremaining: 4m 54s\n","17:\tlearn: 2036.7337943\ttotal: 5.28s\tremaining: 4m 48s\n","18:\tlearn: 2000.8633755\ttotal: 5.5s\tremaining: 4m 43s\n","19:\tlearn: 1967.8974204\ttotal: 5.71s\tremaining: 4m 39s\n","20:\tlearn: 1938.3907167\ttotal: 5.92s\tremaining: 4m 35s\n","21:\tlearn: 1913.3381395\ttotal: 6.2s\tremaining: 4m 35s\n","22:\tlearn: 1891.3131170\ttotal: 6.43s\tremaining: 4m 33s\n","23:\tlearn: 1871.5613788\ttotal: 6.74s\tremaining: 4m 34s\n","24:\tlearn: 1853.7185518\ttotal: 6.91s\tremaining: 4m 29s\n","25:\tlearn: 1837.6280784\ttotal: 7.17s\tremaining: 4m 28s\n","26:\tlearn: 1824.0979609\ttotal: 7.36s\tremaining: 4m 25s\n","27:\tlearn: 1811.8358182\ttotal: 7.78s\tremaining: 4m 30s\n","28:\tlearn: 1800.3630471\ttotal: 7.97s\tremaining: 4m 26s\n","29:\tlearn: 1790.5603711\ttotal: 8.46s\tremaining: 4m 33s\n","30:\tlearn: 1781.0707613\ttotal: 8.65s\tremaining: 4m 30s\n","31:\tlearn: 1772.9850317\ttotal: 8.9s\tremaining: 4m 29s\n","32:\tlearn: 1765.8379244\ttotal: 9.21s\tremaining: 4m 29s\n","33:\tlearn: 1758.6993637\ttotal: 9.36s\tremaining: 4m 25s\n","34:\tlearn: 1752.5499655\ttotal: 9.61s\tremaining: 4m 25s\n","35:\tlearn: 1746.9165070\ttotal: 9.86s\tremaining: 4m 24s\n","36:\tlearn: 1742.3627216\ttotal: 10.1s\tremaining: 4m 23s\n","37:\tlearn: 1737.0408186\ttotal: 10.4s\tremaining: 4m 22s\n","38:\tlearn: 1731.9943828\ttotal: 10.6s\tremaining: 4m 21s\n","39:\tlearn: 1727.9084695\ttotal: 10.8s\tremaining: 4m 19s\n","40:\tlearn: 1723.6626797\ttotal: 11s\tremaining: 4m 18s\n","41:\tlearn: 1718.8342111\ttotal: 11.3s\tremaining: 4m 17s\n","42:\tlearn: 1714.6313747\ttotal: 11.5s\tremaining: 4m 16s\n","43:\tlearn: 1711.0088693\ttotal: 11.7s\tremaining: 4m 14s\n","44:\tlearn: 1708.4445522\ttotal: 11.9s\tremaining: 4m 13s\n","45:\tlearn: 1705.1659536\ttotal: 12.1s\tremaining: 4m 10s\n","46:\tlearn: 1703.1544192\ttotal: 12.5s\tremaining: 4m 12s\n","47:\tlearn: 1700.8669130\ttotal: 12.7s\tremaining: 4m 11s\n","48:\tlearn: 1698.4367992\ttotal: 13s\tremaining: 4m 12s\n","49:\tlearn: 1694.0046307\ttotal: 13.4s\tremaining: 4m 13s\n","50:\tlearn: 1690.4665022\ttotal: 13.6s\tremaining: 4m 13s\n","51:\tlearn: 1688.3263907\ttotal: 13.9s\tremaining: 4m 13s\n","52:\tlearn: 1684.8638409\ttotal: 14.1s\tremaining: 4m 12s\n","53:\tlearn: 1681.7125180\ttotal: 14.4s\tremaining: 4m 12s\n","54:\tlearn: 1679.2605256\ttotal: 14.8s\tremaining: 4m 14s\n","55:\tlearn: 1675.6420245\ttotal: 15.2s\tremaining: 4m 16s\n","56:\tlearn: 1672.9612384\ttotal: 15.6s\tremaining: 4m 18s\n","57:\tlearn: 1671.0599862\ttotal: 15.8s\tremaining: 4m 16s\n","58:\tlearn: 1669.8541402\ttotal: 16s\tremaining: 4m 15s\n","59:\tlearn: 1668.1747194\ttotal: 16.2s\tremaining: 4m 13s\n","60:\tlearn: 1665.4998398\ttotal: 16.5s\tremaining: 4m 13s\n","61:\tlearn: 1662.5580571\ttotal: 16.7s\tremaining: 4m 12s\n","62:\tlearn: 1660.9714076\ttotal: 17s\tremaining: 4m 12s\n","63:\tlearn: 1659.3385252\ttotal: 17.2s\tremaining: 4m 12s\n","64:\tlearn: 1657.7782374\ttotal: 17.5s\tremaining: 4m 11s\n","65:\tlearn: 1654.6551610\ttotal: 17.7s\tremaining: 4m 10s\n","66:\tlearn: 1652.6895382\ttotal: 17.9s\tremaining: 4m 9s\n","67:\tlearn: 1651.0016793\ttotal: 18.2s\tremaining: 4m 9s\n","68:\tlearn: 1648.5604748\ttotal: 18.4s\tremaining: 4m 7s\n","69:\tlearn: 1646.3444756\ttotal: 18.7s\tremaining: 4m 8s\n","70:\tlearn: 1645.4537361\ttotal: 19s\tremaining: 4m 9s\n","71:\tlearn: 1643.7038099\ttotal: 19.4s\tremaining: 4m 10s\n","72:\tlearn: 1642.6468469\ttotal: 20s\tremaining: 4m 13s\n","73:\tlearn: 1641.2165635\ttotal: 20.3s\tremaining: 4m 14s\n","74:\tlearn: 1639.2349296\ttotal: 20.5s\tremaining: 4m 13s\n","75:\tlearn: 1638.1492031\ttotal: 20.8s\tremaining: 4m 13s\n","76:\tlearn: 1636.7113289\ttotal: 21.1s\tremaining: 4m 13s\n","77:\tlearn: 1635.5010470\ttotal: 21.3s\tremaining: 4m 12s\n","78:\tlearn: 1634.1254415\ttotal: 21.5s\tremaining: 4m 11s\n","79:\tlearn: 1633.1289473\ttotal: 22s\tremaining: 4m 12s\n","80:\tlearn: 1631.2860939\ttotal: 22.3s\tremaining: 4m 12s\n","81:\tlearn: 1630.0631998\ttotal: 22.4s\tremaining: 4m 11s\n","82:\tlearn: 1628.4390315\ttotal: 22.7s\tremaining: 4m 10s\n","83:\tlearn: 1626.8820202\ttotal: 23.1s\tremaining: 4m 11s\n","84:\tlearn: 1625.0505899\ttotal: 23.3s\tremaining: 4m 10s\n","85:\tlearn: 1622.5934091\ttotal: 23.5s\tremaining: 4m 9s\n","86:\tlearn: 1621.5228974\ttotal: 23.6s\tremaining: 4m 7s\n","87:\tlearn: 1619.0723845\ttotal: 23.9s\tremaining: 4m 7s\n","88:\tlearn: 1618.4746424\ttotal: 24.1s\tremaining: 4m 6s\n","89:\tlearn: 1617.0144537\ttotal: 24.3s\tremaining: 4m 6s\n","90:\tlearn: 1616.0138221\ttotal: 24.6s\tremaining: 4m 6s\n","91:\tlearn: 1614.9638542\ttotal: 24.9s\tremaining: 4m 5s\n","92:\tlearn: 1612.8725720\ttotal: 25.2s\tremaining: 4m 5s\n","93:\tlearn: 1611.7282224\ttotal: 25.4s\tremaining: 4m 5s\n","94:\tlearn: 1610.3134483\ttotal: 25.8s\tremaining: 4m 5s\n","95:\tlearn: 1608.6792139\ttotal: 26.1s\tremaining: 4m 5s\n","96:\tlearn: 1606.9229837\ttotal: 26.4s\tremaining: 4m 5s\n","97:\tlearn: 1605.2318547\ttotal: 26.7s\tremaining: 4m 5s\n","98:\tlearn: 1604.2947716\ttotal: 27.1s\tremaining: 4m 6s\n","99:\tlearn: 1603.7540411\ttotal: 27.3s\tremaining: 4m 5s\n","100:\tlearn: 1601.6644666\ttotal: 27.6s\tremaining: 4m 5s\n","101:\tlearn: 1600.9984401\ttotal: 27.9s\tremaining: 4m 6s\n","102:\tlearn: 1599.8576173\ttotal: 28.2s\tremaining: 4m 5s\n","103:\tlearn: 1598.8283392\ttotal: 28.4s\tremaining: 4m 5s\n","104:\tlearn: 1598.1864153\ttotal: 28.6s\tremaining: 4m 4s\n","105:\tlearn: 1597.0423198\ttotal: 28.9s\tremaining: 4m 4s\n","106:\tlearn: 1595.4059544\ttotal: 29.2s\tremaining: 4m 4s\n","107:\tlearn: 1593.6081762\ttotal: 29.5s\tremaining: 4m 3s\n","108:\tlearn: 1592.2903130\ttotal: 29.7s\tremaining: 4m 2s\n","109:\tlearn: 1591.4712757\ttotal: 30s\tremaining: 4m 3s\n","110:\tlearn: 1590.9337775\ttotal: 30.3s\tremaining: 4m 2s\n","111:\tlearn: 1588.8083179\ttotal: 30.5s\tremaining: 4m 1s\n","112:\tlearn: 1586.6824224\ttotal: 30.7s\tremaining: 4m 1s\n","113:\tlearn: 1585.9742940\ttotal: 31.2s\tremaining: 4m 2s\n","114:\tlearn: 1584.7090723\ttotal: 31.5s\tremaining: 4m 2s\n","115:\tlearn: 1583.4680092\ttotal: 31.9s\tremaining: 4m 2s\n","116:\tlearn: 1582.1691052\ttotal: 32s\tremaining: 4m 1s\n","117:\tlearn: 1581.4471145\ttotal: 32.3s\tremaining: 4m 1s\n","118:\tlearn: 1580.1263060\ttotal: 32.5s\tremaining: 4m\n","119:\tlearn: 1579.3589408\ttotal: 32.7s\tremaining: 4m\n","120:\tlearn: 1577.8840354\ttotal: 32.9s\tremaining: 3m 59s\n","121:\tlearn: 1577.3221289\ttotal: 33.2s\tremaining: 3m 58s\n","122:\tlearn: 1576.5872474\ttotal: 33.5s\tremaining: 3m 59s\n","123:\tlearn: 1575.5523465\ttotal: 33.7s\tremaining: 3m 58s\n","124:\tlearn: 1574.2308591\ttotal: 33.9s\tremaining: 3m 57s\n","125:\tlearn: 1573.2937548\ttotal: 34.1s\tremaining: 3m 56s\n","126:\tlearn: 1572.1004019\ttotal: 34.4s\tremaining: 3m 56s\n","127:\tlearn: 1570.8095020\ttotal: 34.6s\tremaining: 3m 55s\n","128:\tlearn: 1570.0412808\ttotal: 34.8s\tremaining: 3m 55s\n","129:\tlearn: 1569.2908968\ttotal: 35.1s\tremaining: 3m 54s\n","130:\tlearn: 1567.8710846\ttotal: 35.3s\tremaining: 3m 54s\n","131:\tlearn: 1566.7618342\ttotal: 35.6s\tremaining: 3m 54s\n","132:\tlearn: 1565.3787196\ttotal: 35.8s\tremaining: 3m 53s\n","133:\tlearn: 1564.4414826\ttotal: 36s\tremaining: 3m 52s\n","134:\tlearn: 1563.3556251\ttotal: 36.2s\tremaining: 3m 52s\n","135:\tlearn: 1562.8098753\ttotal: 36.5s\tremaining: 3m 51s\n","136:\tlearn: 1562.2457749\ttotal: 36.7s\tremaining: 3m 51s\n","137:\tlearn: 1561.2492597\ttotal: 36.9s\tremaining: 3m 50s\n","138:\tlearn: 1560.7566558\ttotal: 37.2s\tremaining: 3m 50s\n","139:\tlearn: 1559.8746392\ttotal: 37.4s\tremaining: 3m 49s\n","140:\tlearn: 1559.3203013\ttotal: 37.6s\tremaining: 3m 48s\n","141:\tlearn: 1558.4184006\ttotal: 37.8s\tremaining: 3m 48s\n","142:\tlearn: 1558.0532750\ttotal: 38.1s\tremaining: 3m 48s\n","143:\tlearn: 1557.1365963\ttotal: 38.3s\tremaining: 3m 47s\n","144:\tlearn: 1556.2008760\ttotal: 38.5s\tremaining: 3m 46s\n","145:\tlearn: 1555.7008090\ttotal: 38.8s\tremaining: 3m 46s\n","146:\tlearn: 1554.9101084\ttotal: 39s\tremaining: 3m 46s\n","147:\tlearn: 1553.9805816\ttotal: 39.3s\tremaining: 3m 46s\n","148:\tlearn: 1553.5970759\ttotal: 39.5s\tremaining: 3m 45s\n","149:\tlearn: 1553.1050797\ttotal: 39.8s\tremaining: 3m 45s\n","150:\tlearn: 1552.4192169\ttotal: 40.1s\tremaining: 3m 45s\n","151:\tlearn: 1552.1403616\ttotal: 40.3s\tremaining: 3m 45s\n","152:\tlearn: 1550.8053254\ttotal: 40.6s\tremaining: 3m 45s\n","153:\tlearn: 1549.9585106\ttotal: 40.8s\tremaining: 3m 44s\n","154:\tlearn: 1549.5413980\ttotal: 41.1s\tremaining: 3m 43s\n","155:\tlearn: 1548.8661517\ttotal: 41.3s\tremaining: 3m 43s\n","156:\tlearn: 1547.9364732\ttotal: 41.6s\tremaining: 3m 43s\n","157:\tlearn: 1547.4047299\ttotal: 41.7s\tremaining: 3m 42s\n","158:\tlearn: 1546.1630248\ttotal: 41.9s\tremaining: 3m 41s\n","159:\tlearn: 1545.3594375\ttotal: 42.2s\tremaining: 3m 41s\n","160:\tlearn: 1544.8797466\ttotal: 42.4s\tremaining: 3m 41s\n","161:\tlearn: 1544.3934431\ttotal: 42.6s\tremaining: 3m 40s\n","162:\tlearn: 1543.4534225\ttotal: 42.8s\tremaining: 3m 39s\n","163:\tlearn: 1542.8622266\ttotal: 43.1s\tremaining: 3m 39s\n","164:\tlearn: 1542.4741179\ttotal: 43.3s\tremaining: 3m 39s\n","165:\tlearn: 1541.7162349\ttotal: 43.6s\tremaining: 3m 39s\n","166:\tlearn: 1541.1451033\ttotal: 43.8s\tremaining: 3m 38s\n","167:\tlearn: 1540.2212550\ttotal: 44.1s\tremaining: 3m 38s\n","168:\tlearn: 1539.2869051\ttotal: 44.3s\tremaining: 3m 37s\n","169:\tlearn: 1539.0092523\ttotal: 44.6s\tremaining: 3m 37s\n","170:\tlearn: 1538.3885078\ttotal: 44.8s\tremaining: 3m 37s\n","171:\tlearn: 1537.7902789\ttotal: 45s\tremaining: 3m 36s\n","172:\tlearn: 1537.2054454\ttotal: 45.2s\tremaining: 3m 36s\n","173:\tlearn: 1536.9799728\ttotal: 45.4s\tremaining: 3m 35s\n","174:\tlearn: 1536.6752753\ttotal: 45.6s\tremaining: 3m 35s\n","175:\tlearn: 1536.2913947\ttotal: 45.9s\tremaining: 3m 34s\n","176:\tlearn: 1535.6374651\ttotal: 46s\tremaining: 3m 34s\n","177:\tlearn: 1534.3765154\ttotal: 46.3s\tremaining: 3m 33s\n","178:\tlearn: 1533.5688980\ttotal: 46.6s\tremaining: 3m 33s\n","179:\tlearn: 1533.2140860\ttotal: 46.8s\tremaining: 3m 33s\n","180:\tlearn: 1531.9340638\ttotal: 47s\tremaining: 3m 32s\n","181:\tlearn: 1531.2287536\ttotal: 47.3s\tremaining: 3m 32s\n","182:\tlearn: 1530.8787721\ttotal: 47.5s\tremaining: 3m 32s\n","183:\tlearn: 1529.9753255\ttotal: 48s\tremaining: 3m 32s\n","184:\tlearn: 1529.1443899\ttotal: 48.2s\tremaining: 3m 32s\n","185:\tlearn: 1528.6599452\ttotal: 48.4s\tremaining: 3m 31s\n","186:\tlearn: 1527.7298993\ttotal: 48.6s\tremaining: 3m 31s\n","187:\tlearn: 1526.7775887\ttotal: 48.8s\tremaining: 3m 30s\n","188:\tlearn: 1526.0099129\ttotal: 49.2s\tremaining: 3m 30s\n","189:\tlearn: 1525.3002072\ttotal: 49.5s\tremaining: 3m 30s\n","190:\tlearn: 1524.6530456\ttotal: 49.7s\tremaining: 3m 30s\n","191:\tlearn: 1524.1978137\ttotal: 50s\tremaining: 3m 30s\n","192:\tlearn: 1524.0742748\ttotal: 50.2s\tremaining: 3m 30s\n","193:\tlearn: 1523.6872954\ttotal: 50.4s\tremaining: 3m 29s\n","194:\tlearn: 1523.2527834\ttotal: 50.7s\tremaining: 3m 29s\n","195:\tlearn: 1522.3380035\ttotal: 51s\tremaining: 3m 29s\n","196:\tlearn: 1522.1166471\ttotal: 51.2s\tremaining: 3m 28s\n","197:\tlearn: 1520.8893988\ttotal: 51.5s\tremaining: 3m 28s\n","198:\tlearn: 1520.7864192\ttotal: 51.7s\tremaining: 3m 27s\n","199:\tlearn: 1519.9824892\ttotal: 51.9s\tremaining: 3m 27s\n","200:\tlearn: 1519.5127712\ttotal: 52.2s\tremaining: 3m 27s\n","201:\tlearn: 1519.3027674\ttotal: 52.4s\tremaining: 3m 27s\n","202:\tlearn: 1518.4559046\ttotal: 52.7s\tremaining: 3m 26s\n","203:\tlearn: 1518.0851205\ttotal: 53s\tremaining: 3m 26s\n","204:\tlearn: 1517.5235871\ttotal: 53.2s\tremaining: 3m 26s\n","205:\tlearn: 1516.4856544\ttotal: 53.5s\tremaining: 3m 26s\n","206:\tlearn: 1516.3521593\ttotal: 53.9s\tremaining: 3m 26s\n","207:\tlearn: 1515.3227391\ttotal: 54.2s\tremaining: 3m 26s\n","208:\tlearn: 1515.2274051\ttotal: 54.7s\tremaining: 3m 26s\n","209:\tlearn: 1514.6113897\ttotal: 55.1s\tremaining: 3m 27s\n","210:\tlearn: 1514.1611097\ttotal: 55.4s\tremaining: 3m 27s\n","211:\tlearn: 1513.2166401\ttotal: 55.8s\tremaining: 3m 27s\n","212:\tlearn: 1512.4905686\ttotal: 56.3s\tremaining: 3m 28s\n","213:\tlearn: 1512.2541011\ttotal: 56.8s\tremaining: 3m 28s\n","214:\tlearn: 1511.9562038\ttotal: 57.2s\tremaining: 3m 28s\n","215:\tlearn: 1511.5148130\ttotal: 57.5s\tremaining: 3m 28s\n","216:\tlearn: 1510.8914111\ttotal: 57.8s\tremaining: 3m 28s\n","217:\tlearn: 1510.5895526\ttotal: 58.1s\tremaining: 3m 28s\n","218:\tlearn: 1509.8747801\ttotal: 58.3s\tremaining: 3m 28s\n","219:\tlearn: 1509.2490193\ttotal: 58.6s\tremaining: 3m 27s\n","220:\tlearn: 1508.9609698\ttotal: 58.8s\tremaining: 3m 27s\n","221:\tlearn: 1508.4020921\ttotal: 59.1s\tremaining: 3m 27s\n","222:\tlearn: 1508.1115066\ttotal: 59.4s\tremaining: 3m 26s\n","223:\tlearn: 1507.5876898\ttotal: 59.6s\tremaining: 3m 26s\n","224:\tlearn: 1507.3387541\ttotal: 59.9s\tremaining: 3m 26s\n","225:\tlearn: 1506.8764967\ttotal: 1m\tremaining: 3m 26s\n","226:\tlearn: 1506.6986748\ttotal: 1m\tremaining: 3m 25s\n","227:\tlearn: 1506.2556484\ttotal: 1m\tremaining: 3m 25s\n","228:\tlearn: 1505.2519898\ttotal: 1m 1s\tremaining: 3m 26s\n","229:\tlearn: 1504.0080510\ttotal: 1m 1s\tremaining: 3m 25s\n","230:\tlearn: 1503.1686158\ttotal: 1m 1s\tremaining: 3m 25s\n","231:\tlearn: 1502.3629808\ttotal: 1m 1s\tremaining: 3m 24s\n","232:\tlearn: 1501.8008102\ttotal: 1m 1s\tremaining: 3m 24s\n","233:\tlearn: 1501.0576437\ttotal: 1m 2s\tremaining: 3m 23s\n","234:\tlearn: 1500.3605857\ttotal: 1m 2s\tremaining: 3m 23s\n","235:\tlearn: 1499.9891957\ttotal: 1m 2s\tremaining: 3m 23s\n","236:\tlearn: 1499.2677756\ttotal: 1m 3s\tremaining: 3m 23s\n","237:\tlearn: 1498.9643966\ttotal: 1m 3s\tremaining: 3m 22s\n","238:\tlearn: 1498.4619403\ttotal: 1m 3s\tremaining: 3m 22s\n","239:\tlearn: 1497.5421720\ttotal: 1m 3s\tremaining: 3m 22s\n","240:\tlearn: 1497.2859159\ttotal: 1m 4s\tremaining: 3m 22s\n","241:\tlearn: 1497.0179467\ttotal: 1m 4s\tremaining: 3m 21s\n","242:\tlearn: 1496.5326740\ttotal: 1m 4s\tremaining: 3m 21s\n","243:\tlearn: 1495.9355169\ttotal: 1m 4s\tremaining: 3m 20s\n","244:\tlearn: 1495.2421747\ttotal: 1m 5s\tremaining: 3m 20s\n","245:\tlearn: 1495.0017708\ttotal: 1m 5s\tremaining: 3m 20s\n","246:\tlearn: 1494.1193964\ttotal: 1m 5s\tremaining: 3m 19s\n","247:\tlearn: 1493.8773264\ttotal: 1m 5s\tremaining: 3m 19s\n","248:\tlearn: 1493.0001854\ttotal: 1m 6s\tremaining: 3m 19s\n","249:\tlearn: 1492.6115121\ttotal: 1m 6s\tremaining: 3m 19s\n","250:\tlearn: 1492.2561807\ttotal: 1m 6s\tremaining: 3m 18s\n","251:\tlearn: 1491.1582576\ttotal: 1m 7s\tremaining: 3m 18s\n","252:\tlearn: 1490.8706687\ttotal: 1m 7s\tremaining: 3m 18s\n","253:\tlearn: 1490.2265306\ttotal: 1m 7s\tremaining: 3m 19s\n","254:\tlearn: 1490.0735971\ttotal: 1m 8s\tremaining: 3m 18s\n","255:\tlearn: 1489.2416617\ttotal: 1m 8s\tremaining: 3m 18s\n","256:\tlearn: 1488.6455847\ttotal: 1m 8s\tremaining: 3m 18s\n","257:\tlearn: 1487.9743450\ttotal: 1m 8s\tremaining: 3m 17s\n","258:\tlearn: 1487.1447757\ttotal: 1m 9s\tremaining: 3m 17s\n","259:\tlearn: 1486.3890233\ttotal: 1m 9s\tremaining: 3m 17s\n","260:\tlearn: 1485.8674509\ttotal: 1m 9s\tremaining: 3m 16s\n","261:\tlearn: 1485.5329879\ttotal: 1m 9s\tremaining: 3m 16s\n","262:\tlearn: 1485.2109390\ttotal: 1m 10s\tremaining: 3m 16s\n","263:\tlearn: 1484.5433251\ttotal: 1m 10s\tremaining: 3m 16s\n","264:\tlearn: 1483.6885763\ttotal: 1m 10s\tremaining: 3m 15s\n","265:\tlearn: 1483.4717622\ttotal: 1m 10s\tremaining: 3m 15s\n","266:\tlearn: 1483.1973524\ttotal: 1m 11s\tremaining: 3m 15s\n","267:\tlearn: 1482.8805107\ttotal: 1m 11s\tremaining: 3m 15s\n","268:\tlearn: 1482.6842711\ttotal: 1m 11s\tremaining: 3m 14s\n","269:\tlearn: 1482.2077538\ttotal: 1m 11s\tremaining: 3m 14s\n","270:\tlearn: 1481.5781980\ttotal: 1m 12s\tremaining: 3m 13s\n","271:\tlearn: 1481.3582480\ttotal: 1m 12s\tremaining: 3m 13s\n","272:\tlearn: 1481.2177767\ttotal: 1m 12s\tremaining: 3m 13s\n","273:\tlearn: 1480.6048165\ttotal: 1m 12s\tremaining: 3m 13s\n","274:\tlearn: 1480.2252534\ttotal: 1m 13s\tremaining: 3m 12s\n","275:\tlearn: 1479.9538732\ttotal: 1m 13s\tremaining: 3m 12s\n","276:\tlearn: 1479.5178299\ttotal: 1m 13s\tremaining: 3m 11s\n","277:\tlearn: 1479.3070214\ttotal: 1m 13s\tremaining: 3m 11s\n","278:\tlearn: 1479.0346260\ttotal: 1m 14s\tremaining: 3m 11s\n","279:\tlearn: 1478.4472872\ttotal: 1m 14s\tremaining: 3m 10s\n","280:\tlearn: 1478.1513140\ttotal: 1m 14s\tremaining: 3m 10s\n","281:\tlearn: 1477.5147117\ttotal: 1m 14s\tremaining: 3m 10s\n","282:\tlearn: 1476.8708338\ttotal: 1m 14s\tremaining: 3m 10s\n","283:\tlearn: 1476.3012526\ttotal: 1m 15s\tremaining: 3m 9s\n","284:\tlearn: 1476.1399704\ttotal: 1m 15s\tremaining: 3m 9s\n","285:\tlearn: 1475.9735213\ttotal: 1m 15s\tremaining: 3m 8s\n","286:\tlearn: 1475.7457206\ttotal: 1m 15s\tremaining: 3m 8s\n","287:\tlearn: 1475.2914099\ttotal: 1m 16s\tremaining: 3m 8s\n","288:\tlearn: 1474.8816824\ttotal: 1m 16s\tremaining: 3m 7s\n","289:\tlearn: 1473.9826278\ttotal: 1m 16s\tremaining: 3m 7s\n","290:\tlearn: 1473.7368017\ttotal: 1m 16s\tremaining: 3m 7s\n","291:\tlearn: 1473.0256728\ttotal: 1m 17s\tremaining: 3m 7s\n","292:\tlearn: 1472.6812715\ttotal: 1m 17s\tremaining: 3m 6s\n","293:\tlearn: 1472.5118989\ttotal: 1m 17s\tremaining: 3m 6s\n","294:\tlearn: 1471.9723264\ttotal: 1m 17s\tremaining: 3m 5s\n","295:\tlearn: 1471.6923507\ttotal: 1m 18s\tremaining: 3m 5s\n","296:\tlearn: 1471.2818555\ttotal: 1m 18s\tremaining: 3m 5s\n","297:\tlearn: 1471.1236980\ttotal: 1m 18s\tremaining: 3m 5s\n","298:\tlearn: 1470.5563094\ttotal: 1m 18s\tremaining: 3m 5s\n","299:\tlearn: 1470.4248504\ttotal: 1m 19s\tremaining: 3m 4s\n","300:\tlearn: 1469.9564749\ttotal: 1m 19s\tremaining: 3m 4s\n","301:\tlearn: 1469.1562032\ttotal: 1m 19s\tremaining: 3m 4s\n","302:\tlearn: 1468.6477486\ttotal: 1m 19s\tremaining: 3m 3s\n","303:\tlearn: 1467.9348442\ttotal: 1m 20s\tremaining: 3m 3s\n","304:\tlearn: 1467.7053820\ttotal: 1m 20s\tremaining: 3m 3s\n","305:\tlearn: 1467.6037512\ttotal: 1m 20s\tremaining: 3m 3s\n","306:\tlearn: 1467.4060055\ttotal: 1m 21s\tremaining: 3m 3s\n","307:\tlearn: 1467.0939607\ttotal: 1m 21s\tremaining: 3m 3s\n","308:\tlearn: 1466.9231537\ttotal: 1m 22s\tremaining: 3m 3s\n","309:\tlearn: 1466.7065659\ttotal: 1m 22s\tremaining: 3m 3s\n","310:\tlearn: 1466.5354556\ttotal: 1m 22s\tremaining: 3m 3s\n","311:\tlearn: 1466.0658543\ttotal: 1m 22s\tremaining: 3m 2s\n","312:\tlearn: 1465.7402242\ttotal: 1m 23s\tremaining: 3m 2s\n","313:\tlearn: 1465.1657204\ttotal: 1m 23s\tremaining: 3m 2s\n","314:\tlearn: 1465.0354789\ttotal: 1m 23s\tremaining: 3m 1s\n","315:\tlearn: 1464.6337255\ttotal: 1m 23s\tremaining: 3m 1s\n","316:\tlearn: 1464.2981793\ttotal: 1m 24s\tremaining: 3m 1s\n","317:\tlearn: 1464.0438203\ttotal: 1m 24s\tremaining: 3m\n","318:\tlearn: 1463.3638282\ttotal: 1m 24s\tremaining: 3m\n","319:\tlearn: 1462.9486426\ttotal: 1m 24s\tremaining: 3m\n","320:\tlearn: 1462.4091780\ttotal: 1m 25s\tremaining: 2m 59s\n","321:\tlearn: 1461.7409307\ttotal: 1m 25s\tremaining: 2m 59s\n","322:\tlearn: 1461.6099911\ttotal: 1m 25s\tremaining: 2m 59s\n","323:\tlearn: 1461.4925456\ttotal: 1m 25s\tremaining: 2m 58s\n","324:\tlearn: 1460.7148135\ttotal: 1m 25s\tremaining: 2m 58s\n","325:\tlearn: 1460.2200617\ttotal: 1m 26s\tremaining: 2m 58s\n","326:\tlearn: 1459.7385571\ttotal: 1m 26s\tremaining: 2m 57s\n","327:\tlearn: 1459.1254430\ttotal: 1m 26s\tremaining: 2m 57s\n","328:\tlearn: 1458.7059924\ttotal: 1m 26s\tremaining: 2m 57s\n","329:\tlearn: 1458.3368109\ttotal: 1m 27s\tremaining: 2m 56s\n","330:\tlearn: 1458.2141526\ttotal: 1m 27s\tremaining: 2m 56s\n","331:\tlearn: 1457.7005523\ttotal: 1m 27s\tremaining: 2m 56s\n","332:\tlearn: 1457.4274426\ttotal: 1m 27s\tremaining: 2m 55s\n","333:\tlearn: 1456.8530356\ttotal: 1m 28s\tremaining: 2m 55s\n","334:\tlearn: 1456.5303690\ttotal: 1m 28s\tremaining: 2m 55s\n","335:\tlearn: 1456.3496914\ttotal: 1m 28s\tremaining: 2m 55s\n","336:\tlearn: 1455.8769334\ttotal: 1m 29s\tremaining: 2m 55s\n","337:\tlearn: 1455.7517628\ttotal: 1m 29s\tremaining: 2m 55s\n","338:\tlearn: 1455.4497847\ttotal: 1m 29s\tremaining: 2m 54s\n","339:\tlearn: 1455.4202020\ttotal: 1m 29s\tremaining: 2m 54s\n","340:\tlearn: 1455.0920487\ttotal: 1m 30s\tremaining: 2m 54s\n","341:\tlearn: 1454.9341278\ttotal: 1m 30s\tremaining: 2m 54s\n","342:\tlearn: 1454.3093806\ttotal: 1m 30s\tremaining: 2m 53s\n","343:\tlearn: 1454.0597580\ttotal: 1m 31s\tremaining: 2m 53s\n","344:\tlearn: 1453.6114907\ttotal: 1m 31s\tremaining: 2m 53s\n","345:\tlearn: 1453.0905738\ttotal: 1m 31s\tremaining: 2m 52s\n","346:\tlearn: 1452.3889667\ttotal: 1m 31s\tremaining: 2m 52s\n","347:\tlearn: 1452.0244107\ttotal: 1m 32s\tremaining: 2m 52s\n","348:\tlearn: 1451.6648742\ttotal: 1m 32s\tremaining: 2m 52s\n","349:\tlearn: 1451.5182000\ttotal: 1m 32s\tremaining: 2m 51s\n","350:\tlearn: 1450.9958522\ttotal: 1m 32s\tremaining: 2m 51s\n","351:\tlearn: 1450.6630952\ttotal: 1m 32s\tremaining: 2m 51s\n","352:\tlearn: 1450.0373015\ttotal: 1m 33s\tremaining: 2m 50s\n","353:\tlearn: 1449.8992239\ttotal: 1m 33s\tremaining: 2m 50s\n","354:\tlearn: 1449.1353560\ttotal: 1m 33s\tremaining: 2m 50s\n","355:\tlearn: 1448.8092562\ttotal: 1m 33s\tremaining: 2m 49s\n","356:\tlearn: 1448.4606318\ttotal: 1m 34s\tremaining: 2m 49s\n","357:\tlearn: 1448.3209994\ttotal: 1m 34s\tremaining: 2m 49s\n","358:\tlearn: 1448.1828456\ttotal: 1m 34s\tremaining: 2m 49s\n","359:\tlearn: 1447.7771093\ttotal: 1m 35s\tremaining: 2m 48s\n","360:\tlearn: 1447.0721752\ttotal: 1m 35s\tremaining: 2m 48s\n","361:\tlearn: 1446.7592427\ttotal: 1m 35s\tremaining: 2m 48s\n","362:\tlearn: 1446.2987932\ttotal: 1m 35s\tremaining: 2m 47s\n","363:\tlearn: 1445.7583847\ttotal: 1m 35s\tremaining: 2m 47s\n","364:\tlearn: 1445.6016410\ttotal: 1m 36s\tremaining: 2m 47s\n","365:\tlearn: 1445.1661017\ttotal: 1m 36s\tremaining: 2m 46s\n","366:\tlearn: 1444.5672492\ttotal: 1m 36s\tremaining: 2m 46s\n","367:\tlearn: 1444.2775305\ttotal: 1m 36s\tremaining: 2m 46s\n","368:\tlearn: 1443.6363038\ttotal: 1m 37s\tremaining: 2m 45s\n","369:\tlearn: 1442.7682320\ttotal: 1m 37s\tremaining: 2m 45s\n","370:\tlearn: 1442.5265977\ttotal: 1m 37s\tremaining: 2m 45s\n","371:\tlearn: 1442.0009609\ttotal: 1m 37s\tremaining: 2m 45s\n","372:\tlearn: 1441.6611179\ttotal: 1m 38s\tremaining: 2m 44s\n","373:\tlearn: 1441.4301030\ttotal: 1m 38s\tremaining: 2m 44s\n","374:\tlearn: 1441.4187563\ttotal: 1m 38s\tremaining: 2m 44s\n","375:\tlearn: 1441.1747466\ttotal: 1m 38s\tremaining: 2m 43s\n","376:\tlearn: 1440.8113433\ttotal: 1m 38s\tremaining: 2m 43s\n","377:\tlearn: 1440.5801095\ttotal: 1m 39s\tremaining: 2m 43s\n","378:\tlearn: 1440.4436988\ttotal: 1m 39s\tremaining: 2m 42s\n","379:\tlearn: 1440.0024773\ttotal: 1m 39s\tremaining: 2m 42s\n","380:\tlearn: 1439.7684188\ttotal: 1m 39s\tremaining: 2m 41s\n","381:\tlearn: 1439.6073022\ttotal: 1m 39s\tremaining: 2m 41s\n","382:\tlearn: 1439.1713780\ttotal: 1m 40s\tremaining: 2m 41s\n","383:\tlearn: 1438.8272415\ttotal: 1m 40s\tremaining: 2m 40s\n","384:\tlearn: 1438.3600083\ttotal: 1m 40s\tremaining: 2m 40s\n","385:\tlearn: 1437.7983019\ttotal: 1m 40s\tremaining: 2m 40s\n","386:\tlearn: 1437.4374116\ttotal: 1m 40s\tremaining: 2m 39s\n","387:\tlearn: 1437.2031419\ttotal: 1m 41s\tremaining: 2m 39s\n","388:\tlearn: 1436.7806318\ttotal: 1m 41s\tremaining: 2m 39s\n","389:\tlearn: 1436.3463423\ttotal: 1m 41s\tremaining: 2m 38s\n","390:\tlearn: 1435.9082286\ttotal: 1m 41s\tremaining: 2m 38s\n","391:\tlearn: 1435.5862484\ttotal: 1m 42s\tremaining: 2m 38s\n","392:\tlearn: 1435.4355409\ttotal: 1m 42s\tremaining: 2m 38s\n","393:\tlearn: 1435.2690191\ttotal: 1m 42s\tremaining: 2m 37s\n","394:\tlearn: 1435.1001439\ttotal: 1m 42s\tremaining: 2m 37s\n","395:\tlearn: 1434.9136307\ttotal: 1m 42s\tremaining: 2m 37s\n","396:\tlearn: 1434.5620633\ttotal: 1m 43s\tremaining: 2m 36s\n","397:\tlearn: 1434.4011398\ttotal: 1m 43s\tremaining: 2m 37s\n","398:\tlearn: 1433.9527440\ttotal: 1m 44s\tremaining: 2m 37s\n","399:\tlearn: 1433.6958878\ttotal: 1m 44s\tremaining: 2m 36s\n","400:\tlearn: 1433.0920377\ttotal: 1m 44s\tremaining: 2m 36s\n","401:\tlearn: 1432.5930766\ttotal: 1m 44s\tremaining: 2m 36s\n","402:\tlearn: 1432.2631328\ttotal: 1m 45s\tremaining: 2m 35s\n","403:\tlearn: 1431.9301040\ttotal: 1m 45s\tremaining: 2m 35s\n","404:\tlearn: 1431.9134009\ttotal: 1m 45s\tremaining: 2m 35s\n","405:\tlearn: 1431.7174779\ttotal: 1m 45s\tremaining: 2m 34s\n","406:\tlearn: 1431.1537494\ttotal: 1m 46s\tremaining: 2m 34s\n","407:\tlearn: 1430.9115741\ttotal: 1m 46s\tremaining: 2m 34s\n","408:\tlearn: 1430.0756634\ttotal: 1m 46s\tremaining: 2m 34s\n","409:\tlearn: 1429.9963698\ttotal: 1m 47s\tremaining: 2m 34s\n","410:\tlearn: 1429.8075508\ttotal: 1m 47s\tremaining: 2m 33s\n","411:\tlearn: 1429.6693228\ttotal: 1m 47s\tremaining: 2m 33s\n","412:\tlearn: 1428.9496131\ttotal: 1m 47s\tremaining: 2m 33s\n","413:\tlearn: 1428.6107634\ttotal: 1m 48s\tremaining: 2m 33s\n","414:\tlearn: 1428.4408265\ttotal: 1m 48s\tremaining: 2m 32s\n","415:\tlearn: 1427.8785660\ttotal: 1m 48s\tremaining: 2m 32s\n","416:\tlearn: 1427.6758720\ttotal: 1m 48s\tremaining: 2m 32s\n","417:\tlearn: 1427.3881207\ttotal: 1m 49s\tremaining: 2m 32s\n","418:\tlearn: 1427.2858650\ttotal: 1m 49s\tremaining: 2m 31s\n","419:\tlearn: 1427.1830572\ttotal: 1m 49s\tremaining: 2m 31s\n","420:\tlearn: 1426.8627315\ttotal: 1m 49s\tremaining: 2m 31s\n","421:\tlearn: 1426.2927227\ttotal: 1m 50s\tremaining: 2m 30s\n","422:\tlearn: 1426.1074779\ttotal: 1m 50s\tremaining: 2m 30s\n","423:\tlearn: 1425.9340747\ttotal: 1m 50s\tremaining: 2m 30s\n","424:\tlearn: 1425.8206487\ttotal: 1m 50s\tremaining: 2m 29s\n","425:\tlearn: 1425.5293101\ttotal: 1m 51s\tremaining: 2m 29s\n","426:\tlearn: 1425.4194850\ttotal: 1m 51s\tremaining: 2m 29s\n","427:\tlearn: 1424.9920263\ttotal: 1m 51s\tremaining: 2m 29s\n","428:\tlearn: 1424.8834971\ttotal: 1m 51s\tremaining: 2m 28s\n","429:\tlearn: 1424.3512494\ttotal: 1m 52s\tremaining: 2m 28s\n","430:\tlearn: 1424.1563726\ttotal: 1m 52s\tremaining: 2m 28s\n","431:\tlearn: 1423.9791699\ttotal: 1m 52s\tremaining: 2m 27s\n","432:\tlearn: 1423.9222250\ttotal: 1m 52s\tremaining: 2m 27s\n","433:\tlearn: 1423.5574029\ttotal: 1m 52s\tremaining: 2m 27s\n","434:\tlearn: 1423.1431492\ttotal: 1m 53s\tremaining: 2m 26s\n","435:\tlearn: 1422.9717762\ttotal: 1m 53s\tremaining: 2m 26s\n","436:\tlearn: 1422.4973426\ttotal: 1m 53s\tremaining: 2m 26s\n","437:\tlearn: 1422.4250390\ttotal: 1m 53s\tremaining: 2m 26s\n","438:\tlearn: 1422.2031176\ttotal: 1m 54s\tremaining: 2m 25s\n","439:\tlearn: 1421.9560291\ttotal: 1m 54s\tremaining: 2m 25s\n","440:\tlearn: 1421.6682666\ttotal: 1m 54s\tremaining: 2m 25s\n","441:\tlearn: 1421.6048142\ttotal: 1m 55s\tremaining: 2m 25s\n","442:\tlearn: 1421.5378105\ttotal: 1m 55s\tremaining: 2m 25s\n","443:\tlearn: 1421.3244897\ttotal: 1m 55s\tremaining: 2m 25s\n","444:\tlearn: 1421.0960035\ttotal: 1m 56s\tremaining: 2m 25s\n","445:\tlearn: 1420.8659257\ttotal: 1m 56s\tremaining: 2m 25s\n","446:\tlearn: 1420.8222363\ttotal: 1m 57s\tremaining: 2m 25s\n","447:\tlearn: 1420.4943198\ttotal: 1m 57s\tremaining: 2m 24s\n","448:\tlearn: 1420.2781725\ttotal: 1m 58s\tremaining: 2m 24s\n","449:\tlearn: 1420.2121308\ttotal: 1m 58s\tremaining: 2m 24s\n","450:\tlearn: 1420.0489788\ttotal: 1m 58s\tremaining: 2m 24s\n","451:\tlearn: 1419.8786769\ttotal: 1m 59s\tremaining: 2m 24s\n","452:\tlearn: 1419.2581327\ttotal: 1m 59s\tremaining: 2m 24s\n","453:\tlearn: 1418.9937099\ttotal: 1m 59s\tremaining: 2m 24s\n","454:\tlearn: 1418.6002313\ttotal: 2m\tremaining: 2m 23s\n","455:\tlearn: 1418.4705755\ttotal: 2m\tremaining: 2m 23s\n","456:\tlearn: 1418.2872229\ttotal: 2m\tremaining: 2m 23s\n","457:\tlearn: 1417.7328538\ttotal: 2m 1s\tremaining: 2m 23s\n","458:\tlearn: 1417.4071187\ttotal: 2m 1s\tremaining: 2m 22s\n","459:\tlearn: 1416.5655517\ttotal: 2m 1s\tremaining: 2m 22s\n","460:\tlearn: 1416.4015448\ttotal: 2m 1s\tremaining: 2m 22s\n","461:\tlearn: 1416.1002827\ttotal: 2m 2s\tremaining: 2m 22s\n","462:\tlearn: 1415.7206410\ttotal: 2m 2s\tremaining: 2m 21s\n","463:\tlearn: 1415.5933792\ttotal: 2m 2s\tremaining: 2m 21s\n","464:\tlearn: 1415.2052868\ttotal: 2m 2s\tremaining: 2m 21s\n","465:\tlearn: 1414.7382595\ttotal: 2m 3s\tremaining: 2m 21s\n","466:\tlearn: 1414.3436742\ttotal: 2m 3s\tremaining: 2m 20s\n","467:\tlearn: 1414.1655607\ttotal: 2m 3s\tremaining: 2m 20s\n","468:\tlearn: 1413.8053790\ttotal: 2m 4s\tremaining: 2m 20s\n","469:\tlearn: 1413.6347292\ttotal: 2m 4s\tremaining: 2m 20s\n","470:\tlearn: 1413.3745687\ttotal: 2m 4s\tremaining: 2m 19s\n","471:\tlearn: 1413.2948282\ttotal: 2m 4s\tremaining: 2m 19s\n","472:\tlearn: 1412.8746724\ttotal: 2m 5s\tremaining: 2m 19s\n","473:\tlearn: 1412.4245889\ttotal: 2m 5s\tremaining: 2m 19s\n","474:\tlearn: 1412.3114329\ttotal: 2m 5s\tremaining: 2m 18s\n","475:\tlearn: 1412.0142891\ttotal: 2m 5s\tremaining: 2m 18s\n","476:\tlearn: 1411.9411300\ttotal: 2m 5s\tremaining: 2m 18s\n","477:\tlearn: 1411.5070120\ttotal: 2m 6s\tremaining: 2m 17s\n","478:\tlearn: 1411.3441667\ttotal: 2m 6s\tremaining: 2m 17s\n","479:\tlearn: 1410.9325948\ttotal: 2m 6s\tremaining: 2m 17s\n","480:\tlearn: 1410.6855196\ttotal: 2m 7s\tremaining: 2m 17s\n","481:\tlearn: 1410.5299386\ttotal: 2m 7s\tremaining: 2m 17s\n","482:\tlearn: 1410.4273899\ttotal: 2m 7s\tremaining: 2m 16s\n","483:\tlearn: 1410.2049088\ttotal: 2m 8s\tremaining: 2m 16s\n","484:\tlearn: 1409.8697609\ttotal: 2m 8s\tremaining: 2m 16s\n","485:\tlearn: 1409.6423895\ttotal: 2m 8s\tremaining: 2m 16s\n","486:\tlearn: 1409.3489186\ttotal: 2m 8s\tremaining: 2m 15s\n","487:\tlearn: 1409.1667943\ttotal: 2m 9s\tremaining: 2m 15s\n","488:\tlearn: 1408.8177533\ttotal: 2m 9s\tremaining: 2m 15s\n","489:\tlearn: 1408.5241830\ttotal: 2m 9s\tremaining: 2m 14s\n","490:\tlearn: 1408.1644622\ttotal: 2m 9s\tremaining: 2m 14s\n","491:\tlearn: 1407.9297770\ttotal: 2m 10s\tremaining: 2m 14s\n","492:\tlearn: 1407.7054296\ttotal: 2m 10s\tremaining: 2m 14s\n","493:\tlearn: 1407.6763141\ttotal: 2m 10s\tremaining: 2m 13s\n","494:\tlearn: 1407.4872986\ttotal: 2m 10s\tremaining: 2m 13s\n","495:\tlearn: 1407.2135743\ttotal: 2m 11s\tremaining: 2m 13s\n","496:\tlearn: 1407.1402084\ttotal: 2m 11s\tremaining: 2m 13s\n","497:\tlearn: 1406.9448103\ttotal: 2m 11s\tremaining: 2m 12s\n","498:\tlearn: 1406.8492286\ttotal: 2m 11s\tremaining: 2m 12s\n","499:\tlearn: 1406.5247779\ttotal: 2m 12s\tremaining: 2m 12s\n","500:\tlearn: 1406.2187115\ttotal: 2m 12s\tremaining: 2m 11s\n","501:\tlearn: 1406.1902991\ttotal: 2m 12s\tremaining: 2m 11s\n","502:\tlearn: 1405.9813307\ttotal: 2m 12s\tremaining: 2m 11s\n","503:\tlearn: 1405.5982551\ttotal: 2m 13s\tremaining: 2m 11s\n","504:\tlearn: 1405.4741030\ttotal: 2m 13s\tremaining: 2m 10s\n","505:\tlearn: 1404.9636058\ttotal: 2m 13s\tremaining: 2m 10s\n","506:\tlearn: 1404.9146595\ttotal: 2m 13s\tremaining: 2m 10s\n","507:\tlearn: 1404.3799936\ttotal: 2m 14s\tremaining: 2m 9s\n","508:\tlearn: 1404.0449615\ttotal: 2m 14s\tremaining: 2m 9s\n","509:\tlearn: 1403.6434304\ttotal: 2m 14s\tremaining: 2m 9s\n","510:\tlearn: 1403.3515473\ttotal: 2m 14s\tremaining: 2m 8s\n","511:\tlearn: 1403.2056285\ttotal: 2m 14s\tremaining: 2m 8s\n","512:\tlearn: 1402.9918304\ttotal: 2m 15s\tremaining: 2m 8s\n","513:\tlearn: 1402.7134040\ttotal: 2m 15s\tremaining: 2m 8s\n","514:\tlearn: 1402.5386566\ttotal: 2m 15s\tremaining: 2m 7s\n","515:\tlearn: 1402.4131352\ttotal: 2m 15s\tremaining: 2m 7s\n","516:\tlearn: 1402.2900643\ttotal: 2m 16s\tremaining: 2m 7s\n","517:\tlearn: 1402.0861014\ttotal: 2m 16s\tremaining: 2m 6s\n","518:\tlearn: 1401.7289735\ttotal: 2m 16s\tremaining: 2m 6s\n","519:\tlearn: 1401.2573932\ttotal: 2m 17s\tremaining: 2m 6s\n","520:\tlearn: 1400.8778745\ttotal: 2m 17s\tremaining: 2m 6s\n","521:\tlearn: 1400.2465631\ttotal: 2m 17s\tremaining: 2m 5s\n","522:\tlearn: 1399.9315041\ttotal: 2m 17s\tremaining: 2m 5s\n","523:\tlearn: 1399.7778602\ttotal: 2m 17s\tremaining: 2m 5s\n","524:\tlearn: 1399.5753399\ttotal: 2m 18s\tremaining: 2m 5s\n","525:\tlearn: 1399.2724486\ttotal: 2m 18s\tremaining: 2m 4s\n","526:\tlearn: 1399.1700558\ttotal: 2m 18s\tremaining: 2m 4s\n","527:\tlearn: 1399.1545133\ttotal: 2m 19s\tremaining: 2m 4s\n","528:\tlearn: 1398.7801375\ttotal: 2m 19s\tremaining: 2m 4s\n","529:\tlearn: 1398.5526756\ttotal: 2m 19s\tremaining: 2m 3s\n","530:\tlearn: 1398.3927581\ttotal: 2m 19s\tremaining: 2m 3s\n","531:\tlearn: 1398.2154302\ttotal: 2m 20s\tremaining: 2m 3s\n","532:\tlearn: 1398.0989343\ttotal: 2m 20s\tremaining: 2m 3s\n","533:\tlearn: 1397.9423909\ttotal: 2m 20s\tremaining: 2m 2s\n","534:\tlearn: 1397.7694696\ttotal: 2m 21s\tremaining: 2m 2s\n","535:\tlearn: 1397.5497119\ttotal: 2m 21s\tremaining: 2m 2s\n","536:\tlearn: 1397.2197483\ttotal: 2m 21s\tremaining: 2m 2s\n","537:\tlearn: 1396.8081470\ttotal: 2m 21s\tremaining: 2m 1s\n","538:\tlearn: 1396.4704160\ttotal: 2m 22s\tremaining: 2m 1s\n","539:\tlearn: 1396.2630484\ttotal: 2m 22s\tremaining: 2m 1s\n","540:\tlearn: 1395.7960510\ttotal: 2m 22s\tremaining: 2m 1s\n","541:\tlearn: 1395.4523645\ttotal: 2m 23s\tremaining: 2m\n","542:\tlearn: 1394.9724214\ttotal: 2m 23s\tremaining: 2m\n","543:\tlearn: 1394.5145596\ttotal: 2m 23s\tremaining: 2m\n","544:\tlearn: 1394.2982231\ttotal: 2m 23s\tremaining: 2m\n","545:\tlearn: 1393.8622091\ttotal: 2m 24s\tremaining: 1m 59s\n","546:\tlearn: 1393.5440813\ttotal: 2m 24s\tremaining: 1m 59s\n","547:\tlearn: 1393.2262434\ttotal: 2m 24s\tremaining: 1m 59s\n","548:\tlearn: 1392.8405632\ttotal: 2m 24s\tremaining: 1m 58s\n","549:\tlearn: 1392.7093450\ttotal: 2m 25s\tremaining: 1m 58s\n","550:\tlearn: 1392.4978435\ttotal: 2m 25s\tremaining: 1m 58s\n","551:\tlearn: 1392.0008782\ttotal: 2m 25s\tremaining: 1m 58s\n","552:\tlearn: 1391.4922444\ttotal: 2m 25s\tremaining: 1m 57s\n","553:\tlearn: 1391.3336714\ttotal: 2m 26s\tremaining: 1m 57s\n","554:\tlearn: 1391.2290028\ttotal: 2m 26s\tremaining: 1m 57s\n","555:\tlearn: 1390.8585074\ttotal: 2m 27s\tremaining: 1m 57s\n","556:\tlearn: 1390.6624538\ttotal: 2m 27s\tremaining: 1m 57s\n","557:\tlearn: 1390.4722839\ttotal: 2m 27s\tremaining: 1m 56s\n","558:\tlearn: 1390.3501521\ttotal: 2m 27s\tremaining: 1m 56s\n","559:\tlearn: 1390.1955449\ttotal: 2m 28s\tremaining: 1m 56s\n","560:\tlearn: 1390.0412696\ttotal: 2m 28s\tremaining: 1m 56s\n","561:\tlearn: 1389.8752080\ttotal: 2m 28s\tremaining: 1m 55s\n","562:\tlearn: 1389.4339365\ttotal: 2m 29s\tremaining: 1m 55s\n","563:\tlearn: 1389.3228312\ttotal: 2m 29s\tremaining: 1m 55s\n","564:\tlearn: 1388.5546079\ttotal: 2m 29s\tremaining: 1m 55s\n","565:\tlearn: 1388.3878311\ttotal: 2m 30s\tremaining: 1m 55s\n","566:\tlearn: 1388.2015715\ttotal: 2m 31s\tremaining: 1m 55s\n","567:\tlearn: 1387.5297321\ttotal: 2m 31s\tremaining: 1m 55s\n","568:\tlearn: 1387.0275435\ttotal: 2m 31s\tremaining: 1m 54s\n","569:\tlearn: 1386.6170958\ttotal: 2m 32s\tremaining: 1m 54s\n","570:\tlearn: 1386.3913383\ttotal: 2m 32s\tremaining: 1m 54s\n","571:\tlearn: 1385.8023455\ttotal: 2m 32s\tremaining: 1m 54s\n","572:\tlearn: 1385.5763977\ttotal: 2m 32s\tremaining: 1m 53s\n","573:\tlearn: 1385.3286750\ttotal: 2m 33s\tremaining: 1m 53s\n","574:\tlearn: 1385.1924092\ttotal: 2m 33s\tremaining: 1m 53s\n","575:\tlearn: 1384.9708185\ttotal: 2m 33s\tremaining: 1m 53s\n","576:\tlearn: 1384.4543129\ttotal: 2m 33s\tremaining: 1m 52s\n","577:\tlearn: 1383.9359420\ttotal: 2m 34s\tremaining: 1m 52s\n","578:\tlearn: 1383.2510449\ttotal: 2m 34s\tremaining: 1m 52s\n","579:\tlearn: 1383.0996873\ttotal: 2m 34s\tremaining: 1m 51s\n","580:\tlearn: 1382.9214297\ttotal: 2m 34s\tremaining: 1m 51s\n","581:\tlearn: 1382.8152650\ttotal: 2m 35s\tremaining: 1m 51s\n","582:\tlearn: 1382.6880442\ttotal: 2m 35s\tremaining: 1m 51s\n","583:\tlearn: 1381.9125085\ttotal: 2m 35s\tremaining: 1m 50s\n","584:\tlearn: 1381.6785386\ttotal: 2m 35s\tremaining: 1m 50s\n","585:\tlearn: 1381.4408830\ttotal: 2m 36s\tremaining: 1m 50s\n","586:\tlearn: 1381.1056524\ttotal: 2m 36s\tremaining: 1m 49s\n","587:\tlearn: 1380.8208628\ttotal: 2m 36s\tremaining: 1m 49s\n","588:\tlearn: 1380.6076711\ttotal: 2m 36s\tremaining: 1m 49s\n","589:\tlearn: 1380.5522081\ttotal: 2m 36s\tremaining: 1m 49s\n","590:\tlearn: 1380.1761198\ttotal: 2m 37s\tremaining: 1m 48s\n","591:\tlearn: 1379.8316605\ttotal: 2m 37s\tremaining: 1m 48s\n","592:\tlearn: 1379.7325389\ttotal: 2m 37s\tremaining: 1m 48s\n","593:\tlearn: 1379.5107337\ttotal: 2m 37s\tremaining: 1m 47s\n","594:\tlearn: 1379.4455092\ttotal: 2m 38s\tremaining: 1m 47s\n","595:\tlearn: 1379.2592471\ttotal: 2m 38s\tremaining: 1m 47s\n","596:\tlearn: 1378.9971621\ttotal: 2m 38s\tremaining: 1m 47s\n","597:\tlearn: 1378.9533624\ttotal: 2m 38s\tremaining: 1m 46s\n","598:\tlearn: 1378.7032191\ttotal: 2m 39s\tremaining: 1m 46s\n","599:\tlearn: 1378.2430979\ttotal: 2m 39s\tremaining: 1m 46s\n","600:\tlearn: 1377.9342828\ttotal: 2m 39s\tremaining: 1m 45s\n","601:\tlearn: 1377.6815295\ttotal: 2m 39s\tremaining: 1m 45s\n","602:\tlearn: 1377.5546811\ttotal: 2m 40s\tremaining: 1m 45s\n","603:\tlearn: 1377.3852673\ttotal: 2m 40s\tremaining: 1m 45s\n","604:\tlearn: 1376.8757855\ttotal: 2m 40s\tremaining: 1m 44s\n","605:\tlearn: 1376.5151272\ttotal: 2m 40s\tremaining: 1m 44s\n","606:\tlearn: 1376.2711941\ttotal: 2m 41s\tremaining: 1m 44s\n","607:\tlearn: 1376.1387854\ttotal: 2m 41s\tremaining: 1m 43s\n","608:\tlearn: 1376.0897737\ttotal: 2m 41s\tremaining: 1m 43s\n","609:\tlearn: 1375.9504838\ttotal: 2m 41s\tremaining: 1m 43s\n","610:\tlearn: 1375.7307377\ttotal: 2m 41s\tremaining: 1m 43s\n","611:\tlearn: 1375.5043762\ttotal: 2m 42s\tremaining: 1m 42s\n","612:\tlearn: 1375.2587282\ttotal: 2m 42s\tremaining: 1m 42s\n","613:\tlearn: 1375.0278960\ttotal: 2m 42s\tremaining: 1m 42s\n","614:\tlearn: 1374.8081153\ttotal: 2m 43s\tremaining: 1m 42s\n","615:\tlearn: 1374.6683010\ttotal: 2m 43s\tremaining: 1m 41s\n","616:\tlearn: 1374.1258597\ttotal: 2m 43s\tremaining: 1m 41s\n","617:\tlearn: 1373.7811489\ttotal: 2m 43s\tremaining: 1m 41s\n","618:\tlearn: 1373.5909319\ttotal: 2m 43s\tremaining: 1m 40s\n","619:\tlearn: 1373.3683379\ttotal: 2m 44s\tremaining: 1m 40s\n","620:\tlearn: 1373.1380577\ttotal: 2m 44s\tremaining: 1m 40s\n","621:\tlearn: 1373.1176456\ttotal: 2m 44s\tremaining: 1m 40s\n","622:\tlearn: 1372.8516551\ttotal: 2m 44s\tremaining: 1m 39s\n","623:\tlearn: 1372.4469539\ttotal: 2m 45s\tremaining: 1m 39s\n","624:\tlearn: 1372.2052616\ttotal: 2m 45s\tremaining: 1m 39s\n","625:\tlearn: 1372.0046493\ttotal: 2m 45s\tremaining: 1m 38s\n","626:\tlearn: 1371.8564191\ttotal: 2m 45s\tremaining: 1m 38s\n","627:\tlearn: 1371.5306561\ttotal: 2m 46s\tremaining: 1m 38s\n","628:\tlearn: 1371.2219383\ttotal: 2m 46s\tremaining: 1m 38s\n","629:\tlearn: 1370.9393763\ttotal: 2m 46s\tremaining: 1m 37s\n","630:\tlearn: 1370.5147311\ttotal: 2m 46s\tremaining: 1m 37s\n","631:\tlearn: 1370.3336067\ttotal: 2m 47s\tremaining: 1m 37s\n","632:\tlearn: 1370.0788086\ttotal: 2m 47s\tremaining: 1m 37s\n","633:\tlearn: 1369.8268220\ttotal: 2m 47s\tremaining: 1m 36s\n","634:\tlearn: 1369.7563102\ttotal: 2m 48s\tremaining: 1m 36s\n","635:\tlearn: 1369.5993566\ttotal: 2m 48s\tremaining: 1m 36s\n","636:\tlearn: 1369.3611261\ttotal: 2m 48s\tremaining: 1m 36s\n","637:\tlearn: 1369.1534520\ttotal: 2m 48s\tremaining: 1m 35s\n","638:\tlearn: 1368.8829196\ttotal: 2m 49s\tremaining: 1m 35s\n","639:\tlearn: 1368.6908000\ttotal: 2m 49s\tremaining: 1m 35s\n","640:\tlearn: 1368.5029606\ttotal: 2m 49s\tremaining: 1m 34s\n","641:\tlearn: 1368.2407222\ttotal: 2m 49s\tremaining: 1m 34s\n","642:\tlearn: 1368.2149950\ttotal: 2m 49s\tremaining: 1m 34s\n","643:\tlearn: 1368.1103774\ttotal: 2m 50s\tremaining: 1m 34s\n","644:\tlearn: 1368.0475189\ttotal: 2m 50s\tremaining: 1m 33s\n","645:\tlearn: 1367.7669774\ttotal: 2m 50s\tremaining: 1m 33s\n","646:\tlearn: 1367.6562795\ttotal: 2m 50s\tremaining: 1m 33s\n","647:\tlearn: 1367.6144541\ttotal: 2m 51s\tremaining: 1m 32s\n","648:\tlearn: 1367.4088693\ttotal: 2m 51s\tremaining: 1m 32s\n","649:\tlearn: 1367.2531790\ttotal: 2m 51s\tremaining: 1m 32s\n","650:\tlearn: 1367.0968778\ttotal: 2m 51s\tremaining: 1m 32s\n","651:\tlearn: 1366.9189601\ttotal: 2m 52s\tremaining: 1m 31s\n","652:\tlearn: 1366.7009131\ttotal: 2m 52s\tremaining: 1m 31s\n","653:\tlearn: 1366.5531754\ttotal: 2m 52s\tremaining: 1m 31s\n","654:\tlearn: 1366.2806696\ttotal: 2m 52s\tremaining: 1m 31s\n","655:\tlearn: 1366.1232706\ttotal: 2m 53s\tremaining: 1m 30s\n","656:\tlearn: 1365.9269059\ttotal: 2m 53s\tremaining: 1m 30s\n","657:\tlearn: 1365.7573728\ttotal: 2m 53s\tremaining: 1m 30s\n","658:\tlearn: 1365.7181730\ttotal: 2m 54s\tremaining: 1m 30s\n","659:\tlearn: 1365.2730948\ttotal: 2m 54s\tremaining: 1m 29s\n","660:\tlearn: 1364.9585651\ttotal: 2m 54s\tremaining: 1m 29s\n","661:\tlearn: 1364.6193108\ttotal: 2m 54s\tremaining: 1m 29s\n","662:\tlearn: 1364.4535851\ttotal: 2m 55s\tremaining: 1m 28s\n","663:\tlearn: 1364.0772899\ttotal: 2m 55s\tremaining: 1m 28s\n","664:\tlearn: 1363.7752017\ttotal: 2m 55s\tremaining: 1m 28s\n","665:\tlearn: 1363.3431972\ttotal: 2m 55s\tremaining: 1m 28s\n","666:\tlearn: 1363.1192606\ttotal: 2m 56s\tremaining: 1m 27s\n","667:\tlearn: 1363.0147096\ttotal: 2m 56s\tremaining: 1m 27s\n","668:\tlearn: 1362.6650350\ttotal: 2m 56s\tremaining: 1m 27s\n","669:\tlearn: 1362.3194716\ttotal: 2m 56s\tremaining: 1m 27s\n","670:\tlearn: 1362.0506288\ttotal: 2m 56s\tremaining: 1m 26s\n","671:\tlearn: 1361.8900629\ttotal: 2m 57s\tremaining: 1m 26s\n","672:\tlearn: 1361.7902237\ttotal: 2m 57s\tremaining: 1m 26s\n","673:\tlearn: 1361.6167822\ttotal: 2m 57s\tremaining: 1m 25s\n","674:\tlearn: 1361.2744413\ttotal: 2m 58s\tremaining: 1m 25s\n","675:\tlearn: 1360.6498844\ttotal: 2m 58s\tremaining: 1m 25s\n","676:\tlearn: 1360.2477533\ttotal: 2m 58s\tremaining: 1m 25s\n","677:\tlearn: 1360.0535667\ttotal: 2m 58s\tremaining: 1m 24s\n","678:\tlearn: 1359.7633150\ttotal: 2m 59s\tremaining: 1m 24s\n","679:\tlearn: 1359.5643100\ttotal: 2m 59s\tremaining: 1m 24s\n","680:\tlearn: 1359.3230227\ttotal: 2m 59s\tremaining: 1m 24s\n","681:\tlearn: 1359.0113407\ttotal: 2m 59s\tremaining: 1m 23s\n","682:\tlearn: 1358.7435971\ttotal: 3m\tremaining: 1m 23s\n","683:\tlearn: 1358.6793892\ttotal: 3m\tremaining: 1m 23s\n","684:\tlearn: 1358.5455132\ttotal: 3m\tremaining: 1m 23s\n","685:\tlearn: 1358.4642465\ttotal: 3m\tremaining: 1m 22s\n","686:\tlearn: 1358.2190208\ttotal: 3m 1s\tremaining: 1m 22s\n","687:\tlearn: 1357.8806273\ttotal: 3m 1s\tremaining: 1m 22s\n","688:\tlearn: 1357.4637142\ttotal: 3m 2s\tremaining: 1m 22s\n","689:\tlearn: 1357.3296055\ttotal: 3m 2s\tremaining: 1m 22s\n","690:\tlearn: 1357.2016703\ttotal: 3m 3s\tremaining: 1m 21s\n","691:\tlearn: 1357.0219991\ttotal: 3m 3s\tremaining: 1m 21s\n","692:\tlearn: 1356.7538693\ttotal: 3m 3s\tremaining: 1m 21s\n","693:\tlearn: 1356.6685316\ttotal: 3m 3s\tremaining: 1m 21s\n","694:\tlearn: 1356.4985972\ttotal: 3m 4s\tremaining: 1m 20s\n","695:\tlearn: 1356.3058983\ttotal: 3m 4s\tremaining: 1m 20s\n","696:\tlearn: 1356.1220292\ttotal: 3m 4s\tremaining: 1m 20s\n","697:\tlearn: 1355.8920134\ttotal: 3m 4s\tremaining: 1m 20s\n","698:\tlearn: 1355.7343269\ttotal: 3m 5s\tremaining: 1m 19s\n","699:\tlearn: 1355.4505089\ttotal: 3m 5s\tremaining: 1m 19s\n","700:\tlearn: 1355.3476705\ttotal: 3m 5s\tremaining: 1m 19s\n","701:\tlearn: 1355.2016998\ttotal: 3m 5s\tremaining: 1m 18s\n","702:\tlearn: 1355.0871609\ttotal: 3m 6s\tremaining: 1m 18s\n","703:\tlearn: 1354.3032335\ttotal: 3m 6s\tremaining: 1m 18s\n","704:\tlearn: 1354.1075670\ttotal: 3m 7s\tremaining: 1m 18s\n","705:\tlearn: 1353.6640120\ttotal: 3m 7s\tremaining: 1m 18s\n","706:\tlearn: 1353.5747549\ttotal: 3m 7s\tremaining: 1m 17s\n","707:\tlearn: 1353.2351217\ttotal: 3m 8s\tremaining: 1m 17s\n","708:\tlearn: 1352.7831634\ttotal: 3m 8s\tremaining: 1m 17s\n","709:\tlearn: 1352.5834977\ttotal: 3m 8s\tremaining: 1m 17s\n","710:\tlearn: 1352.3794786\ttotal: 3m 9s\tremaining: 1m 16s\n","711:\tlearn: 1352.3106077\ttotal: 3m 9s\tremaining: 1m 16s\n","712:\tlearn: 1352.1281596\ttotal: 3m 9s\tremaining: 1m 16s\n","713:\tlearn: 1351.5782286\ttotal: 3m 9s\tremaining: 1m 16s\n","714:\tlearn: 1350.9748068\ttotal: 3m 10s\tremaining: 1m 15s\n","715:\tlearn: 1350.8274307\ttotal: 3m 10s\tremaining: 1m 15s\n","716:\tlearn: 1350.7810878\ttotal: 3m 10s\tremaining: 1m 15s\n","717:\tlearn: 1350.5970127\ttotal: 3m 10s\tremaining: 1m 14s\n","718:\tlearn: 1350.4281444\ttotal: 3m 11s\tremaining: 1m 14s\n","719:\tlearn: 1350.3366467\ttotal: 3m 11s\tremaining: 1m 14s\n","720:\tlearn: 1349.9978535\ttotal: 3m 11s\tremaining: 1m 14s\n","721:\tlearn: 1349.7355337\ttotal: 3m 12s\tremaining: 1m 13s\n","722:\tlearn: 1349.7204429\ttotal: 3m 12s\tremaining: 1m 13s\n","723:\tlearn: 1349.4714595\ttotal: 3m 13s\tremaining: 1m 13s\n","724:\tlearn: 1349.1916435\ttotal: 3m 13s\tremaining: 1m 13s\n","725:\tlearn: 1348.8701147\ttotal: 3m 13s\tremaining: 1m 13s\n","726:\tlearn: 1348.6796684\ttotal: 3m 13s\tremaining: 1m 12s\n","727:\tlearn: 1348.4814214\ttotal: 3m 14s\tremaining: 1m 12s\n","728:\tlearn: 1348.1242062\ttotal: 3m 14s\tremaining: 1m 12s\n","729:\tlearn: 1347.9862798\ttotal: 3m 14s\tremaining: 1m 11s\n","730:\tlearn: 1347.6844100\ttotal: 3m 14s\tremaining: 1m 11s\n","731:\tlearn: 1347.5089352\ttotal: 3m 15s\tremaining: 1m 11s\n","732:\tlearn: 1347.2446063\ttotal: 3m 15s\tremaining: 1m 11s\n","733:\tlearn: 1346.9894558\ttotal: 3m 15s\tremaining: 1m 10s\n","734:\tlearn: 1346.8756442\ttotal: 3m 15s\tremaining: 1m 10s\n","735:\tlearn: 1346.5294721\ttotal: 3m 16s\tremaining: 1m 10s\n","736:\tlearn: 1346.3242856\ttotal: 3m 16s\tremaining: 1m 10s\n","737:\tlearn: 1346.1658958\ttotal: 3m 16s\tremaining: 1m 9s\n","738:\tlearn: 1345.9621484\ttotal: 3m 16s\tremaining: 1m 9s\n","739:\tlearn: 1345.7025185\ttotal: 3m 17s\tremaining: 1m 9s\n","740:\tlearn: 1345.5283948\ttotal: 3m 17s\tremaining: 1m 9s\n","741:\tlearn: 1345.2784531\ttotal: 3m 17s\tremaining: 1m 8s\n","742:\tlearn: 1345.0202259\ttotal: 3m 17s\tremaining: 1m 8s\n","743:\tlearn: 1344.7082309\ttotal: 3m 18s\tremaining: 1m 8s\n","744:\tlearn: 1344.3070086\ttotal: 3m 18s\tremaining: 1m 7s\n","745:\tlearn: 1343.5293050\ttotal: 3m 18s\tremaining: 1m 7s\n","746:\tlearn: 1343.2801059\ttotal: 3m 18s\tremaining: 1m 7s\n","747:\tlearn: 1343.1385015\ttotal: 3m 19s\tremaining: 1m 7s\n","748:\tlearn: 1343.0109922\ttotal: 3m 19s\tremaining: 1m 6s\n","749:\tlearn: 1342.7321576\ttotal: 3m 19s\tremaining: 1m 6s\n","750:\tlearn: 1342.5141115\ttotal: 3m 19s\tremaining: 1m 6s\n","751:\tlearn: 1342.2202091\ttotal: 3m 20s\tremaining: 1m 5s\n","752:\tlearn: 1342.1193995\ttotal: 3m 20s\tremaining: 1m 5s\n","753:\tlearn: 1341.8595891\ttotal: 3m 20s\tremaining: 1m 5s\n","754:\tlearn: 1341.6069130\ttotal: 3m 20s\tremaining: 1m 5s\n","755:\tlearn: 1341.5620855\ttotal: 3m 20s\tremaining: 1m 4s\n","756:\tlearn: 1341.4290362\ttotal: 3m 21s\tremaining: 1m 4s\n","757:\tlearn: 1341.0873541\ttotal: 3m 21s\tremaining: 1m 4s\n","758:\tlearn: 1340.9605505\ttotal: 3m 21s\tremaining: 1m 4s\n","759:\tlearn: 1340.7431619\ttotal: 3m 22s\tremaining: 1m 3s\n","760:\tlearn: 1340.4443676\ttotal: 3m 22s\tremaining: 1m 3s\n","761:\tlearn: 1340.2353477\ttotal: 3m 22s\tremaining: 1m 3s\n","762:\tlearn: 1340.0826199\ttotal: 3m 23s\tremaining: 1m 3s\n","763:\tlearn: 1339.8176327\ttotal: 3m 23s\tremaining: 1m 2s\n","764:\tlearn: 1339.7041301\ttotal: 3m 23s\tremaining: 1m 2s\n","765:\tlearn: 1339.4389482\ttotal: 3m 24s\tremaining: 1m 2s\n","766:\tlearn: 1339.3021542\ttotal: 3m 24s\tremaining: 1m 2s\n","767:\tlearn: 1339.1359750\ttotal: 3m 24s\tremaining: 1m 1s\n","768:\tlearn: 1339.0265060\ttotal: 3m 24s\tremaining: 1m 1s\n","769:\tlearn: 1338.7162165\ttotal: 3m 25s\tremaining: 1m 1s\n","770:\tlearn: 1338.4409623\ttotal: 3m 25s\tremaining: 1m 1s\n","771:\tlearn: 1337.8964389\ttotal: 3m 25s\tremaining: 1m\n","772:\tlearn: 1337.6219068\ttotal: 3m 25s\tremaining: 1m\n","773:\tlearn: 1337.4355264\ttotal: 3m 26s\tremaining: 1m\n","774:\tlearn: 1337.1361908\ttotal: 3m 26s\tremaining: 59.9s\n","775:\tlearn: 1336.9947108\ttotal: 3m 26s\tremaining: 59.7s\n","776:\tlearn: 1336.7436737\ttotal: 3m 26s\tremaining: 59.4s\n","777:\tlearn: 1336.6253896\ttotal: 3m 27s\tremaining: 59.1s\n","778:\tlearn: 1336.5102250\ttotal: 3m 27s\tremaining: 58.8s\n","779:\tlearn: 1336.1306492\ttotal: 3m 27s\tremaining: 58.5s\n","780:\tlearn: 1336.0447113\ttotal: 3m 27s\tremaining: 58.3s\n","781:\tlearn: 1335.3878878\ttotal: 3m 28s\tremaining: 58s\n","782:\tlearn: 1334.9616520\ttotal: 3m 28s\tremaining: 57.7s\n","783:\tlearn: 1334.8209789\ttotal: 3m 28s\tremaining: 57.5s\n","784:\tlearn: 1334.7527973\ttotal: 3m 28s\tremaining: 57.2s\n","785:\tlearn: 1334.5235176\ttotal: 3m 28s\tremaining: 56.9s\n","786:\tlearn: 1334.4205169\ttotal: 3m 29s\tremaining: 56.6s\n","787:\tlearn: 1333.9429685\ttotal: 3m 29s\tremaining: 56.3s\n","788:\tlearn: 1333.6996786\ttotal: 3m 29s\tremaining: 56.1s\n","789:\tlearn: 1333.5404391\ttotal: 3m 29s\tremaining: 55.8s\n","790:\tlearn: 1333.3867742\ttotal: 3m 30s\tremaining: 55.5s\n","791:\tlearn: 1333.2558524\ttotal: 3m 30s\tremaining: 55.3s\n","792:\tlearn: 1332.9633053\ttotal: 3m 30s\tremaining: 55s\n","793:\tlearn: 1332.7768529\ttotal: 3m 30s\tremaining: 54.7s\n","794:\tlearn: 1332.5625524\ttotal: 3m 31s\tremaining: 54.5s\n","795:\tlearn: 1332.2318808\ttotal: 3m 31s\tremaining: 54.2s\n","796:\tlearn: 1332.0561115\ttotal: 3m 31s\tremaining: 53.9s\n","797:\tlearn: 1331.7871444\ttotal: 3m 31s\tremaining: 53.7s\n","798:\tlearn: 1331.6333868\ttotal: 3m 32s\tremaining: 53.4s\n","799:\tlearn: 1331.4647395\ttotal: 3m 32s\tremaining: 53.1s\n","800:\tlearn: 1331.1206906\ttotal: 3m 32s\tremaining: 52.8s\n","801:\tlearn: 1330.8809933\ttotal: 3m 32s\tremaining: 52.6s\n","802:\tlearn: 1330.7247084\ttotal: 3m 33s\tremaining: 52.3s\n","803:\tlearn: 1330.4535718\ttotal: 3m 33s\tremaining: 52s\n","804:\tlearn: 1330.3293134\ttotal: 3m 33s\tremaining: 51.8s\n","805:\tlearn: 1330.0130873\ttotal: 3m 33s\tremaining: 51.5s\n","806:\tlearn: 1329.8364266\ttotal: 3m 34s\tremaining: 51.2s\n","807:\tlearn: 1329.4855860\ttotal: 3m 34s\tremaining: 50.9s\n","808:\tlearn: 1329.3800339\ttotal: 3m 34s\tremaining: 50.7s\n","809:\tlearn: 1329.1551941\ttotal: 3m 34s\tremaining: 50.4s\n","810:\tlearn: 1329.0105585\ttotal: 3m 35s\tremaining: 50.1s\n","811:\tlearn: 1328.7864848\ttotal: 3m 35s\tremaining: 49.8s\n","812:\tlearn: 1328.6774629\ttotal: 3m 35s\tremaining: 49.6s\n","813:\tlearn: 1328.4263470\ttotal: 3m 35s\tremaining: 49.3s\n","814:\tlearn: 1328.2875669\ttotal: 3m 36s\tremaining: 49.1s\n","815:\tlearn: 1327.9538505\ttotal: 3m 36s\tremaining: 48.8s\n","816:\tlearn: 1327.8645898\ttotal: 3m 36s\tremaining: 48.5s\n","817:\tlearn: 1327.5775373\ttotal: 3m 36s\tremaining: 48.2s\n","818:\tlearn: 1327.4576240\ttotal: 3m 37s\tremaining: 48s\n","819:\tlearn: 1327.2500829\ttotal: 3m 37s\tremaining: 47.7s\n","820:\tlearn: 1326.9997488\ttotal: 3m 37s\tremaining: 47.4s\n","821:\tlearn: 1326.7832390\ttotal: 3m 37s\tremaining: 47.2s\n","822:\tlearn: 1326.5087379\ttotal: 3m 38s\tremaining: 46.9s\n","823:\tlearn: 1326.3264866\ttotal: 3m 38s\tremaining: 46.6s\n","824:\tlearn: 1326.2524553\ttotal: 3m 38s\tremaining: 46.4s\n","825:\tlearn: 1326.0570668\ttotal: 3m 39s\tremaining: 46.1s\n","826:\tlearn: 1325.9637098\ttotal: 3m 39s\tremaining: 45.9s\n","827:\tlearn: 1325.8612836\ttotal: 3m 39s\tremaining: 45.6s\n","828:\tlearn: 1325.7225953\ttotal: 3m 40s\tremaining: 45.4s\n","829:\tlearn: 1325.6469991\ttotal: 3m 40s\tremaining: 45.1s\n","830:\tlearn: 1325.5469030\ttotal: 3m 40s\tremaining: 44.9s\n","831:\tlearn: 1325.3729436\ttotal: 3m 41s\tremaining: 44.7s\n","832:\tlearn: 1325.1652538\ttotal: 3m 41s\tremaining: 44.4s\n","833:\tlearn: 1324.9098345\ttotal: 3m 41s\tremaining: 44.2s\n","834:\tlearn: 1324.7201356\ttotal: 3m 42s\tremaining: 43.9s\n","835:\tlearn: 1324.4752728\ttotal: 3m 42s\tremaining: 43.7s\n","836:\tlearn: 1324.0814074\ttotal: 3m 43s\tremaining: 43.4s\n","837:\tlearn: 1323.8411792\ttotal: 3m 43s\tremaining: 43.2s\n","838:\tlearn: 1323.6771517\ttotal: 3m 43s\tremaining: 42.9s\n","839:\tlearn: 1323.5004371\ttotal: 3m 44s\tremaining: 42.7s\n","840:\tlearn: 1323.0441112\ttotal: 3m 44s\tremaining: 42.5s\n","841:\tlearn: 1322.8541015\ttotal: 3m 44s\tremaining: 42.2s\n","842:\tlearn: 1322.8180144\ttotal: 3m 45s\tremaining: 41.9s\n","843:\tlearn: 1322.6352105\ttotal: 3m 45s\tremaining: 41.7s\n","844:\tlearn: 1322.4945594\ttotal: 3m 45s\tremaining: 41.4s\n","845:\tlearn: 1322.4112650\ttotal: 3m 46s\tremaining: 41.2s\n","846:\tlearn: 1321.8557823\ttotal: 3m 46s\tremaining: 40.9s\n","847:\tlearn: 1321.5723333\ttotal: 3m 46s\tremaining: 40.7s\n","848:\tlearn: 1321.3738254\ttotal: 3m 47s\tremaining: 40.4s\n","849:\tlearn: 1321.0306155\ttotal: 3m 47s\tremaining: 40.2s\n","850:\tlearn: 1320.7491076\ttotal: 3m 48s\tremaining: 39.9s\n","851:\tlearn: 1320.6307003\ttotal: 3m 48s\tremaining: 39.7s\n","852:\tlearn: 1320.4443887\ttotal: 3m 48s\tremaining: 39.4s\n","853:\tlearn: 1320.2872942\ttotal: 3m 48s\tremaining: 39.1s\n","854:\tlearn: 1320.0386035\ttotal: 3m 49s\tremaining: 38.9s\n","855:\tlearn: 1319.8309854\ttotal: 3m 49s\tremaining: 38.6s\n","856:\tlearn: 1319.6174252\ttotal: 3m 49s\tremaining: 38.3s\n","857:\tlearn: 1319.4610340\ttotal: 3m 49s\tremaining: 38.1s\n","858:\tlearn: 1319.3414660\ttotal: 3m 50s\tremaining: 37.8s\n","859:\tlearn: 1319.1850609\ttotal: 3m 50s\tremaining: 37.5s\n","860:\tlearn: 1318.9028472\ttotal: 3m 50s\tremaining: 37.2s\n","861:\tlearn: 1318.8153903\ttotal: 3m 50s\tremaining: 37s\n","862:\tlearn: 1318.7133767\ttotal: 3m 51s\tremaining: 36.7s\n","863:\tlearn: 1318.5097121\ttotal: 3m 51s\tremaining: 36.4s\n","864:\tlearn: 1318.3630630\ttotal: 3m 51s\tremaining: 36.2s\n","865:\tlearn: 1317.5354046\ttotal: 3m 51s\tremaining: 35.9s\n","866:\tlearn: 1317.3924159\ttotal: 3m 52s\tremaining: 35.6s\n","867:\tlearn: 1317.1487563\ttotal: 3m 52s\tremaining: 35.3s\n","868:\tlearn: 1316.8955291\ttotal: 3m 52s\tremaining: 35s\n","869:\tlearn: 1316.7632229\ttotal: 3m 52s\tremaining: 34.8s\n","870:\tlearn: 1316.5818845\ttotal: 3m 52s\tremaining: 34.5s\n","871:\tlearn: 1316.5193002\ttotal: 3m 53s\tremaining: 34.2s\n","872:\tlearn: 1316.1892635\ttotal: 3m 53s\tremaining: 34s\n","873:\tlearn: 1315.9900801\ttotal: 3m 53s\tremaining: 33.7s\n","874:\tlearn: 1315.8458869\ttotal: 3m 53s\tremaining: 33.4s\n","875:\tlearn: 1315.7600144\ttotal: 3m 54s\tremaining: 33.1s\n","876:\tlearn: 1315.5984926\ttotal: 3m 54s\tremaining: 32.9s\n","877:\tlearn: 1315.3537915\ttotal: 3m 54s\tremaining: 32.6s\n","878:\tlearn: 1315.1461592\ttotal: 3m 54s\tremaining: 32.3s\n","879:\tlearn: 1315.1244981\ttotal: 3m 55s\tremaining: 32s\n","880:\tlearn: 1314.9465379\ttotal: 3m 55s\tremaining: 31.8s\n","881:\tlearn: 1314.8034803\ttotal: 3m 55s\tremaining: 31.5s\n","882:\tlearn: 1314.3886703\ttotal: 3m 55s\tremaining: 31.2s\n","883:\tlearn: 1314.0563739\ttotal: 3m 55s\tremaining: 31s\n","884:\tlearn: 1313.8211405\ttotal: 3m 56s\tremaining: 30.7s\n","885:\tlearn: 1313.7590374\ttotal: 3m 56s\tremaining: 30.4s\n","886:\tlearn: 1313.6484018\ttotal: 3m 56s\tremaining: 30.1s\n","887:\tlearn: 1313.4052490\ttotal: 3m 56s\tremaining: 29.9s\n","888:\tlearn: 1312.9399032\ttotal: 3m 57s\tremaining: 29.6s\n","889:\tlearn: 1312.9205348\ttotal: 3m 57s\tremaining: 29.3s\n","890:\tlearn: 1312.8765737\ttotal: 3m 57s\tremaining: 29.1s\n","891:\tlearn: 1312.6736262\ttotal: 3m 57s\tremaining: 28.8s\n","892:\tlearn: 1312.5623318\ttotal: 3m 58s\tremaining: 28.5s\n","893:\tlearn: 1312.3842396\ttotal: 3m 58s\tremaining: 28.3s\n","894:\tlearn: 1312.2043694\ttotal: 3m 58s\tremaining: 28s\n","895:\tlearn: 1312.0239846\ttotal: 3m 58s\tremaining: 27.7s\n","896:\tlearn: 1311.9024104\ttotal: 3m 58s\tremaining: 27.4s\n","897:\tlearn: 1311.5730815\ttotal: 3m 59s\tremaining: 27.2s\n","898:\tlearn: 1311.2453006\ttotal: 3m 59s\tremaining: 26.9s\n","899:\tlearn: 1310.9633189\ttotal: 3m 59s\tremaining: 26.6s\n","900:\tlearn: 1310.7023338\ttotal: 3m 59s\tremaining: 26.4s\n","901:\tlearn: 1310.6245933\ttotal: 4m\tremaining: 26.1s\n","902:\tlearn: 1310.5674521\ttotal: 4m\tremaining: 25.8s\n","903:\tlearn: 1310.3499458\ttotal: 4m\tremaining: 25.5s\n","904:\tlearn: 1310.2427968\ttotal: 4m\tremaining: 25.3s\n","905:\tlearn: 1310.1498517\ttotal: 4m 1s\tremaining: 25s\n","906:\tlearn: 1310.0526167\ttotal: 4m 1s\tremaining: 24.7s\n","907:\tlearn: 1309.9092326\ttotal: 4m 1s\tremaining: 24.5s\n","908:\tlearn: 1309.8532890\ttotal: 4m 1s\tremaining: 24.2s\n","909:\tlearn: 1309.7757974\ttotal: 4m 2s\tremaining: 23.9s\n","910:\tlearn: 1309.6092815\ttotal: 4m 2s\tremaining: 23.7s\n","911:\tlearn: 1309.3855206\ttotal: 4m 2s\tremaining: 23.4s\n","912:\tlearn: 1309.1296964\ttotal: 4m 2s\tremaining: 23.1s\n","913:\tlearn: 1309.0421217\ttotal: 4m 3s\tremaining: 22.9s\n","914:\tlearn: 1308.8424735\ttotal: 4m 3s\tremaining: 22.6s\n","915:\tlearn: 1308.8002806\ttotal: 4m 3s\tremaining: 22.3s\n","916:\tlearn: 1308.7816031\ttotal: 4m 3s\tremaining: 22.1s\n","917:\tlearn: 1308.4754750\ttotal: 4m 4s\tremaining: 21.8s\n","918:\tlearn: 1308.1784124\ttotal: 4m 4s\tremaining: 21.5s\n","919:\tlearn: 1308.0540634\ttotal: 4m 4s\tremaining: 21.3s\n","920:\tlearn: 1307.7401779\ttotal: 4m 4s\tremaining: 21s\n","921:\tlearn: 1307.6994969\ttotal: 4m 5s\tremaining: 20.7s\n","922:\tlearn: 1307.5570987\ttotal: 4m 5s\tremaining: 20.5s\n","923:\tlearn: 1307.4157576\ttotal: 4m 5s\tremaining: 20.2s\n","924:\tlearn: 1307.3249754\ttotal: 4m 5s\tremaining: 19.9s\n","925:\tlearn: 1307.2341165\ttotal: 4m 5s\tremaining: 19.7s\n","926:\tlearn: 1307.0002488\ttotal: 4m 6s\tremaining: 19.4s\n","927:\tlearn: 1306.9712085\ttotal: 4m 6s\tremaining: 19.1s\n","928:\tlearn: 1306.7963119\ttotal: 4m 7s\tremaining: 18.9s\n","929:\tlearn: 1306.3168047\ttotal: 4m 7s\tremaining: 18.6s\n","930:\tlearn: 1306.2691179\ttotal: 4m 8s\tremaining: 18.4s\n","931:\tlearn: 1306.0139903\ttotal: 4m 8s\tremaining: 18.1s\n","932:\tlearn: 1305.8641095\ttotal: 4m 8s\tremaining: 17.9s\n","933:\tlearn: 1305.7094299\ttotal: 4m 9s\tremaining: 17.6s\n","934:\tlearn: 1305.5665374\ttotal: 4m 9s\tremaining: 17.3s\n","935:\tlearn: 1305.4525344\ttotal: 4m 9s\tremaining: 17.1s\n","936:\tlearn: 1305.3070972\ttotal: 4m 9s\tremaining: 16.8s\n","937:\tlearn: 1305.1394035\ttotal: 4m 9s\tremaining: 16.5s\n","938:\tlearn: 1304.9475078\ttotal: 4m 10s\tremaining: 16.3s\n","939:\tlearn: 1304.8076106\ttotal: 4m 10s\tremaining: 16s\n","940:\tlearn: 1304.6880360\ttotal: 4m 10s\tremaining: 15.7s\n","941:\tlearn: 1304.4565211\ttotal: 4m 10s\tremaining: 15.5s\n","942:\tlearn: 1304.3751793\ttotal: 4m 11s\tremaining: 15.2s\n","943:\tlearn: 1304.2735532\ttotal: 4m 11s\tremaining: 14.9s\n","944:\tlearn: 1304.1522050\ttotal: 4m 11s\tremaining: 14.7s\n","945:\tlearn: 1303.9758195\ttotal: 4m 12s\tremaining: 14.4s\n","946:\tlearn: 1303.8630357\ttotal: 4m 12s\tremaining: 14.1s\n","947:\tlearn: 1303.7776070\ttotal: 4m 12s\tremaining: 13.9s\n","948:\tlearn: 1303.7190816\ttotal: 4m 12s\tremaining: 13.6s\n","949:\tlearn: 1303.3135540\ttotal: 4m 13s\tremaining: 13.3s\n","950:\tlearn: 1303.2244541\ttotal: 4m 13s\tremaining: 13.1s\n","951:\tlearn: 1303.1374418\ttotal: 4m 13s\tremaining: 12.8s\n","952:\tlearn: 1303.0151834\ttotal: 4m 13s\tremaining: 12.5s\n","953:\tlearn: 1302.8012527\ttotal: 4m 14s\tremaining: 12.3s\n","954:\tlearn: 1302.5340674\ttotal: 4m 14s\tremaining: 12s\n","955:\tlearn: 1302.4978431\ttotal: 4m 14s\tremaining: 11.7s\n","956:\tlearn: 1302.3150276\ttotal: 4m 14s\tremaining: 11.4s\n","957:\tlearn: 1302.0603734\ttotal: 4m 15s\tremaining: 11.2s\n","958:\tlearn: 1301.8426774\ttotal: 4m 15s\tremaining: 10.9s\n","959:\tlearn: 1301.4631602\ttotal: 4m 15s\tremaining: 10.6s\n","960:\tlearn: 1301.1697866\ttotal: 4m 15s\tremaining: 10.4s\n","961:\tlearn: 1301.1471039\ttotal: 4m 15s\tremaining: 10.1s\n","962:\tlearn: 1301.0306046\ttotal: 4m 16s\tremaining: 9.84s\n","963:\tlearn: 1301.0033526\ttotal: 4m 16s\tremaining: 9.58s\n","964:\tlearn: 1300.5985427\ttotal: 4m 16s\tremaining: 9.31s\n","965:\tlearn: 1300.4678096\ttotal: 4m 16s\tremaining: 9.04s\n","966:\tlearn: 1300.3234393\ttotal: 4m 17s\tremaining: 8.77s\n","967:\tlearn: 1300.0606390\ttotal: 4m 17s\tremaining: 8.51s\n","968:\tlearn: 1299.8575011\ttotal: 4m 17s\tremaining: 8.24s\n","969:\tlearn: 1299.7570994\ttotal: 4m 17s\tremaining: 7.98s\n","970:\tlearn: 1299.6795708\ttotal: 4m 18s\tremaining: 7.71s\n","971:\tlearn: 1299.5210013\ttotal: 4m 18s\tremaining: 7.45s\n","972:\tlearn: 1299.3850657\ttotal: 4m 18s\tremaining: 7.18s\n","973:\tlearn: 1299.1678008\ttotal: 4m 19s\tremaining: 6.91s\n","974:\tlearn: 1299.1275597\ttotal: 4m 19s\tremaining: 6.65s\n","975:\tlearn: 1298.8078739\ttotal: 4m 19s\tremaining: 6.38s\n","976:\tlearn: 1298.6061005\ttotal: 4m 19s\tremaining: 6.11s\n","977:\tlearn: 1298.3218392\ttotal: 4m 19s\tremaining: 5.85s\n","978:\tlearn: 1298.1115950\ttotal: 4m 20s\tremaining: 5.58s\n","979:\tlearn: 1297.9228912\ttotal: 4m 20s\tremaining: 5.31s\n","980:\tlearn: 1297.6168554\ttotal: 4m 20s\tremaining: 5.04s\n","981:\tlearn: 1297.4388734\ttotal: 4m 20s\tremaining: 4.78s\n","982:\tlearn: 1297.3339338\ttotal: 4m 20s\tremaining: 4.51s\n","983:\tlearn: 1297.1996855\ttotal: 4m 21s\tremaining: 4.25s\n","984:\tlearn: 1296.9319021\ttotal: 4m 21s\tremaining: 3.98s\n","985:\tlearn: 1296.7629797\ttotal: 4m 21s\tremaining: 3.72s\n","986:\tlearn: 1296.4697038\ttotal: 4m 22s\tremaining: 3.45s\n","987:\tlearn: 1296.3089490\ttotal: 4m 22s\tremaining: 3.19s\n","988:\tlearn: 1296.0060872\ttotal: 4m 22s\tremaining: 2.92s\n","989:\tlearn: 1295.8651512\ttotal: 4m 22s\tremaining: 2.65s\n","990:\tlearn: 1295.6460732\ttotal: 4m 23s\tremaining: 2.39s\n","991:\tlearn: 1295.5228025\ttotal: 4m 23s\tremaining: 2.12s\n","992:\tlearn: 1295.4852056\ttotal: 4m 23s\tremaining: 1.86s\n","993:\tlearn: 1295.3746193\ttotal: 4m 23s\tremaining: 1.59s\n","994:\tlearn: 1295.1183197\ttotal: 4m 24s\tremaining: 1.33s\n","995:\tlearn: 1294.8858868\ttotal: 4m 24s\tremaining: 1.06s\n","996:\tlearn: 1294.6131964\ttotal: 4m 25s\tremaining: 798ms\n","997:\tlearn: 1294.5351554\ttotal: 4m 25s\tremaining: 532ms\n","998:\tlearn: 1294.4047285\ttotal: 4m 25s\tremaining: 266ms\n","999:\tlearn: 1294.1085383\ttotal: 4m 26s\tremaining: 0us\n"]}],"source":["#CatBoost\n","start_train_cat = time.time()\n","model_cat_test = CatBoostRegressor(cat_features=cat_columns, max_depth=10, min_child_samples=16)\n","model_cat_test.fit(features_light_train, target_light_train)\n","end_train_cat = time.time()\n","Time_cat_train = end_train_cat - start_train_cat"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE CatBoost на тестовой выборке составляет 1584.67\n"]}],"source":["start_predict_cat = time.time()\n","prediction_cat_test = model_cat_test.predict(features_light_test)\n","end_predict_cat = time.time()\n","Time_cat_pred = end_predict_cat - start_predict_cat\n","rmse_cat_test = mean_squared_error(prediction_cat_test, target_light_test, squared=False)\n","print('RMSE CatBoost на тестовой выборке составляет {:.2f}'.format(rmse_light_test))"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["scores_final = [rmse_ridge_test, rmse_light_test, rmse_cat_test]\n","learing_times = [Time_ridge_train, Time_light_train, Time_cat_train]\n","predicting_times = [Time_ridge_pred, Time_light_pred, Time_cat_pred]\n","models = ['Ridge', 'LightGBM','CatBoostRegressor']\n","final_table = pd.DataFrame({'model':models,'score_final':scores_final,'train_time_sec':learing_times, 'pred_time_sec':predicting_times})"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_final</th>\n","      <th>train_time_sec</th>\n","      <th>pred_time_sec</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>CatBoostRegressor</td>\n","      <td>1583.09</td>\n","      <td>268.24</td>\n","      <td>0.86</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LightGBM</td>\n","      <td>1584.67</td>\n","      <td>2.87</td>\n","      <td>0.46</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Ridge</td>\n","      <td>2125.77</td>\n","      <td>1.20</td>\n","      <td>0.13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               model  score_final  train_time_sec  pred_time_sec\n","2  CatBoostRegressor      1583.09          268.24           0.86\n","1           LightGBM      1584.67            2.87           0.46\n","0              Ridge      2125.77            1.20           0.13"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["final_table.sort_values(by='score_final')"]},{"cell_type":"markdown","metadata":{},"source":["<a id = 'Conclusion'></a>\n","### 7. Выводы"]},{"cell_type":"markdown","metadata":{},"source":["### Провели работу по предсказанию цены на подержанные автомобили:  \n","1. Подготовли данные для анализа:\n","    - удалили нерелевантные столбцы  \n","    - заполнили пропуски  \n","    - удалили дубликаты  \n","2. Подготвили данные для построения моделей:\n","    - применили кодирование категориальных переменных  \n","    - произвели нормирование численных переменных  \n","3. Построили модели Линейной регрессии, Lasso, Ridge, LightGBM, CatBoost из коробки - без настройки гиперпараметров  \n","    - все модели показали очень хороший результат\n","    - лучше всего показала себя модель CatBoost, RMSE = 1618  \n","    - Самой быстрой оказалась модель Ridge  \n","4.  Настраивали модели, меняя гиперпараметры. Для экономии времени, меняли ограниченное количество параметров, те результаты могли бы быть еще лучше  \n","    - Модель Ridge регрессии не улучшила предсказания  \n","    - Для модели LightGBM удалось добиться RMSE = 1576, при следующих параметрах: \n","        -- n_estimators: 100\n","        -- num_leaves: 200\n","        -- max_depth: 12  \n","    - Модель CatBoost показала результат RMSE = 1584  \n","    Params:   \n","        -- max_depth: 10 \n","        -- min_child_samples: 12  \n","5. На тестовой выборке  лучше всех показала себя модель Catboost и LightGBM, LightGBM показала также очень низкое время обучения  \n","Для использования стоит применить модель LightGBM, у нее очень высокие показатели предсказаний и низкое время обучения, модель Catboost показывает сходное с LightGBM качество предсказаний, но вот обучается модель намного медленнее  "]}],"metadata":{"ExecuteTimeLog":[{"duration":1926,"start_time":"2022-07-05T04:55:37.351Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.281Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.282Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.284Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.286Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.287Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.288Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.289Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.291Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.292Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.293Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.295Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.296Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.323Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.325Z"},{"duration":1,"start_time":"2022-07-05T04:55:39.326Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.328Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.330Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.331Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.332Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.334Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.335Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.337Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.339Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.340Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.342Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.343Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.344Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.346Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.347Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.349Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.349Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.351Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.352Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.353Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.354Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.355Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.357Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.357Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.358Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.359Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.360Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.361Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.362Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.424Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.425Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.426Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.428Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.429Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.430Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.432Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.433Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.434Z"},{"duration":0,"start_time":"2022-07-05T04:55:39.435Z"},{"duration":6417,"start_time":"2022-07-05T04:56:40.467Z"},{"duration":2172,"start_time":"2022-07-05T04:57:17.514Z"},{"duration":328,"start_time":"2022-07-05T04:57:19.688Z"},{"duration":3,"start_time":"2022-07-05T04:57:20.018Z"},{"duration":725,"start_time":"2022-07-05T04:57:20.024Z"},{"duration":15,"start_time":"2022-07-05T04:57:20.751Z"},{"duration":140,"start_time":"2022-07-05T04:57:20.767Z"},{"duration":126,"start_time":"2022-07-05T04:57:20.908Z"},{"duration":2,"start_time":"2022-07-05T04:57:21.036Z"},{"duration":10,"start_time":"2022-07-05T04:57:21.040Z"},{"duration":31,"start_time":"2022-07-05T04:57:21.052Z"},{"duration":17,"start_time":"2022-07-05T04:57:21.084Z"},{"duration":195,"start_time":"2022-07-05T04:57:21.102Z"},{"duration":213,"start_time":"2022-07-05T04:57:21.299Z"},{"duration":65,"start_time":"2022-07-05T04:57:21.514Z"},{"duration":1374,"start_time":"2022-07-05T04:57:21.580Z"},{"duration":32,"start_time":"2022-07-05T04:57:22.955Z"},{"duration":8,"start_time":"2022-07-05T04:57:22.988Z"},{"duration":1187,"start_time":"2022-07-05T04:57:22.997Z"},{"duration":3,"start_time":"2022-07-05T04:57:24.186Z"},{"duration":3113,"start_time":"2022-07-05T04:57:24.191Z"},{"duration":27,"start_time":"2022-07-05T04:57:27.307Z"},{"duration":6,"start_time":"2022-07-05T04:57:27.336Z"},{"duration":195,"start_time":"2022-07-05T04:57:27.343Z"},{"duration":27,"start_time":"2022-07-05T04:57:27.539Z"},{"duration":29,"start_time":"2022-07-05T04:57:27.567Z"},{"duration":361,"start_time":"2022-07-05T04:57:27.598Z"},{"duration":84,"start_time":"2022-07-05T04:57:27.961Z"},{"duration":17,"start_time":"2022-07-05T04:57:28.048Z"},{"duration":159,"start_time":"2022-07-05T04:57:28.067Z"},{"duration":124,"start_time":"2022-07-05T04:57:28.227Z"},{"duration":6743,"start_time":"2022-07-05T04:57:28.353Z"},{"duration":6878,"start_time":"2022-07-05T04:57:35.097Z"},{"duration":82,"start_time":"2022-07-05T04:57:41.977Z"},{"duration":125,"start_time":"2022-07-05T04:57:42.060Z"},{"duration":107,"start_time":"2022-07-05T04:57:42.187Z"},{"duration":90,"start_time":"2022-07-05T04:57:42.296Z"},{"duration":13,"start_time":"2022-07-05T04:57:42.387Z"},{"duration":35,"start_time":"2022-07-05T04:57:42.402Z"},{"duration":13,"start_time":"2022-07-05T04:57:42.439Z"},{"duration":2,"start_time":"2022-07-05T04:57:42.454Z"},{"duration":14,"start_time":"2022-07-05T04:57:42.457Z"},{"duration":86,"start_time":"2022-07-05T04:57:42.472Z"},{"duration":3617,"start_time":"2022-07-05T04:57:42.560Z"},{"duration":17,"start_time":"2022-07-05T04:57:46.179Z"},{"duration":5,"start_time":"2022-07-05T04:57:46.197Z"},{"duration":22,"start_time":"2022-07-05T04:57:46.204Z"},{"duration":23,"start_time":"2022-07-05T04:57:46.228Z"},{"duration":10,"start_time":"2022-07-05T04:57:46.253Z"},{"duration":7,"start_time":"2022-07-05T04:57:46.264Z"},{"duration":586,"start_time":"2022-07-05T04:57:46.272Z"},{"duration":15,"start_time":"2022-07-05T04:57:46.859Z"},{"duration":173,"start_time":"2022-07-05T04:57:46.875Z"},{"duration":121,"start_time":"2022-07-05T04:57:47.050Z"},{"duration":317,"start_time":"2022-07-05T04:57:47.173Z"},{"duration":17,"start_time":"2022-07-05T04:57:47.492Z"},{"duration":4,"start_time":"2022-07-05T05:19:34.422Z"},{"duration":669,"start_time":"2022-07-05T05:19:43.382Z"},{"duration":15,"start_time":"2022-07-05T05:19:44.690Z"},{"duration":269,"start_time":"2022-07-05T05:20:11.691Z"},{"duration":116,"start_time":"2022-07-05T05:20:15.641Z"},{"duration":346,"start_time":"2022-07-05T05:20:17.150Z"},{"duration":31796,"start_time":"2022-07-05T05:20:20.730Z"},{"duration":185,"start_time":"2022-07-05T05:20:57.943Z"},{"duration":6,"start_time":"2022-07-05T05:21:02.239Z"},{"duration":40,"start_time":"2022-07-05T05:24:17.742Z"},{"duration":14,"start_time":"2022-07-05T05:24:27.296Z"},{"duration":2,"start_time":"2022-07-05T05:25:30.451Z"},{"duration":5,"start_time":"2022-07-05T05:26:53.402Z"},{"duration":4,"start_time":"2022-07-05T05:27:30.730Z"},{"duration":551,"start_time":"2022-07-05T05:27:33.099Z"},{"duration":16,"start_time":"2022-07-05T05:27:34.296Z"},{"duration":167,"start_time":"2022-07-05T05:27:36.139Z"},{"duration":115,"start_time":"2022-07-05T05:27:37.701Z"},{"duration":303,"start_time":"2022-07-05T05:27:48.935Z"},{"duration":30820,"start_time":"2022-07-05T05:27:52.011Z"},{"duration":295,"start_time":"2022-07-05T05:28:22.834Z"},{"duration":5,"start_time":"2022-07-05T05:30:45.130Z"},{"duration":5,"start_time":"2022-07-05T05:30:49.234Z"}],"interpreter":{"hash":"6f5dd8f20b058ead9365f7e252fda945bb74a615f91a5f6b0a68f63e4f4eb6f7"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":2}
